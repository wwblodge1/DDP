{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-mounting",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modular-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stone-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decreased-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: wandb in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.12.6)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.18.1)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: pathtools in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: six>=1.13.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwwblodge1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "discrete-relay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/yxp093u9\" target=\"_blank\">valiant-universe-25</a></strong> to <a href=\"https://wandb.ai/wwblodge1/hw9_instance\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/hw9_instance/runs/yxp093u9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0cb01db090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"hw9_instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-mortality",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "# Assume that this notebook only sees one GPU.\n",
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-mixer",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-commonwealth",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-morgan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "departmental-listing",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-hammer",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 1\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\"\n",
    "\n",
    "global_step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-elite",
   "metadata": {
    "id": "85299ee3"
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confused-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yxp093u9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10797... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">valiant-universe-25</strong>: <a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/yxp093u9\" target=\"_blank\">https://wandb.ai/wwblodge1/hw9_instance/runs/yxp093u9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211029_195747-yxp093u9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yxp093u9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/uncategorized/runs/36dvsyn5\" target=\"_blank\">serene-dragon-7</a></strong> to <a href=\"https://wandb.ai/wwblodge1/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/uncategorized/runs/36dvsyn5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0cb01a8690>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-eugene",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many processes in cluster?\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "# where is the master?\n",
    "# export NCCL_SOCKET_IFNAME=172.31.24.47\n",
    "URL = 'tcp://172.31.24.47:1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is my rank?\n",
    "RANK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-melbourne",
   "metadata": {
    "id": "68491838"
   },
   "outputs": [],
   "source": [
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "disturbed-swimming",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device('cpu')\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mineral-gibson",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-fireplace",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "# def train(train_loader, model, criterion, optimizer, epoch):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     data_time = AverageMeter('Data', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(train_loader),\n",
    "#         [batch_time, data_time, losses, top1, top5],\n",
    "#         prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "#     # switch to train mode\n",
    "#     model.train()\n",
    "\n",
    "#     end = time.time()\n",
    "#     for i, (images, target) in enumerate(train_loader):\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # measure accuracy and record loss\n",
    "#         acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#         losses.update(loss.item(), images.size(0))\n",
    "#         top1.update(acc1[0], images.size(0))\n",
    "#         top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if i % PRINT_FREQ == 0:\n",
    "#             progress.display(i)\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-cathedral",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "# def validate(val_loader, model, criterion):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(val_loader),\n",
    "#         [batch_time, losses, top1, top5],\n",
    "#         prefix='Test: ')\n",
    "\n",
    "#     # switch to evaluate mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         end = time.time()\n",
    "#         for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#             # compute output\n",
    "#             output = model(images)\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # measure accuracy and record loss\n",
    "#             acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#             losses.update(loss.item(), images.size(0))\n",
    "#             top1.update(acc1[0], images.size(0))\n",
    "#             top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#             # measure elapsed time\n",
    "#             batch_time.update(time.time() - end)\n",
    "#             end = time.time()\n",
    "\n",
    "#             if i % PRINT_FREQ == 0:\n",
    "#                 progress.display(i)\n",
    "\n",
    "#         # TODO: this should also be done with the ProgressMeter\n",
    "#         print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "#               .format(top1=top1, top5=top5))\n",
    "\n",
    "#     return top1.avg\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-cover",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-cross",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informal-tunisia",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fresh-illustration",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rolled-bullet",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "muslim-edition",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advisory-flesh",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "linear-louisiana",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "anticipated-wound",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "organizational-format",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sacred-welsh",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varying-berry",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "detailed-hungary",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])\n",
    "# model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "homeless-ethernet",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-explorer",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "temporal-attachment",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seven-forum",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "painful-badge",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "durable-median",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparable-anderson",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "damaged-genre",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "productive-optimum",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-commercial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "grateful-margin",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spanish-manitoba",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 11.614 (11.614)\tData  4.333 ( 4.333)\tLoss 7.0065e+00 (7.0065e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  10/1282]\tTime  0.839 ( 2.231)\tData  0.105 ( 0.893)\tLoss 6.9203e+00 (6.9694e+00)\tAcc@1   0.60 (  0.22)\tAcc@5   1.80 (  0.71)\n",
      "Epoch: [0][  20/1282]\tTime  0.821 ( 2.046)\tData  0.089 ( 0.986)\tLoss 6.9500e+00 (6.9570e+00)\tAcc@1   0.40 (  0.20)\tAcc@5   1.20 (  0.81)\n",
      "Epoch: [0][  30/1282]\tTime  0.828 ( 1.998)\tData  0.091 ( 1.035)\tLoss 6.7850e+00 (6.9201e+00)\tAcc@1   0.80 (  0.28)\tAcc@5   1.80 (  1.11)\n",
      "Epoch: [0][  40/1282]\tTime  0.839 ( 1.976)\tData  0.095 ( 1.062)\tLoss 6.7368e+00 (6.8854e+00)\tAcc@1   0.80 (  0.39)\tAcc@5   3.40 (  1.41)\n",
      "Epoch: [0][  50/1282]\tTime  0.751 ( 1.970)\tData  0.002 ( 1.086)\tLoss 6.6988e+00 (6.8418e+00)\tAcc@1   0.00 (  0.43)\tAcc@5   1.40 (  1.67)\n",
      "Epoch: [0][  60/1282]\tTime  0.755 ( 1.963)\tData  0.002 ( 1.099)\tLoss 6.5351e+00 (6.7995e+00)\tAcc@1   1.20 (  0.51)\tAcc@5   4.00 (  1.94)\n",
      "Epoch: [0][  70/1282]\tTime  1.279 ( 1.957)\tData  0.002 ( 1.095)\tLoss 6.4549e+00 (6.7528e+00)\tAcc@1   1.20 (  0.61)\tAcc@5   3.20 (  2.27)\n",
      "Epoch: [0][  80/1282]\tTime  0.848 ( 1.949)\tData  0.003 ( 1.073)\tLoss 6.3818e+00 (6.7100e+00)\tAcc@1   0.60 (  0.68)\tAcc@5   3.00 (  2.51)\n",
      "Epoch: [0][  90/1282]\tTime  4.181 ( 1.976)\tData  0.002 ( 1.039)\tLoss 6.4503e+00 (6.6728e+00)\tAcc@1   0.80 (  0.72)\tAcc@5   4.60 (  2.75)\n",
      "Epoch: [0][ 100/1282]\tTime  3.715 ( 2.029)\tData  0.002 ( 0.945)\tLoss 6.1907e+00 (6.6303e+00)\tAcc@1   2.60 (  0.82)\tAcc@5   7.60 (  3.04)\n",
      "Epoch: [0][ 110/1282]\tTime  3.560 ( 2.065)\tData  0.003 ( 0.878)\tLoss 6.1677e+00 (6.5882e+00)\tAcc@1   1.60 (  0.92)\tAcc@5   7.00 (  3.38)\n",
      "Epoch: [0][ 120/1282]\tTime  4.345 ( 2.120)\tData  0.003 ( 0.812)\tLoss 6.1444e+00 (6.5486e+00)\tAcc@1   2.60 (  1.02)\tAcc@5   7.60 (  3.66)\n",
      "Epoch: [0][ 130/1282]\tTime  4.804 ( 2.151)\tData  0.002 ( 0.755)\tLoss 5.9871e+00 (6.5118e+00)\tAcc@1   2.80 (  1.11)\tAcc@5   9.00 (  3.94)\n",
      "Epoch: [0][ 140/1282]\tTime  4.207 ( 2.185)\tData  0.002 ( 0.705)\tLoss 5.8635e+00 (6.4754e+00)\tAcc@1   2.20 (  1.18)\tAcc@5  10.80 (  4.23)\n",
      "Epoch: [0][ 150/1282]\tTime  4.166 ( 2.224)\tData  0.002 ( 0.659)\tLoss 5.8346e+00 (6.4357e+00)\tAcc@1   4.60 (  1.33)\tAcc@5  11.40 (  4.62)\n",
      "Epoch: [0][ 160/1282]\tTime  2.415 ( 2.245)\tData  0.002 ( 0.618)\tLoss 5.8395e+00 (6.3999e+00)\tAcc@1   1.80 (  1.43)\tAcc@5   8.40 (  4.92)\n",
      "Epoch: [0][ 170/1282]\tTime  2.300 ( 2.268)\tData  0.002 ( 0.582)\tLoss 5.7899e+00 (6.3648e+00)\tAcc@1   4.40 (  1.53)\tAcc@5   9.80 (  5.24)\n",
      "Epoch: [0][ 180/1282]\tTime  2.791 ( 2.293)\tData  0.002 ( 0.550)\tLoss 5.6925e+00 (6.3318e+00)\tAcc@1   4.20 (  1.66)\tAcc@5  11.60 (  5.59)\n",
      "Epoch: [0][ 190/1282]\tTime  1.949 ( 2.308)\tData  0.002 ( 0.521)\tLoss 5.7406e+00 (6.3028e+00)\tAcc@1   3.20 (  1.76)\tAcc@5  14.20 (  5.88)\n",
      "Epoch: [0][ 200/1282]\tTime  0.868 ( 2.323)\tData  0.003 ( 0.495)\tLoss 5.6580e+00 (6.2704e+00)\tAcc@1   4.80 (  1.88)\tAcc@5  12.80 (  6.23)\n",
      "Epoch: [0][ 210/1282]\tTime  0.856 ( 2.339)\tData  0.002 ( 0.472)\tLoss 5.6101e+00 (6.2413e+00)\tAcc@1   5.20 (  2.00)\tAcc@5  12.40 (  6.52)\n",
      "Epoch: [0][ 220/1282]\tTime  0.771 ( 2.358)\tData  0.003 ( 0.451)\tLoss 5.5942e+00 (6.2111e+00)\tAcc@1   4.80 (  2.10)\tAcc@5  14.40 (  6.82)\n",
      "Epoch: [0][ 230/1282]\tTime  0.740 ( 2.371)\tData  0.003 ( 0.431)\tLoss 5.5859e+00 (6.1841e+00)\tAcc@1   5.20 (  2.20)\tAcc@5  14.40 (  7.09)\n",
      "Epoch: [0][ 240/1282]\tTime  1.104 ( 2.384)\tData  0.002 ( 0.414)\tLoss 5.5909e+00 (6.1573e+00)\tAcc@1   5.40 (  2.31)\tAcc@5  14.20 (  7.39)\n",
      "Epoch: [0][ 250/1282]\tTime  0.811 ( 2.395)\tData  0.003 ( 0.397)\tLoss 5.3403e+00 (6.1281e+00)\tAcc@1   5.40 (  2.44)\tAcc@5  17.20 (  7.73)\n",
      "Epoch: [0][ 260/1282]\tTime  0.732 ( 2.409)\tData  0.003 ( 0.382)\tLoss 5.4341e+00 (6.0998e+00)\tAcc@1   5.80 (  2.55)\tAcc@5  15.60 (  8.06)\n",
      "Epoch: [0][ 270/1282]\tTime  0.722 ( 2.423)\tData  0.002 ( 0.368)\tLoss 5.4558e+00 (6.0736e+00)\tAcc@1   4.20 (  2.64)\tAcc@5  14.60 (  8.34)\n",
      "Epoch: [0][ 280/1282]\tTime  0.731 ( 2.435)\tData  0.002 ( 0.355)\tLoss 5.4717e+00 (6.0475e+00)\tAcc@1   4.00 (  2.75)\tAcc@5  15.40 (  8.69)\n",
      "Epoch: [0][ 290/1282]\tTime  0.724 ( 2.440)\tData  0.003 ( 0.343)\tLoss 5.2996e+00 (6.0222e+00)\tAcc@1   6.40 (  2.88)\tAcc@5  16.00 (  8.99)\n",
      "Epoch: [0][ 300/1282]\tTime  0.735 ( 2.451)\tData  0.002 ( 0.332)\tLoss 5.1241e+00 (5.9967e+00)\tAcc@1   9.00 (  3.01)\tAcc@5  22.40 (  9.32)\n",
      "Epoch: [0][ 310/1282]\tTime  0.730 ( 2.461)\tData  0.002 ( 0.321)\tLoss 5.1127e+00 (5.9725e+00)\tAcc@1   7.00 (  3.12)\tAcc@5  18.60 (  9.61)\n",
      "Epoch: [0][ 320/1282]\tTime  0.737 ( 2.464)\tData  0.002 ( 0.311)\tLoss 5.1536e+00 (5.9493e+00)\tAcc@1   7.00 (  3.24)\tAcc@5  18.60 (  9.93)\n",
      "Epoch: [0][ 330/1282]\tTime  0.739 ( 2.471)\tData  0.003 ( 0.302)\tLoss 5.0388e+00 (5.9256e+00)\tAcc@1   7.40 (  3.36)\tAcc@5  20.60 ( 10.24)\n",
      "Epoch: [0][ 340/1282]\tTime  0.742 ( 2.475)\tData  0.002 ( 0.293)\tLoss 5.2708e+00 (5.9023e+00)\tAcc@1   5.00 (  3.49)\tAcc@5  17.20 ( 10.55)\n",
      "Epoch: [0][ 350/1282]\tTime  0.743 ( 2.484)\tData  0.002 ( 0.285)\tLoss 5.1773e+00 (5.8802e+00)\tAcc@1   7.00 (  3.61)\tAcc@5  19.80 ( 10.87)\n",
      "Epoch: [0][ 360/1282]\tTime  0.749 ( 2.492)\tData  0.002 ( 0.277)\tLoss 5.0579e+00 (5.8584e+00)\tAcc@1   7.00 (  3.72)\tAcc@5  24.20 ( 11.17)\n",
      "Epoch: [0][ 370/1282]\tTime  0.750 ( 2.503)\tData  0.002 ( 0.269)\tLoss 5.0247e+00 (5.8380e+00)\tAcc@1   5.60 (  3.83)\tAcc@5  21.20 ( 11.45)\n",
      "Epoch: [0][ 380/1282]\tTime  0.751 ( 2.507)\tData  0.003 ( 0.262)\tLoss 5.0014e+00 (5.8174e+00)\tAcc@1   8.00 (  3.93)\tAcc@5  22.00 ( 11.73)\n",
      "Epoch: [0][ 390/1282]\tTime  0.752 ( 2.519)\tData  0.002 ( 0.256)\tLoss 5.1240e+00 (5.7991e+00)\tAcc@1   7.80 (  4.03)\tAcc@5  19.40 ( 11.98)\n",
      "Epoch: [0][ 400/1282]\tTime  0.753 ( 2.532)\tData  0.002 ( 0.250)\tLoss 4.9766e+00 (5.7784e+00)\tAcc@1   8.80 (  4.15)\tAcc@5  24.00 ( 12.27)\n",
      "Epoch: [0][ 410/1282]\tTime  0.753 ( 2.548)\tData  0.002 ( 0.244)\tLoss 5.0660e+00 (5.7584e+00)\tAcc@1   7.80 (  4.26)\tAcc@5  21.20 ( 12.54)\n",
      "Epoch: [0][ 420/1282]\tTime  0.756 ( 2.552)\tData  0.002 ( 0.238)\tLoss 4.9540e+00 (5.7387e+00)\tAcc@1   9.40 (  4.38)\tAcc@5  23.00 ( 12.81)\n",
      "Epoch: [0][ 430/1282]\tTime  0.756 ( 2.555)\tData  0.002 ( 0.232)\tLoss 4.9294e+00 (5.7213e+00)\tAcc@1   9.00 (  4.48)\tAcc@5  24.60 ( 13.06)\n",
      "Epoch: [0][ 440/1282]\tTime  0.758 ( 2.556)\tData  0.002 ( 0.227)\tLoss 4.9002e+00 (5.7026e+00)\tAcc@1   7.60 (  4.58)\tAcc@5  21.60 ( 13.33)\n",
      "Epoch: [0][ 450/1282]\tTime  0.774 ( 2.559)\tData  0.002 ( 0.222)\tLoss 4.7634e+00 (5.6833e+00)\tAcc@1  11.20 (  4.71)\tAcc@5  28.00 ( 13.60)\n",
      "Epoch: [0][ 460/1282]\tTime  0.763 ( 2.561)\tData  0.002 ( 0.217)\tLoss 4.9315e+00 (5.6647e+00)\tAcc@1   7.00 (  4.82)\tAcc@5  24.00 ( 13.88)\n",
      "Epoch: [0][ 470/1282]\tTime  0.761 ( 2.568)\tData  0.003 ( 0.213)\tLoss 4.8060e+00 (5.6470e+00)\tAcc@1   9.60 (  4.93)\tAcc@5  27.20 ( 14.13)\n",
      "Epoch: [0][ 480/1282]\tTime  0.766 ( 2.569)\tData  0.002 ( 0.208)\tLoss 4.7207e+00 (5.6286e+00)\tAcc@1  11.80 (  5.06)\tAcc@5  28.00 ( 14.40)\n",
      "Epoch: [0][ 490/1282]\tTime  0.765 ( 2.575)\tData  0.003 ( 0.204)\tLoss 4.7590e+00 (5.6105e+00)\tAcc@1  12.60 (  5.18)\tAcc@5  27.40 ( 14.67)\n",
      "Epoch: [0][ 500/1282]\tTime  0.762 ( 2.574)\tData  0.002 ( 0.200)\tLoss 4.8751e+00 (5.5928e+00)\tAcc@1  10.40 (  5.29)\tAcc@5  24.60 ( 14.94)\n",
      "Epoch: [0][ 510/1282]\tTime  0.769 ( 2.579)\tData  0.002 ( 0.196)\tLoss 4.7524e+00 (5.5764e+00)\tAcc@1  11.40 (  5.39)\tAcc@5  28.60 ( 15.19)\n",
      "Epoch: [0][ 520/1282]\tTime  0.767 ( 2.583)\tData  0.003 ( 0.193)\tLoss 4.7623e+00 (5.5603e+00)\tAcc@1  12.20 (  5.51)\tAcc@5  27.40 ( 15.43)\n",
      "Epoch: [0][ 530/1282]\tTime  0.766 ( 2.593)\tData  0.002 ( 0.189)\tLoss 4.4799e+00 (5.5438e+00)\tAcc@1  12.80 (  5.63)\tAcc@5  33.20 ( 15.69)\n",
      "Epoch: [0][ 540/1282]\tTime  0.764 ( 2.600)\tData  0.002 ( 0.186)\tLoss 4.7114e+00 (5.5281e+00)\tAcc@1  10.40 (  5.74)\tAcc@5  28.20 ( 15.91)\n",
      "Epoch: [0][ 550/1282]\tTime  0.751 ( 2.601)\tData  0.002 ( 0.182)\tLoss 4.7638e+00 (5.5122e+00)\tAcc@1   9.80 (  5.85)\tAcc@5  26.80 ( 16.17)\n",
      "Epoch: [0][ 560/1282]\tTime  0.737 ( 2.604)\tData  0.003 ( 0.179)\tLoss 4.6205e+00 (5.4956e+00)\tAcc@1  10.80 (  5.98)\tAcc@5  28.60 ( 16.42)\n",
      "Epoch: [0][ 570/1282]\tTime  0.734 ( 2.607)\tData  0.002 ( 0.176)\tLoss 4.4266e+00 (5.4793e+00)\tAcc@1  12.40 (  6.10)\tAcc@5  32.00 ( 16.68)\n",
      "Epoch: [0][ 580/1282]\tTime  0.733 ( 2.613)\tData  0.002 ( 0.173)\tLoss 4.5502e+00 (5.4632e+00)\tAcc@1  14.60 (  6.22)\tAcc@5  32.40 ( 16.94)\n",
      "Epoch: [0][ 590/1282]\tTime  0.739 ( 2.612)\tData  0.002 ( 0.170)\tLoss 4.5577e+00 (5.4471e+00)\tAcc@1  14.00 (  6.34)\tAcc@5  31.40 ( 17.19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 600/1282]\tTime  0.737 ( 2.614)\tData  0.003 ( 0.167)\tLoss 4.6482e+00 (5.4323e+00)\tAcc@1  11.20 (  6.45)\tAcc@5  29.60 ( 17.42)\n",
      "Epoch: [0][ 610/1282]\tTime  0.729 ( 2.614)\tData  0.002 ( 0.165)\tLoss 4.4907e+00 (5.4163e+00)\tAcc@1  14.60 (  6.58)\tAcc@5  31.40 ( 17.68)\n",
      "Epoch: [0][ 620/1282]\tTime  0.726 ( 2.616)\tData  0.002 ( 0.162)\tLoss 4.4576e+00 (5.4010e+00)\tAcc@1  12.80 (  6.70)\tAcc@5  35.80 ( 17.94)\n",
      "Epoch: [0][ 630/1282]\tTime  0.733 ( 2.619)\tData  0.003 ( 0.160)\tLoss 4.4590e+00 (5.3858e+00)\tAcc@1  17.20 (  6.82)\tAcc@5  34.40 ( 18.18)\n",
      "Epoch: [0][ 640/1282]\tTime  0.762 ( 2.619)\tData  0.002 ( 0.158)\tLoss 4.5057e+00 (5.3715e+00)\tAcc@1  12.80 (  6.94)\tAcc@5  33.20 ( 18.41)\n",
      "Epoch: [0][ 650/1282]\tTime  0.752 ( 2.619)\tData  0.002 ( 0.155)\tLoss 4.4400e+00 (5.3564e+00)\tAcc@1  15.00 (  7.05)\tAcc@5  33.80 ( 18.65)\n",
      "Epoch: [0][ 660/1282]\tTime  0.755 ( 2.627)\tData  0.002 ( 0.153)\tLoss 4.4828e+00 (5.3417e+00)\tAcc@1  11.40 (  7.17)\tAcc@5  30.80 ( 18.90)\n",
      "Epoch: [0][ 670/1282]\tTime  0.754 ( 2.630)\tData  0.002 ( 0.151)\tLoss 4.3200e+00 (5.3280e+00)\tAcc@1  13.40 (  7.28)\tAcc@5  32.00 ( 19.11)\n",
      "Epoch: [0][ 680/1282]\tTime  0.757 ( 2.632)\tData  0.003 ( 0.148)\tLoss 4.4067e+00 (5.3148e+00)\tAcc@1  18.00 (  7.39)\tAcc@5  35.20 ( 19.33)\n",
      "Epoch: [0][ 690/1282]\tTime  0.734 ( 2.632)\tData  0.002 ( 0.146)\tLoss 4.2496e+00 (5.3004e+00)\tAcc@1  15.60 (  7.51)\tAcc@5  36.00 ( 19.56)\n",
      "Epoch: [0][ 700/1282]\tTime  0.750 ( 2.639)\tData  0.002 ( 0.144)\tLoss 4.3781e+00 (5.2862e+00)\tAcc@1  14.20 (  7.62)\tAcc@5  34.20 ( 19.80)\n",
      "Epoch: [0][ 710/1282]\tTime  0.759 ( 2.649)\tData  0.002 ( 0.142)\tLoss 4.2270e+00 (5.2723e+00)\tAcc@1  19.40 (  7.74)\tAcc@5  37.60 ( 20.02)\n",
      "Epoch: [0][ 720/1282]\tTime  0.757 ( 2.653)\tData  0.002 ( 0.140)\tLoss 4.2184e+00 (5.2581e+00)\tAcc@1  18.20 (  7.86)\tAcc@5  35.20 ( 20.25)\n",
      "Epoch: [0][ 730/1282]\tTime  0.760 ( 2.658)\tData  0.003 ( 0.138)\tLoss 4.2328e+00 (5.2456e+00)\tAcc@1  15.40 (  7.97)\tAcc@5  37.40 ( 20.46)\n",
      "Epoch: [0][ 740/1282]\tTime  0.767 ( 2.663)\tData  0.002 ( 0.137)\tLoss 4.2279e+00 (5.2325e+00)\tAcc@1  15.80 (  8.09)\tAcc@5  37.20 ( 20.68)\n",
      "Epoch: [0][ 750/1282]\tTime  0.752 ( 2.675)\tData  0.002 ( 0.135)\tLoss 4.4239e+00 (5.2207e+00)\tAcc@1  13.80 (  8.18)\tAcc@5  34.20 ( 20.87)\n",
      "Epoch: [0][ 760/1282]\tTime  0.762 ( 2.683)\tData  0.002 ( 0.133)\tLoss 4.1835e+00 (5.2074e+00)\tAcc@1  17.80 (  8.28)\tAcc@5  40.80 ( 21.09)\n",
      "Epoch: [0][ 770/1282]\tTime  0.732 ( 2.685)\tData  0.002 ( 0.131)\tLoss 4.1891e+00 (5.1947e+00)\tAcc@1  15.40 (  8.40)\tAcc@5  38.20 ( 21.31)\n",
      "Epoch: [0][ 780/1282]\tTime  0.758 ( 2.688)\tData  0.003 ( 0.130)\tLoss 4.1622e+00 (5.1817e+00)\tAcc@1  18.00 (  8.52)\tAcc@5  40.00 ( 21.53)\n",
      "Epoch: [0][ 790/1282]\tTime  0.757 ( 2.691)\tData  0.003 ( 0.128)\tLoss 4.3133e+00 (5.1694e+00)\tAcc@1  14.80 (  8.62)\tAcc@5  33.60 ( 21.73)\n",
      "Epoch: [0][ 800/1282]\tTime  1.346 ( 2.694)\tData  0.002 ( 0.127)\tLoss 4.0258e+00 (5.1565e+00)\tAcc@1  19.40 (  8.74)\tAcc@5  40.40 ( 21.95)\n",
      "Epoch: [0][ 810/1282]\tTime  0.895 ( 2.696)\tData  0.003 ( 0.125)\tLoss 4.1227e+00 (5.1441e+00)\tAcc@1  15.80 (  8.85)\tAcc@5  39.20 ( 22.16)\n",
      "Epoch: [0][ 820/1282]\tTime  1.173 ( 2.696)\tData  0.003 ( 0.124)\tLoss 3.9763e+00 (5.1310e+00)\tAcc@1  18.80 (  8.97)\tAcc@5  41.80 ( 22.39)\n",
      "Epoch: [0][ 830/1282]\tTime  1.962 ( 2.694)\tData  0.002 ( 0.122)\tLoss 3.9901e+00 (5.1188e+00)\tAcc@1  19.20 (  9.08)\tAcc@5  44.80 ( 22.60)\n",
      "Epoch: [0][ 840/1282]\tTime  2.000 ( 2.694)\tData  0.002 ( 0.121)\tLoss 4.1299e+00 (5.1067e+00)\tAcc@1  17.20 (  9.19)\tAcc@5  41.80 ( 22.81)\n",
      "Epoch: [0][ 850/1282]\tTime  1.340 ( 2.693)\tData  0.002 ( 0.119)\tLoss 3.8895e+00 (5.0941e+00)\tAcc@1  21.00 (  9.30)\tAcc@5  44.80 ( 23.03)\n",
      "Epoch: [0][ 860/1282]\tTime  1.617 ( 2.693)\tData  0.002 ( 0.118)\tLoss 4.1926e+00 (5.0815e+00)\tAcc@1  16.40 (  9.42)\tAcc@5  38.00 ( 23.24)\n",
      "Epoch: [0][ 870/1282]\tTime  0.759 ( 2.693)\tData  0.003 ( 0.117)\tLoss 4.0772e+00 (5.0693e+00)\tAcc@1  18.20 (  9.52)\tAcc@5  41.00 ( 23.45)\n",
      "Epoch: [0][ 880/1282]\tTime  0.774 ( 2.694)\tData  0.002 ( 0.115)\tLoss 4.1013e+00 (5.0576e+00)\tAcc@1  17.60 (  9.63)\tAcc@5  40.60 ( 23.65)\n",
      "Epoch: [0][ 890/1282]\tTime  0.762 ( 2.697)\tData  0.002 ( 0.114)\tLoss 4.0541e+00 (5.0459e+00)\tAcc@1  19.40 (  9.74)\tAcc@5  38.00 ( 23.86)\n",
      "Epoch: [0][ 900/1282]\tTime  0.763 ( 2.700)\tData  0.002 ( 0.113)\tLoss 4.0294e+00 (5.0343e+00)\tAcc@1  20.20 (  9.86)\tAcc@5  39.00 ( 24.05)\n",
      "Epoch: [0][ 910/1282]\tTime  0.767 ( 2.700)\tData  0.002 ( 0.112)\tLoss 4.0056e+00 (5.0228e+00)\tAcc@1  19.20 (  9.97)\tAcc@5  40.00 ( 24.25)\n",
      "Epoch: [0][ 920/1282]\tTime  0.737 ( 2.703)\tData  0.002 ( 0.110)\tLoss 4.1676e+00 (5.0115e+00)\tAcc@1  17.40 ( 10.08)\tAcc@5  40.00 ( 24.45)\n",
      "Epoch: [0][ 930/1282]\tTime  0.771 ( 2.703)\tData  0.002 ( 0.109)\tLoss 3.9972e+00 (4.9998e+00)\tAcc@1  16.60 ( 10.19)\tAcc@5  42.60 ( 24.66)\n",
      "Epoch: [0][ 940/1282]\tTime  0.739 ( 2.706)\tData  0.002 ( 0.108)\tLoss 3.9123e+00 (4.9887e+00)\tAcc@1  20.80 ( 10.30)\tAcc@5  43.00 ( 24.85)\n",
      "Epoch: [0][ 950/1282]\tTime  0.760 ( 2.706)\tData  0.002 ( 0.107)\tLoss 3.8549e+00 (4.9778e+00)\tAcc@1  23.20 ( 10.41)\tAcc@5  44.80 ( 25.04)\n",
      "Epoch: [0][ 960/1282]\tTime  0.844 ( 2.707)\tData  0.002 ( 0.106)\tLoss 3.9784e+00 (4.9671e+00)\tAcc@1  21.40 ( 10.52)\tAcc@5  41.00 ( 25.22)\n",
      "Epoch: [0][ 970/1282]\tTime  0.762 ( 2.711)\tData  0.002 ( 0.105)\tLoss 3.9393e+00 (4.9564e+00)\tAcc@1  20.20 ( 10.62)\tAcc@5  43.80 ( 25.41)\n",
      "Epoch: [0][ 980/1282]\tTime  0.764 ( 2.713)\tData  0.002 ( 0.104)\tLoss 3.9556e+00 (4.9454e+00)\tAcc@1  20.20 ( 10.74)\tAcc@5  40.80 ( 25.60)\n",
      "Epoch: [0][ 990/1282]\tTime  0.764 ( 2.717)\tData  0.002 ( 0.103)\tLoss 3.8597e+00 (4.9348e+00)\tAcc@1  22.80 ( 10.84)\tAcc@5  44.00 ( 25.79)\n",
      "Epoch: [0][1000/1282]\tTime  0.741 ( 2.716)\tData  0.002 ( 0.102)\tLoss 3.9559e+00 (4.9242e+00)\tAcc@1  20.80 ( 10.95)\tAcc@5  42.20 ( 25.97)\n",
      "Epoch: [0][1010/1282]\tTime  0.765 ( 2.716)\tData  0.003 ( 0.101)\tLoss 3.8301e+00 (4.9132e+00)\tAcc@1  23.80 ( 11.06)\tAcc@5  45.80 ( 26.17)\n",
      "Epoch: [0][1020/1282]\tTime  0.741 ( 2.715)\tData  0.002 ( 0.100)\tLoss 3.8655e+00 (4.9028e+00)\tAcc@1  20.00 ( 11.17)\tAcc@5  44.00 ( 26.36)\n",
      "Epoch: [0][1030/1282]\tTime  0.742 ( 2.714)\tData  0.003 ( 0.099)\tLoss 3.9445e+00 (4.8925e+00)\tAcc@1  19.40 ( 11.28)\tAcc@5  43.40 ( 26.54)\n",
      "Epoch: [0][1040/1282]\tTime  1.101 ( 2.715)\tData  0.003 ( 0.098)\tLoss 3.9581e+00 (4.8822e+00)\tAcc@1  21.60 ( 11.38)\tAcc@5  43.60 ( 26.72)\n",
      "Epoch: [0][1050/1282]\tTime  0.922 ( 2.716)\tData  0.002 ( 0.097)\tLoss 4.0209e+00 (4.8721e+00)\tAcc@1  20.60 ( 11.48)\tAcc@5  42.40 ( 26.89)\n",
      "Epoch: [0][1060/1282]\tTime  1.266 ( 2.719)\tData  0.003 ( 0.096)\tLoss 3.6131e+00 (4.8616e+00)\tAcc@1  24.80 ( 11.59)\tAcc@5  51.80 ( 27.09)\n",
      "Epoch: [0][1070/1282]\tTime  0.765 ( 2.730)\tData  0.003 ( 0.095)\tLoss 3.9024e+00 (4.8519e+00)\tAcc@1  19.40 ( 11.68)\tAcc@5  44.00 ( 27.25)\n",
      "Epoch: [0][1080/1282]\tTime  0.762 ( 2.742)\tData  0.002 ( 0.095)\tLoss 3.6837e+00 (4.8419e+00)\tAcc@1  22.40 ( 11.79)\tAcc@5  48.20 ( 27.43)\n",
      "Epoch: [0][1090/1282]\tTime  0.765 ( 2.751)\tData  0.002 ( 0.094)\tLoss 3.6984e+00 (4.8320e+00)\tAcc@1  26.40 ( 11.89)\tAcc@5  51.00 ( 27.61)\n",
      "Epoch: [0][1100/1282]\tTime  0.765 ( 2.757)\tData  0.003 ( 0.093)\tLoss 3.6717e+00 (4.8220e+00)\tAcc@1  21.60 ( 12.00)\tAcc@5  50.40 ( 27.79)\n",
      "Epoch: [0][1110/1282]\tTime  0.740 ( 2.756)\tData  0.002 ( 0.092)\tLoss 3.7156e+00 (4.8118e+00)\tAcc@1  21.80 ( 12.11)\tAcc@5  45.80 ( 27.97)\n",
      "Epoch: [0][1120/1282]\tTime  0.764 ( 2.756)\tData  0.003 ( 0.091)\tLoss 3.6256e+00 (4.8018e+00)\tAcc@1  25.00 ( 12.21)\tAcc@5  51.00 ( 28.15)\n",
      "Epoch: [0][1130/1282]\tTime  0.762 ( 2.759)\tData  0.002 ( 0.091)\tLoss 3.6159e+00 (4.7920e+00)\tAcc@1  27.80 ( 12.32)\tAcc@5  49.60 ( 28.32)\n",
      "Epoch: [0][1140/1282]\tTime  0.759 ( 2.759)\tData  0.002 ( 0.090)\tLoss 3.7474e+00 (4.7823e+00)\tAcc@1  21.00 ( 12.42)\tAcc@5  48.00 ( 28.50)\n",
      "Epoch: [0][1150/1282]\tTime  0.761 ( 2.761)\tData  0.002 ( 0.089)\tLoss 3.6019e+00 (4.7726e+00)\tAcc@1  25.20 ( 12.52)\tAcc@5  49.40 ( 28.67)\n",
      "Epoch: [0][1160/1282]\tTime  0.738 ( 2.760)\tData  0.002 ( 0.088)\tLoss 3.5220e+00 (4.7626e+00)\tAcc@1  24.80 ( 12.62)\tAcc@5  49.60 ( 28.84)\n",
      "Epoch: [0][1170/1282]\tTime  0.737 ( 2.763)\tData  0.003 ( 0.088)\tLoss 3.4395e+00 (4.7527e+00)\tAcc@1  28.80 ( 12.72)\tAcc@5  52.20 ( 29.02)\n",
      "Epoch: [0][1180/1282]\tTime  0.740 ( 2.762)\tData  0.002 ( 0.087)\tLoss 3.6857e+00 (4.7430e+00)\tAcc@1  24.00 ( 12.82)\tAcc@5  49.40 ( 29.18)\n",
      "Epoch: [0][1190/1282]\tTime  0.742 ( 2.761)\tData  0.002 ( 0.086)\tLoss 3.6262e+00 (4.7333e+00)\tAcc@1  23.40 ( 12.93)\tAcc@5  50.60 ( 29.36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1200/1282]\tTime  0.722 ( 2.760)\tData  0.002 ( 0.085)\tLoss 3.4807e+00 (4.7241e+00)\tAcc@1  28.40 ( 13.03)\tAcc@5  53.60 ( 29.53)\n",
      "Epoch: [0][1210/1282]\tTime  0.719 ( 2.759)\tData  0.002 ( 0.085)\tLoss 3.5992e+00 (4.7146e+00)\tAcc@1  24.40 ( 13.13)\tAcc@5  48.20 ( 29.70)\n",
      "Epoch: [0][1220/1282]\tTime  0.732 ( 2.760)\tData  0.002 ( 0.084)\tLoss 3.5245e+00 (4.7053e+00)\tAcc@1  27.80 ( 13.24)\tAcc@5  48.00 ( 29.87)\n",
      "Epoch: [0][1230/1282]\tTime  0.736 ( 2.761)\tData  0.003 ( 0.083)\tLoss 3.6226e+00 (4.6962e+00)\tAcc@1  24.20 ( 13.33)\tAcc@5  49.60 ( 30.03)\n",
      "Epoch: [0][1240/1282]\tTime  0.730 ( 2.759)\tData  0.002 ( 0.083)\tLoss 3.7131e+00 (4.6869e+00)\tAcc@1  24.80 ( 13.44)\tAcc@5  47.60 ( 30.20)\n",
      "Epoch: [0][1250/1282]\tTime  0.745 ( 2.759)\tData  0.002 ( 0.082)\tLoss 3.5407e+00 (4.6777e+00)\tAcc@1  26.00 ( 13.54)\tAcc@5  51.40 ( 30.36)\n",
      "Epoch: [0][1260/1282]\tTime  0.753 ( 2.759)\tData  0.002 ( 0.082)\tLoss 3.3935e+00 (4.6687e+00)\tAcc@1  27.60 ( 13.64)\tAcc@5  54.40 ( 30.52)\n",
      "Epoch: [0][1270/1282]\tTime  0.734 ( 2.757)\tData  0.003 ( 0.081)\tLoss 3.4548e+00 (4.6596e+00)\tAcc@1  27.60 ( 13.73)\tAcc@5  51.40 ( 30.68)\n",
      "Epoch: [0][1280/1282]\tTime  0.737 ( 2.757)\tData  0.002 ( 0.080)\tLoss 3.5603e+00 (4.6505e+00)\tAcc@1  26.20 ( 13.84)\tAcc@5  49.20 ( 30.85)\n",
      "Test: [0/3]\tTime  9.525 ( 9.525)\tLoss 3.9357e+00 (3.9357e+00)\tAcc@1  20.60 ( 20.60)\tAcc@5  43.80 ( 43.80)\n",
      " * Acc@1 20.579 Acc@5 43.457\n",
      "lr: [0.0]\n",
      "Epoch: [1][   0/1282]\tTime  7.290 ( 7.290)\tData  5.123 ( 5.123)\tLoss 3.5285e+00 (3.5285e+00)\tAcc@1  27.00 ( 27.00)\tAcc@5  52.60 ( 52.60)\n",
      "Epoch: [1][  10/1282]\tTime  5.108 ( 3.077)\tData  0.485 ( 1.035)\tLoss 3.7801e+00 (3.5245e+00)\tAcc@1  22.40 ( 26.53)\tAcc@5  45.60 ( 50.24)\n",
      "Epoch: [1][  20/1282]\tTime  4.873 ( 2.952)\tData  0.002 ( 0.544)\tLoss 3.4785e+00 (3.5154e+00)\tAcc@1  27.40 ( 26.61)\tAcc@5  50.20 ( 50.52)\n",
      "Epoch: [1][  30/1282]\tTime  4.598 ( 2.892)\tData  0.002 ( 0.369)\tLoss 3.5198e+00 (3.5277e+00)\tAcc@1  24.00 ( 26.39)\tAcc@5  52.20 ( 50.53)\n",
      "Epoch: [1][  40/1282]\tTime  3.657 ( 2.835)\tData  0.002 ( 0.280)\tLoss 3.5689e+00 (3.5433e+00)\tAcc@1  27.00 ( 26.15)\tAcc@5  51.40 ( 50.33)\n",
      "Epoch: [1][  50/1282]\tTime  4.806 ( 2.824)\tData  0.002 ( 0.225)\tLoss 3.6443e+00 (3.5431e+00)\tAcc@1  25.00 ( 26.08)\tAcc@5  49.60 ( 50.29)\n",
      "Epoch: [1][  60/1282]\tTime  4.605 ( 2.800)\tData  0.002 ( 0.189)\tLoss 3.5480e+00 (3.5393e+00)\tAcc@1  28.40 ( 26.26)\tAcc@5  53.80 ( 50.51)\n",
      "Epoch: [1][  70/1282]\tTime  4.838 ( 2.781)\tData  0.003 ( 0.163)\tLoss 3.5120e+00 (3.5405e+00)\tAcc@1  26.60 ( 26.25)\tAcc@5  51.20 ( 50.52)\n",
      "Epoch: [1][  80/1282]\tTime  4.454 ( 2.775)\tData  0.002 ( 0.143)\tLoss 3.6077e+00 (3.5452e+00)\tAcc@1  25.40 ( 26.18)\tAcc@5  47.60 ( 50.46)\n",
      "Epoch: [1][  90/1282]\tTime  4.710 ( 2.764)\tData  0.003 ( 0.127)\tLoss 3.4117e+00 (3.5447e+00)\tAcc@1  28.60 ( 26.18)\tAcc@5  54.60 ( 50.42)\n",
      "Epoch: [1][ 100/1282]\tTime  6.250 ( 2.787)\tData  0.003 ( 0.115)\tLoss 3.5432e+00 (3.5433e+00)\tAcc@1  28.00 ( 26.14)\tAcc@5  50.40 ( 50.44)\n",
      "Epoch: [1][ 110/1282]\tTime  6.216 ( 2.800)\tData  0.002 ( 0.105)\tLoss 3.4250e+00 (3.5438e+00)\tAcc@1  26.40 ( 26.12)\tAcc@5  52.60 ( 50.41)\n",
      "Epoch: [1][ 120/1282]\tTime  4.649 ( 2.801)\tData  0.002 ( 0.096)\tLoss 3.6435e+00 (3.5439e+00)\tAcc@1  23.60 ( 26.13)\tAcc@5  48.80 ( 50.43)\n",
      "Epoch: [1][ 130/1282]\tTime  5.312 ( 2.796)\tData  0.002 ( 0.089)\tLoss 3.5622e+00 (3.5464e+00)\tAcc@1  25.60 ( 26.07)\tAcc@5  53.80 ( 50.40)\n",
      "Epoch: [1][ 140/1282]\tTime  4.743 ( 2.788)\tData  0.002 ( 0.083)\tLoss 3.4494e+00 (3.5404e+00)\tAcc@1  25.20 ( 26.12)\tAcc@5  50.80 ( 50.53)\n",
      "Epoch: [1][ 150/1282]\tTime  5.717 ( 2.797)\tData  0.002 ( 0.078)\tLoss 3.5540e+00 (3.5386e+00)\tAcc@1  26.60 ( 26.20)\tAcc@5  52.40 ( 50.63)\n",
      "Epoch: [1][ 160/1282]\tTime  4.361 ( 2.792)\tData  0.002 ( 0.073)\tLoss 3.4697e+00 (3.5384e+00)\tAcc@1  25.60 ( 26.14)\tAcc@5  50.00 ( 50.62)\n",
      "Epoch: [1][ 170/1282]\tTime  3.846 ( 2.772)\tData  0.002 ( 0.069)\tLoss 3.5997e+00 (3.5374e+00)\tAcc@1  26.00 ( 26.17)\tAcc@5  47.00 ( 50.61)\n",
      "Epoch: [1][ 180/1282]\tTime  4.240 ( 2.764)\tData  0.002 ( 0.065)\tLoss 3.4454e+00 (3.5363e+00)\tAcc@1  25.20 ( 26.19)\tAcc@5  50.00 ( 50.63)\n",
      "Epoch: [1][ 190/1282]\tTime  4.273 ( 2.758)\tData  0.003 ( 0.062)\tLoss 3.5406e+00 (3.5377e+00)\tAcc@1  23.00 ( 26.19)\tAcc@5  53.40 ( 50.63)\n",
      "Epoch: [1][ 200/1282]\tTime  3.500 ( 2.752)\tData  0.003 ( 0.059)\tLoss 3.5054e+00 (3.5384e+00)\tAcc@1  26.60 ( 26.16)\tAcc@5  48.00 ( 50.64)\n",
      "Epoch: [1][ 210/1282]\tTime  2.995 ( 2.744)\tData  0.003 ( 0.056)\tLoss 3.6038e+00 (3.5390e+00)\tAcc@1  24.20 ( 26.18)\tAcc@5  48.60 ( 50.62)\n",
      "Epoch: [1][ 220/1282]\tTime  3.137 ( 2.749)\tData  0.002 ( 0.054)\tLoss 3.6860e+00 (3.5384e+00)\tAcc@1  24.20 ( 26.18)\tAcc@5  48.20 ( 50.66)\n",
      "Epoch: [1][ 230/1282]\tTime  2.981 ( 2.742)\tData  0.002 ( 0.052)\tLoss 3.5107e+00 (3.5382e+00)\tAcc@1  24.20 ( 26.15)\tAcc@5  50.60 ( 50.67)\n",
      "Epoch: [1][ 240/1282]\tTime  4.085 ( 2.742)\tData  0.003 ( 0.050)\tLoss 3.6073e+00 (3.5388e+00)\tAcc@1  28.20 ( 26.14)\tAcc@5  48.80 ( 50.64)\n",
      "Epoch: [1][ 250/1282]\tTime  3.720 ( 2.740)\tData  0.002 ( 0.048)\tLoss 3.4300e+00 (3.5358e+00)\tAcc@1  26.80 ( 26.19)\tAcc@5  53.00 ( 50.70)\n",
      "Epoch: [1][ 260/1282]\tTime  2.829 ( 2.739)\tData  0.002 ( 0.046)\tLoss 3.4536e+00 (3.5329e+00)\tAcc@1  28.40 ( 26.22)\tAcc@5  52.80 ( 50.76)\n",
      "Epoch: [1][ 270/1282]\tTime  2.944 ( 2.741)\tData  0.002 ( 0.044)\tLoss 3.5277e+00 (3.5317e+00)\tAcc@1  28.00 ( 26.25)\tAcc@5  53.00 ( 50.81)\n",
      "Epoch: [1][ 280/1282]\tTime  3.149 ( 2.742)\tData  0.002 ( 0.043)\tLoss 3.7382e+00 (3.5312e+00)\tAcc@1  20.80 ( 26.27)\tAcc@5  47.20 ( 50.84)\n",
      "Epoch: [1][ 290/1282]\tTime  3.198 ( 2.746)\tData  0.002 ( 0.042)\tLoss 3.6585e+00 (3.5304e+00)\tAcc@1  26.00 ( 26.29)\tAcc@5  47.20 ( 50.85)\n",
      "Epoch: [1][ 300/1282]\tTime  2.128 ( 2.738)\tData  0.002 ( 0.040)\tLoss 3.5709e+00 (3.5316e+00)\tAcc@1  25.80 ( 26.28)\tAcc@5  49.20 ( 50.82)\n",
      "Epoch: [1][ 310/1282]\tTime  1.914 ( 2.737)\tData  0.002 ( 0.039)\tLoss 3.3796e+00 (3.5313e+00)\tAcc@1  26.40 ( 26.30)\tAcc@5  52.40 ( 50.83)\n",
      "Epoch: [1][ 320/1282]\tTime  0.746 ( 2.746)\tData  0.002 ( 0.038)\tLoss 3.4860e+00 (3.5325e+00)\tAcc@1  25.60 ( 26.27)\tAcc@5  51.20 ( 50.80)\n",
      "Epoch: [1][ 330/1282]\tTime  1.101 ( 2.741)\tData  0.002 ( 0.037)\tLoss 3.4603e+00 (3.5333e+00)\tAcc@1  27.40 ( 26.28)\tAcc@5  51.60 ( 50.78)\n",
      "Epoch: [1][ 340/1282]\tTime  0.945 ( 2.740)\tData  0.003 ( 0.036)\tLoss 3.4528e+00 (3.5314e+00)\tAcc@1  27.80 ( 26.32)\tAcc@5  49.40 ( 50.80)\n",
      "Epoch: [1][ 350/1282]\tTime  0.761 ( 2.745)\tData  0.003 ( 0.035)\tLoss 3.6622e+00 (3.5308e+00)\tAcc@1  27.00 ( 26.34)\tAcc@5  46.80 ( 50.83)\n",
      "Epoch: [1][ 360/1282]\tTime  0.758 ( 2.751)\tData  0.002 ( 0.034)\tLoss 3.6012e+00 (3.5309e+00)\tAcc@1  24.20 ( 26.34)\tAcc@5  49.20 ( 50.81)\n",
      "Epoch: [1][ 370/1282]\tTime  0.753 ( 2.762)\tData  0.002 ( 0.033)\tLoss 3.4570e+00 (3.5316e+00)\tAcc@1  28.00 ( 26.35)\tAcc@5  52.00 ( 50.78)\n",
      "Epoch: [1][ 380/1282]\tTime  0.739 ( 2.762)\tData  0.002 ( 0.032)\tLoss 3.5400e+00 (3.5317e+00)\tAcc@1  27.20 ( 26.36)\tAcc@5  53.00 ( 50.79)\n",
      "Epoch: [1][ 390/1282]\tTime  0.738 ( 2.757)\tData  0.002 ( 0.032)\tLoss 3.6427e+00 (3.5329e+00)\tAcc@1  26.00 ( 26.34)\tAcc@5  48.40 ( 50.76)\n",
      "Epoch: [1][ 400/1282]\tTime  0.761 ( 2.759)\tData  0.003 ( 0.031)\tLoss 3.6873e+00 (3.5318e+00)\tAcc@1  24.60 ( 26.35)\tAcc@5  48.60 ( 50.77)\n",
      "Epoch: [1][ 410/1282]\tTime  0.753 ( 2.765)\tData  0.002 ( 0.030)\tLoss 3.6410e+00 (3.5314e+00)\tAcc@1  23.40 ( 26.34)\tAcc@5  48.20 ( 50.79)\n",
      "Epoch: [1][ 420/1282]\tTime  0.757 ( 2.772)\tData  0.003 ( 0.029)\tLoss 3.4804e+00 (3.5310e+00)\tAcc@1  27.60 ( 26.33)\tAcc@5  50.80 ( 50.80)\n",
      "Epoch: [1][ 430/1282]\tTime  0.753 ( 2.780)\tData  0.003 ( 0.029)\tLoss 3.5633e+00 (3.5318e+00)\tAcc@1  24.80 ( 26.32)\tAcc@5  51.40 ( 50.79)\n",
      "Epoch: [1][ 440/1282]\tTime  0.759 ( 2.778)\tData  0.002 ( 0.028)\tLoss 3.6095e+00 (3.5314e+00)\tAcc@1  26.40 ( 26.33)\tAcc@5  50.80 ( 50.81)\n",
      "Epoch: [1][ 450/1282]\tTime  0.730 ( 2.776)\tData  0.002 ( 0.028)\tLoss 3.5194e+00 (3.5311e+00)\tAcc@1  27.00 ( 26.35)\tAcc@5  51.40 ( 50.82)\n",
      "Epoch: [1][ 460/1282]\tTime  0.761 ( 2.781)\tData  0.002 ( 0.027)\tLoss 3.4489e+00 (3.5303e+00)\tAcc@1  26.40 ( 26.37)\tAcc@5  53.40 ( 50.86)\n",
      "Epoch: [1][ 470/1282]\tTime  0.735 ( 2.783)\tData  0.002 ( 0.027)\tLoss 3.3854e+00 (3.5301e+00)\tAcc@1  27.20 ( 26.36)\tAcc@5  54.00 ( 50.86)\n",
      "Epoch: [1][ 480/1282]\tTime  0.756 ( 2.782)\tData  0.002 ( 0.026)\tLoss 3.5006e+00 (3.5298e+00)\tAcc@1  26.80 ( 26.34)\tAcc@5  49.80 ( 50.86)\n",
      "Epoch: [1][ 490/1282]\tTime  0.761 ( 2.787)\tData  0.003 ( 0.026)\tLoss 3.4596e+00 (3.5293e+00)\tAcc@1  28.40 ( 26.36)\tAcc@5  52.60 ( 50.87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][ 500/1282]\tTime  0.751 ( 2.795)\tData  0.002 ( 0.025)\tLoss 3.6589e+00 (3.5291e+00)\tAcc@1  27.00 ( 26.35)\tAcc@5  50.60 ( 50.87)\n",
      "Epoch: [1][ 510/1282]\tTime  0.755 ( 2.797)\tData  0.003 ( 0.025)\tLoss 3.5254e+00 (3.5291e+00)\tAcc@1  25.40 ( 26.34)\tAcc@5  52.20 ( 50.86)\n",
      "Epoch: [1][ 520/1282]\tTime  0.754 ( 2.799)\tData  0.003 ( 0.024)\tLoss 3.4425e+00 (3.5283e+00)\tAcc@1  27.80 ( 26.37)\tAcc@5  53.60 ( 50.87)\n",
      "Epoch: [1][ 530/1282]\tTime  0.760 ( 2.800)\tData  0.002 ( 0.024)\tLoss 3.4030e+00 (3.5283e+00)\tAcc@1  28.60 ( 26.38)\tAcc@5  52.40 ( 50.88)\n",
      "Epoch: [1][ 540/1282]\tTime  0.754 ( 2.802)\tData  0.002 ( 0.023)\tLoss 3.4854e+00 (3.5280e+00)\tAcc@1  27.60 ( 26.37)\tAcc@5  53.00 ( 50.89)\n",
      "Epoch: [1][ 550/1282]\tTime  0.762 ( 2.804)\tData  0.003 ( 0.023)\tLoss 3.6626e+00 (3.5281e+00)\tAcc@1  25.60 ( 26.37)\tAcc@5  49.20 ( 50.90)\n",
      "Epoch: [1][ 560/1282]\tTime  0.762 ( 2.804)\tData  0.003 ( 0.023)\tLoss 3.5031e+00 (3.5280e+00)\tAcc@1  25.80 ( 26.38)\tAcc@5  51.00 ( 50.89)\n",
      "Epoch: [1][ 570/1282]\tTime  0.764 ( 2.800)\tData  0.002 ( 0.022)\tLoss 3.5164e+00 (3.5284e+00)\tAcc@1  26.60 ( 26.36)\tAcc@5  52.20 ( 50.89)\n",
      "Epoch: [1][ 580/1282]\tTime  0.761 ( 2.799)\tData  0.002 ( 0.022)\tLoss 3.5303e+00 (3.5283e+00)\tAcc@1  26.80 ( 26.35)\tAcc@5  54.40 ( 50.89)\n",
      "Epoch: [1][ 590/1282]\tTime  0.763 ( 2.796)\tData  0.002 ( 0.022)\tLoss 3.4316e+00 (3.5273e+00)\tAcc@1  27.80 ( 26.37)\tAcc@5  52.40 ( 50.92)\n",
      "Epoch: [1][ 600/1282]\tTime  0.760 ( 2.794)\tData  0.003 ( 0.021)\tLoss 3.7183e+00 (3.5273e+00)\tAcc@1  21.60 ( 26.37)\tAcc@5  47.20 ( 50.91)\n",
      "Epoch: [1][ 610/1282]\tTime  0.760 ( 2.797)\tData  0.002 ( 0.021)\tLoss 3.5312e+00 (3.5265e+00)\tAcc@1  27.60 ( 26.38)\tAcc@5  49.60 ( 50.92)\n",
      "Epoch: [1][ 620/1282]\tTime  0.763 ( 2.800)\tData  0.002 ( 0.021)\tLoss 3.4866e+00 (3.5264e+00)\tAcc@1  27.40 ( 26.39)\tAcc@5  51.20 ( 50.91)\n",
      "Epoch: [1][ 630/1282]\tTime  0.761 ( 2.805)\tData  0.003 ( 0.020)\tLoss 3.5662e+00 (3.5261e+00)\tAcc@1  28.40 ( 26.40)\tAcc@5  51.60 ( 50.92)\n",
      "Epoch: [1][ 640/1282]\tTime  0.740 ( 2.810)\tData  0.002 ( 0.020)\tLoss 3.6051e+00 (3.5259e+00)\tAcc@1  28.00 ( 26.40)\tAcc@5  50.20 ( 50.93)\n",
      "Epoch: [1][ 650/1282]\tTime  0.743 ( 2.811)\tData  0.003 ( 0.020)\tLoss 3.3932e+00 (3.5249e+00)\tAcc@1  26.60 ( 26.40)\tAcc@5  55.00 ( 50.95)\n",
      "Epoch: [1][ 660/1282]\tTime  0.756 ( 2.818)\tData  0.002 ( 0.020)\tLoss 3.5953e+00 (3.5239e+00)\tAcc@1  24.80 ( 26.41)\tAcc@5  49.40 ( 50.97)\n",
      "Epoch: [1][ 670/1282]\tTime  0.759 ( 2.818)\tData  0.003 ( 0.019)\tLoss 3.4068e+00 (3.5236e+00)\tAcc@1  28.80 ( 26.42)\tAcc@5  53.60 ( 50.97)\n",
      "Epoch: [1][ 680/1282]\tTime  0.756 ( 2.821)\tData  0.002 ( 0.019)\tLoss 3.5567e+00 (3.5238e+00)\tAcc@1  24.80 ( 26.41)\tAcc@5  49.00 ( 50.97)\n",
      "Epoch: [1][ 690/1282]\tTime  0.759 ( 2.823)\tData  0.002 ( 0.019)\tLoss 3.3216e+00 (3.5229e+00)\tAcc@1  30.80 ( 26.41)\tAcc@5  54.40 ( 50.99)\n",
      "Epoch: [1][ 700/1282]\tTime  0.762 ( 2.823)\tData  0.003 ( 0.019)\tLoss 3.5919e+00 (3.5230e+00)\tAcc@1  24.80 ( 26.41)\tAcc@5  50.00 ( 50.97)\n",
      "Epoch: [1][ 710/1282]\tTime  0.757 ( 2.826)\tData  0.002 ( 0.018)\tLoss 3.3992e+00 (3.5225e+00)\tAcc@1  26.20 ( 26.42)\tAcc@5  51.40 ( 50.98)\n",
      "Epoch: [1][ 720/1282]\tTime  0.757 ( 2.828)\tData  0.002 ( 0.018)\tLoss 3.4971e+00 (3.5215e+00)\tAcc@1  25.40 ( 26.43)\tAcc@5  49.00 ( 50.99)\n",
      "Epoch: [1][ 730/1282]\tTime  0.769 ( 2.831)\tData  0.002 ( 0.018)\tLoss 3.5925e+00 (3.5221e+00)\tAcc@1  24.20 ( 26.42)\tAcc@5  48.20 ( 50.97)\n",
      "Epoch: [1][ 740/1282]\tTime  0.757 ( 2.830)\tData  0.002 ( 0.018)\tLoss 3.5836e+00 (3.5219e+00)\tAcc@1  26.20 ( 26.42)\tAcc@5  49.20 ( 50.98)\n",
      "Epoch: [1][ 750/1282]\tTime  0.756 ( 2.830)\tData  0.002 ( 0.018)\tLoss 3.6780e+00 (3.5228e+00)\tAcc@1  22.40 ( 26.40)\tAcc@5  47.80 ( 50.97)\n",
      "Epoch: [1][ 760/1282]\tTime  0.763 ( 2.829)\tData  0.002 ( 0.017)\tLoss 3.4518e+00 (3.5220e+00)\tAcc@1  28.20 ( 26.40)\tAcc@5  50.20 ( 50.98)\n",
      "Epoch: [1][ 770/1282]\tTime  0.795 ( 2.832)\tData  0.002 ( 0.017)\tLoss 3.4249e+00 (3.5219e+00)\tAcc@1  26.60 ( 26.40)\tAcc@5  50.20 ( 50.98)\n",
      "Epoch: [1][ 780/1282]\tTime  0.767 ( 2.829)\tData  0.002 ( 0.017)\tLoss 3.4733e+00 (3.5216e+00)\tAcc@1  26.40 ( 26.40)\tAcc@5  49.40 ( 50.98)\n",
      "Epoch: [1][ 790/1282]\tTime  0.762 ( 2.829)\tData  0.002 ( 0.017)\tLoss 3.6474e+00 (3.5215e+00)\tAcc@1  22.40 ( 26.39)\tAcc@5  47.20 ( 50.97)\n",
      "Epoch: [1][ 800/1282]\tTime  0.773 ( 2.827)\tData  0.002 ( 0.017)\tLoss 3.3507e+00 (3.5208e+00)\tAcc@1  27.00 ( 26.40)\tAcc@5  53.60 ( 50.99)\n",
      "Epoch: [1][ 810/1282]\tTime  0.764 ( 2.826)\tData  0.002 ( 0.017)\tLoss 3.5127e+00 (3.5206e+00)\tAcc@1  23.80 ( 26.39)\tAcc@5  49.80 ( 50.99)\n",
      "Epoch: [1][ 820/1282]\tTime  0.849 ( 2.824)\tData  0.091 ( 0.017)\tLoss 3.3744e+00 (3.5193e+00)\tAcc@1  31.20 ( 26.41)\tAcc@5  53.00 ( 51.01)\n",
      "Epoch: [1][ 830/1282]\tTime  0.765 ( 2.822)\tData  0.002 ( 0.017)\tLoss 3.3292e+00 (3.5192e+00)\tAcc@1  28.20 ( 26.40)\tAcc@5  54.80 ( 51.02)\n",
      "Epoch: [1][ 840/1282]\tTime  0.761 ( 2.824)\tData  0.002 ( 0.017)\tLoss 3.4753e+00 (3.5185e+00)\tAcc@1  26.00 ( 26.41)\tAcc@5  50.40 ( 51.03)\n",
      "Epoch: [1][ 850/1282]\tTime  0.763 ( 2.828)\tData  0.002 ( 0.017)\tLoss 3.2485e+00 (3.5178e+00)\tAcc@1  30.00 ( 26.43)\tAcc@5  58.20 ( 51.05)\n",
      "Epoch: [1][ 860/1282]\tTime  0.760 ( 2.830)\tData  0.003 ( 0.016)\tLoss 3.7025e+00 (3.5171e+00)\tAcc@1  24.20 ( 26.43)\tAcc@5  49.00 ( 51.06)\n",
      "Epoch: [1][ 870/1282]\tTime  0.762 ( 2.833)\tData  0.002 ( 0.016)\tLoss 3.4697e+00 (3.5165e+00)\tAcc@1  27.60 ( 26.44)\tAcc@5  52.40 ( 51.07)\n",
      "Epoch: [1][ 880/1282]\tTime  0.759 ( 2.839)\tData  0.002 ( 0.016)\tLoss 3.4213e+00 (3.5163e+00)\tAcc@1  28.60 ( 26.43)\tAcc@5  56.00 ( 51.08)\n",
      "Epoch: [1][ 890/1282]\tTime  0.757 ( 2.843)\tData  0.002 ( 0.016)\tLoss 3.4962e+00 (3.5158e+00)\tAcc@1  27.80 ( 26.44)\tAcc@5  51.20 ( 51.09)\n",
      "Epoch: [1][ 900/1282]\tTime  0.757 ( 2.845)\tData  0.002 ( 0.016)\tLoss 3.4334e+00 (3.5152e+00)\tAcc@1  27.60 ( 26.45)\tAcc@5  52.20 ( 51.10)\n",
      "Epoch: [1][ 910/1282]\tTime  0.761 ( 2.847)\tData  0.003 ( 0.016)\tLoss 3.4222e+00 (3.5147e+00)\tAcc@1  26.00 ( 26.45)\tAcc@5  52.80 ( 51.11)\n",
      "Epoch: [1][ 920/1282]\tTime  0.762 ( 2.848)\tData  0.003 ( 0.016)\tLoss 3.5951e+00 (3.5145e+00)\tAcc@1  24.80 ( 26.44)\tAcc@5  48.40 ( 51.12)\n",
      "Epoch: [1][ 930/1282]\tTime  0.759 ( 2.849)\tData  0.002 ( 0.015)\tLoss 3.5344e+00 (3.5138e+00)\tAcc@1  25.60 ( 26.44)\tAcc@5  47.80 ( 51.14)\n",
      "Epoch: [1][ 940/1282]\tTime  0.761 ( 2.849)\tData  0.002 ( 0.015)\tLoss 3.4877e+00 (3.5136e+00)\tAcc@1  28.20 ( 26.46)\tAcc@5  51.40 ( 51.14)\n",
      "Epoch: [1][ 950/1282]\tTime  0.760 ( 2.850)\tData  0.002 ( 0.015)\tLoss 3.3882e+00 (3.5132e+00)\tAcc@1  27.20 ( 26.47)\tAcc@5  51.80 ( 51.15)\n",
      "Epoch: [1][ 960/1282]\tTime  0.765 ( 2.850)\tData  0.003 ( 0.015)\tLoss 3.5530e+00 (3.5127e+00)\tAcc@1  29.20 ( 26.48)\tAcc@5  49.80 ( 51.16)\n",
      "Epoch: [1][ 970/1282]\tTime  0.758 ( 2.855)\tData  0.002 ( 0.015)\tLoss 3.5005e+00 (3.5125e+00)\tAcc@1  26.80 ( 26.48)\tAcc@5  50.40 ( 51.16)\n",
      "Epoch: [1][ 980/1282]\tTime  0.766 ( 2.861)\tData  0.003 ( 0.015)\tLoss 3.6020e+00 (3.5122e+00)\tAcc@1  24.60 ( 26.49)\tAcc@5  46.60 ( 51.16)\n",
      "Epoch: [1][ 990/1282]\tTime  0.772 ( 2.866)\tData  0.002 ( 0.015)\tLoss 3.3873e+00 (3.5117e+00)\tAcc@1  30.80 ( 26.50)\tAcc@5  56.20 ( 51.17)\n",
      "Epoch: [1][1000/1282]\tTime  0.752 ( 2.863)\tData  0.002 ( 0.015)\tLoss 3.5632e+00 (3.5114e+00)\tAcc@1  24.60 ( 26.51)\tAcc@5  51.60 ( 51.18)\n",
      "Epoch: [1][1010/1282]\tTime  0.753 ( 2.860)\tData  0.002 ( 0.014)\tLoss 3.4862e+00 (3.5109e+00)\tAcc@1  26.00 ( 26.52)\tAcc@5  53.80 ( 51.18)\n",
      "Epoch: [1][1020/1282]\tTime  0.755 ( 2.856)\tData  0.003 ( 0.014)\tLoss 3.5102e+00 (3.5105e+00)\tAcc@1  23.80 ( 26.52)\tAcc@5  47.80 ( 51.18)\n",
      "Epoch: [1][1030/1282]\tTime  0.757 ( 2.852)\tData  0.002 ( 0.014)\tLoss 3.4906e+00 (3.5102e+00)\tAcc@1  26.40 ( 26.53)\tAcc@5  53.60 ( 51.19)\n",
      "Epoch: [1][1040/1282]\tTime  0.759 ( 2.849)\tData  0.002 ( 0.014)\tLoss 3.6135e+00 (3.5098e+00)\tAcc@1  26.00 ( 26.54)\tAcc@5  50.20 ( 51.20)\n",
      "Epoch: [1][1050/1282]\tTime  0.765 ( 2.846)\tData  0.003 ( 0.014)\tLoss 3.6174e+00 (3.5093e+00)\tAcc@1  26.20 ( 26.55)\tAcc@5  50.20 ( 51.22)\n",
      "Epoch: [1][1060/1282]\tTime  0.766 ( 2.844)\tData  0.002 ( 0.014)\tLoss 3.3037e+00 (3.5085e+00)\tAcc@1  30.60 ( 26.56)\tAcc@5  55.00 ( 51.23)\n",
      "Epoch: [1][1070/1282]\tTime  0.760 ( 2.842)\tData  0.002 ( 0.014)\tLoss 3.4330e+00 (3.5080e+00)\tAcc@1  25.60 ( 26.56)\tAcc@5  53.00 ( 51.25)\n",
      "Epoch: [1][1080/1282]\tTime  0.783 ( 2.842)\tData  0.003 ( 0.014)\tLoss 3.3331e+00 (3.5074e+00)\tAcc@1  30.00 ( 26.57)\tAcc@5  54.80 ( 51.25)\n",
      "Epoch: [1][1090/1282]\tTime  0.763 ( 2.840)\tData  0.003 ( 0.014)\tLoss 3.3653e+00 (3.5065e+00)\tAcc@1  28.80 ( 26.58)\tAcc@5  55.20 ( 51.27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1100/1282]\tTime  0.767 ( 2.838)\tData  0.002 ( 0.013)\tLoss 3.3363e+00 (3.5058e+00)\tAcc@1  26.40 ( 26.59)\tAcc@5  54.80 ( 51.29)\n",
      "Epoch: [1][1110/1282]\tTime  0.761 ( 2.834)\tData  0.002 ( 0.013)\tLoss 3.3862e+00 (3.5046e+00)\tAcc@1  30.80 ( 26.61)\tAcc@5  52.20 ( 51.30)\n",
      "Epoch: [1][1120/1282]\tTime  0.769 ( 2.834)\tData  0.003 ( 0.013)\tLoss 3.3897e+00 (3.5037e+00)\tAcc@1  29.80 ( 26.63)\tAcc@5  52.00 ( 51.32)\n",
      "Epoch: [1][1130/1282]\tTime  0.795 ( 2.833)\tData  0.002 ( 0.013)\tLoss 3.2934e+00 (3.5030e+00)\tAcc@1  31.20 ( 26.64)\tAcc@5  56.60 ( 51.33)\n",
      "Epoch: [1][1140/1282]\tTime  0.801 ( 2.830)\tData  0.003 ( 0.013)\tLoss 3.4520e+00 (3.5023e+00)\tAcc@1  25.60 ( 26.65)\tAcc@5  53.60 ( 51.35)\n",
      "Epoch: [1][1150/1282]\tTime  0.766 ( 2.829)\tData  0.002 ( 0.013)\tLoss 3.3893e+00 (3.5014e+00)\tAcc@1  25.20 ( 26.65)\tAcc@5  54.60 ( 51.37)\n",
      "Epoch: [1][1160/1282]\tTime  0.770 ( 2.827)\tData  0.003 ( 0.013)\tLoss 3.3760e+00 (3.5000e+00)\tAcc@1  28.80 ( 26.67)\tAcc@5  50.40 ( 51.39)\n",
      "Epoch: [1][1170/1282]\tTime  0.764 ( 2.829)\tData  0.002 ( 0.013)\tLoss 3.2471e+00 (3.4989e+00)\tAcc@1  30.60 ( 26.68)\tAcc@5  54.20 ( 51.41)\n",
      "Epoch: [1][1180/1282]\tTime  0.753 ( 2.832)\tData  0.002 ( 0.013)\tLoss 3.4782e+00 (3.4976e+00)\tAcc@1  26.80 ( 26.70)\tAcc@5  51.80 ( 51.43)\n",
      "Epoch: [1][1190/1282]\tTime  0.728 ( 2.832)\tData  0.002 ( 0.013)\tLoss 3.3801e+00 (3.4961e+00)\tAcc@1  29.00 ( 26.72)\tAcc@5  53.20 ( 51.45)\n",
      "Epoch: [1][1200/1282]\tTime  0.725 ( 2.829)\tData  0.002 ( 0.013)\tLoss 3.1797e+00 (3.4949e+00)\tAcc@1  32.80 ( 26.74)\tAcc@5  57.60 ( 51.48)\n",
      "Epoch: [1][1210/1282]\tTime  0.746 ( 2.827)\tData  0.003 ( 0.012)\tLoss 3.3498e+00 (3.4936e+00)\tAcc@1  28.60 ( 26.77)\tAcc@5  53.20 ( 51.50)\n",
      "Epoch: [1][1220/1282]\tTime  0.737 ( 2.826)\tData  0.002 ( 0.012)\tLoss 3.3587e+00 (3.4926e+00)\tAcc@1  27.80 ( 26.79)\tAcc@5  54.40 ( 51.53)\n",
      "Epoch: [1][1230/1282]\tTime  0.754 ( 2.827)\tData  0.002 ( 0.012)\tLoss 3.4135e+00 (3.4912e+00)\tAcc@1  29.60 ( 26.81)\tAcc@5  53.60 ( 51.55)\n",
      "Epoch: [1][1240/1282]\tTime  0.749 ( 2.829)\tData  0.002 ( 0.012)\tLoss 3.4050e+00 (3.4896e+00)\tAcc@1  26.40 ( 26.83)\tAcc@5  53.20 ( 51.58)\n",
      "Epoch: [1][1250/1282]\tTime  0.753 ( 2.833)\tData  0.002 ( 0.012)\tLoss 3.2927e+00 (3.4878e+00)\tAcc@1  29.40 ( 26.86)\tAcc@5  55.00 ( 51.63)\n",
      "Epoch: [1][1260/1282]\tTime  0.739 ( 2.832)\tData  0.003 ( 0.012)\tLoss 3.1872e+00 (3.4861e+00)\tAcc@1  31.60 ( 26.88)\tAcc@5  57.20 ( 51.66)\n",
      "Epoch: [1][1270/1282]\tTime  0.739 ( 2.831)\tData  0.002 ( 0.012)\tLoss 3.0901e+00 (3.4839e+00)\tAcc@1  34.80 ( 26.91)\tAcc@5  59.40 ( 51.71)\n",
      "Epoch: [1][1280/1282]\tTime  0.739 ( 2.830)\tData  0.002 ( 0.012)\tLoss 3.3340e+00 (3.4812e+00)\tAcc@1  29.60 ( 26.96)\tAcc@5  51.60 ( 51.75)\n",
      "Test: [0/3]\tTime  6.539 ( 6.539)\tLoss 3.3160e+00 (3.3160e+00)\tAcc@1  27.60 ( 27.60)\tAcc@5  56.00 ( 56.00)\n",
      " * Acc@1 25.974 Acc@5 51.349\n",
      "lr: [0.1]\n",
      "CPU times: user 3h 3min 13s, sys: 49min 42s, total: 3h 52min 55s\n",
      "Wall time: 1h 59min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "russian-european",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25910), started 0:35:09 ago. (Use '!kill 25910' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d2e931e9977bf15d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d2e931e9977bf15d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "governmental-columbia",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a373bfdf166413fa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a373bfdf166413fa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-soccer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
