{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-mounting",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modular-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stone-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decreased-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: wandb in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.12.6)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: pathtools in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.18.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwwblodge1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "discrete-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/250aodi4\" target=\"_blank\">feasible-butterfly-38</a></strong> to <a href=\"https://wandb.ai/wwblodge1/hw9_instance\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/hw9_instance/runs/250aodi4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0bde0095d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"hw9_instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-mortality",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "# Assume that this notebook only sees one GPU.\n",
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-mixer",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-commonwealth",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-morgan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "departmental-listing",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-hammer",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 1\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\"\n",
    "\n",
    "global_step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-elite",
   "metadata": {
    "id": "85299ee3"
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confused-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:250aodi4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3419... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">feasible-butterfly-38</strong>: <a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/250aodi4\" target=\"_blank\">https://wandb.ai/wwblodge1/hw9_instance/runs/250aodi4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211119_221136-250aodi4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:250aodi4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/uncategorized/runs/166lekgd\" target=\"_blank\">breezy-bird-19</a></strong> to <a href=\"https://wandb.ai/wwblodge1/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/uncategorized/runs/166lekgd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0bdc76d850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-eugene",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many processes in cluster?\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "# where is the master?\n",
    "# export NCCL_SOCKET_IFNAME=172.31.24.47\n",
    "URL = 'tcp://172.31.24.176:1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is my rank?\n",
    "RANK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-melbourne",
   "metadata": {
    "id": "68491838"
   },
   "outputs": [],
   "source": [
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "disturbed-swimming",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device('cpu')\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mineral-gibson",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-fireplace",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "# def train(train_loader, model, criterion, optimizer, epoch):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     data_time = AverageMeter('Data', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(train_loader),\n",
    "#         [batch_time, data_time, losses, top1, top5],\n",
    "#         prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "#     # switch to train mode\n",
    "#     model.train()\n",
    "\n",
    "#     end = time.time()\n",
    "#     for i, (images, target) in enumerate(train_loader):\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # measure accuracy and record loss\n",
    "#         acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#         losses.update(loss.item(), images.size(0))\n",
    "#         top1.update(acc1[0], images.size(0))\n",
    "#         top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if i % PRINT_FREQ == 0:\n",
    "#             progress.display(i)\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-cathedral",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "# def validate(val_loader, model, criterion):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(val_loader),\n",
    "#         [batch_time, losses, top1, top5],\n",
    "#         prefix='Test: ')\n",
    "\n",
    "#     # switch to evaluate mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         end = time.time()\n",
    "#         for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#             # compute output\n",
    "#             output = model(images)\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # measure accuracy and record loss\n",
    "#             acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#             losses.update(loss.item(), images.size(0))\n",
    "#             top1.update(acc1[0], images.size(0))\n",
    "#             top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#             # measure elapsed time\n",
    "#             batch_time.update(time.time() - end)\n",
    "#             end = time.time()\n",
    "\n",
    "#             if i % PRINT_FREQ == 0:\n",
    "#                 progress.display(i)\n",
    "\n",
    "#         # TODO: this should also be done with the ProgressMeter\n",
    "#         print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "#               .format(top1=top1, top5=top5))\n",
    "\n",
    "#     return top1.avg\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-cover",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-cross",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informal-tunisia",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fresh-illustration",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rolled-bullet",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "muslim-edition",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advisory-flesh",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "linear-louisiana",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "anticipated-wound",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "organizational-format",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sacred-welsh",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varying-berry",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "detailed-hungary",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])\n",
    "# model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "homeless-ethernet",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-explorer",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "temporal-attachment",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seven-forum",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "painful-badge",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "durable-median",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparable-anderson",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "damaged-genre",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "productive-optimum",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-commercial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "grateful-margin",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spanish-manitoba",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 15.564 (15.564)\tData  5.567 ( 5.567)\tLoss 7.0065e+00 (7.0065e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  10/1282]\tTime  1.944 ( 2.992)\tData  0.091 ( 1.107)\tLoss 6.9282e+00 (6.9693e+00)\tAcc@1   0.40 (  0.11)\tAcc@5   1.40 (  0.73)\n",
      "Epoch: [0][  20/1282]\tTime  1.097 ( 2.694)\tData  0.002 ( 1.165)\tLoss 6.9623e+00 (6.9565e+00)\tAcc@1   0.60 (  0.17)\tAcc@5   1.20 (  0.90)\n",
      "Epoch: [0][  30/1282]\tTime  0.822 ( 2.624)\tData  0.002 ( 1.337)\tLoss 6.8046e+00 (6.9236e+00)\tAcc@1   0.60 (  0.24)\tAcc@5   1.40 (  1.08)\n",
      "Epoch: [0][  40/1282]\tTime  0.811 ( 2.572)\tData  0.002 ( 1.397)\tLoss 6.7398e+00 (6.8891e+00)\tAcc@1   0.40 (  0.36)\tAcc@5   3.20 (  1.38)\n",
      "Epoch: [0][  50/1282]\tTime  1.526 ( 2.576)\tData  0.003 ( 1.457)\tLoss 6.6891e+00 (6.8465e+00)\tAcc@1   0.20 (  0.42)\tAcc@5   1.40 (  1.60)\n",
      "Epoch: [0][  60/1282]\tTime  1.480 ( 2.563)\tData  0.002 ( 1.431)\tLoss 6.5479e+00 (6.8035e+00)\tAcc@1   1.20 (  0.48)\tAcc@5   3.20 (  1.88)\n",
      "Epoch: [0][  70/1282]\tTime  2.114 ( 2.562)\tData  0.002 ( 1.418)\tLoss 6.4185e+00 (6.7557e+00)\tAcc@1   0.80 (  0.60)\tAcc@5   4.00 (  2.24)\n",
      "Epoch: [0][  80/1282]\tTime  2.938 ( 2.559)\tData  0.002 ( 1.340)\tLoss 6.3431e+00 (6.7106e+00)\tAcc@1   0.40 (  0.67)\tAcc@5   3.80 (  2.50)\n",
      "Epoch: [0][  90/1282]\tTime  3.485 ( 2.543)\tData  0.002 ( 1.237)\tLoss 6.4333e+00 (6.6704e+00)\tAcc@1   1.20 (  0.74)\tAcc@5   5.00 (  2.76)\n",
      "Epoch: [0][ 100/1282]\tTime  3.999 ( 2.536)\tData  0.003 ( 1.127)\tLoss 6.1824e+00 (6.6279e+00)\tAcc@1   2.20 (  0.84)\tAcc@5   7.60 (  3.04)\n",
      "Epoch: [0][ 110/1282]\tTime  3.680 ( 2.534)\tData  0.003 ( 1.028)\tLoss 6.1601e+00 (6.5878e+00)\tAcc@1   1.80 (  0.95)\tAcc@5   6.40 (  3.37)\n",
      "Epoch: [0][ 120/1282]\tTime  3.943 ( 2.538)\tData  0.002 ( 0.944)\tLoss 6.2053e+00 (6.5506e+00)\tAcc@1   2.00 (  1.03)\tAcc@5   6.80 (  3.65)\n",
      "Epoch: [0][ 130/1282]\tTime  3.548 ( 2.537)\tData  0.002 ( 0.874)\tLoss 6.0243e+00 (6.5170e+00)\tAcc@1   3.20 (  1.13)\tAcc@5   9.20 (  3.92)\n",
      "Epoch: [0][ 140/1282]\tTime  2.639 ( 2.531)\tData  0.003 ( 0.813)\tLoss 5.8809e+00 (6.4819e+00)\tAcc@1   2.40 (  1.21)\tAcc@5   8.00 (  4.20)\n",
      "Epoch: [0][ 150/1282]\tTime  2.226 ( 2.528)\tData  0.003 ( 0.759)\tLoss 5.8128e+00 (6.4427e+00)\tAcc@1   4.60 (  1.34)\tAcc@5   9.20 (  4.54)\n",
      "Epoch: [0][ 160/1282]\tTime  1.596 ( 2.524)\tData  0.002 ( 0.712)\tLoss 5.8439e+00 (6.4081e+00)\tAcc@1   1.20 (  1.44)\tAcc@5   8.00 (  4.84)\n",
      "Epoch: [0][ 170/1282]\tTime  1.495 ( 2.520)\tData  0.003 ( 0.670)\tLoss 5.7877e+00 (6.3735e+00)\tAcc@1   3.00 (  1.53)\tAcc@5   8.20 (  5.13)\n",
      "Epoch: [0][ 180/1282]\tTime  0.834 ( 2.520)\tData  0.002 ( 0.634)\tLoss 5.7639e+00 (6.3411e+00)\tAcc@1   4.20 (  1.65)\tAcc@5  11.80 (  5.48)\n",
      "Epoch: [0][ 190/1282]\tTime  0.750 ( 2.522)\tData  0.002 ( 0.601)\tLoss 5.8059e+00 (6.3131e+00)\tAcc@1   3.20 (  1.73)\tAcc@5   9.40 (  5.74)\n",
      "Epoch: [0][ 200/1282]\tTime  0.749 ( 2.526)\tData  0.002 ( 0.571)\tLoss 5.6260e+00 (6.2809e+00)\tAcc@1   5.00 (  1.86)\tAcc@5  13.60 (  6.08)\n",
      "Epoch: [0][ 210/1282]\tTime  0.750 ( 2.524)\tData  0.002 ( 0.544)\tLoss 5.6373e+00 (6.2521e+00)\tAcc@1   5.00 (  1.97)\tAcc@5  13.80 (  6.39)\n",
      "Epoch: [0][ 220/1282]\tTime  0.763 ( 2.526)\tData  0.002 ( 0.519)\tLoss 5.6966e+00 (6.2232e+00)\tAcc@1   4.00 (  2.07)\tAcc@5  13.00 (  6.67)\n",
      "Epoch: [0][ 230/1282]\tTime  0.748 ( 2.524)\tData  0.002 ( 0.497)\tLoss 5.5940e+00 (6.1966e+00)\tAcc@1   4.20 (  2.15)\tAcc@5  14.60 (  6.93)\n",
      "Epoch: [0][ 240/1282]\tTime  0.744 ( 2.518)\tData  0.002 ( 0.476)\tLoss 5.6503e+00 (6.1702e+00)\tAcc@1   6.20 (  2.27)\tAcc@5  14.40 (  7.21)\n",
      "Epoch: [0][ 250/1282]\tTime  0.781 ( 2.517)\tData  0.002 ( 0.458)\tLoss 5.3492e+00 (6.1419e+00)\tAcc@1   5.00 (  2.40)\tAcc@5  16.80 (  7.50)\n",
      "Epoch: [0][ 260/1282]\tTime  0.748 ( 2.515)\tData  0.002 ( 0.440)\tLoss 5.4627e+00 (6.1143e+00)\tAcc@1   5.80 (  2.52)\tAcc@5  15.40 (  7.81)\n",
      "Epoch: [0][ 270/1282]\tTime  0.749 ( 2.510)\tData  0.003 ( 0.424)\tLoss 5.4979e+00 (6.0890e+00)\tAcc@1   5.20 (  2.62)\tAcc@5  14.80 (  8.10)\n",
      "Epoch: [0][ 280/1282]\tTime  0.774 ( 2.506)\tData  0.002 ( 0.410)\tLoss 5.5013e+00 (6.0630e+00)\tAcc@1   3.40 (  2.72)\tAcc@5  13.00 (  8.41)\n",
      "Epoch: [0][ 290/1282]\tTime  0.750 ( 2.503)\tData  0.002 ( 0.396)\tLoss 5.2897e+00 (6.0371e+00)\tAcc@1   6.80 (  2.85)\tAcc@5  17.80 (  8.73)\n",
      "Epoch: [0][ 300/1282]\tTime  0.835 ( 2.498)\tData  0.090 ( 0.385)\tLoss 5.1320e+00 (6.0120e+00)\tAcc@1   8.80 (  2.98)\tAcc@5  22.00 (  9.05)\n",
      "Epoch: [0][ 310/1282]\tTime  0.747 ( 2.495)\tData  0.002 ( 0.373)\tLoss 5.1657e+00 (5.9879e+00)\tAcc@1   5.60 (  3.10)\tAcc@5  17.40 (  9.34)\n",
      "Epoch: [0][ 320/1282]\tTime  0.836 ( 2.493)\tData  0.087 ( 0.363)\tLoss 5.1647e+00 (5.9645e+00)\tAcc@1   6.60 (  3.22)\tAcc@5  18.20 (  9.66)\n",
      "Epoch: [0][ 330/1282]\tTime  0.929 ( 2.491)\tData  0.182 ( 0.355)\tLoss 5.0307e+00 (5.9413e+00)\tAcc@1   8.40 (  3.33)\tAcc@5  23.00 (  9.97)\n",
      "Epoch: [0][ 340/1282]\tTime  0.838 ( 2.489)\tData  0.090 ( 0.347)\tLoss 5.2415e+00 (5.9189e+00)\tAcc@1   5.60 (  3.45)\tAcc@5  19.00 ( 10.28)\n",
      "Epoch: [0][ 350/1282]\tTime  0.946 ( 2.488)\tData  0.178 ( 0.339)\tLoss 5.1788e+00 (5.8967e+00)\tAcc@1   5.00 (  3.56)\tAcc@5  20.80 ( 10.59)\n",
      "Epoch: [0][ 360/1282]\tTime  0.774 ( 2.486)\tData  0.002 ( 0.330)\tLoss 5.0921e+00 (5.8749e+00)\tAcc@1   9.60 (  3.68)\tAcc@5  23.60 ( 10.89)\n",
      "Epoch: [0][ 370/1282]\tTime  0.832 ( 2.484)\tData  0.088 ( 0.322)\tLoss 5.0144e+00 (5.8540e+00)\tAcc@1   7.20 (  3.81)\tAcc@5  21.00 ( 11.19)\n",
      "Epoch: [0][ 380/1282]\tTime  0.930 ( 2.482)\tData  0.184 ( 0.315)\tLoss 4.9971e+00 (5.8335e+00)\tAcc@1   8.60 (  3.91)\tAcc@5  23.00 ( 11.48)\n",
      "Epoch: [0][ 390/1282]\tTime  0.925 ( 2.480)\tData  0.181 ( 0.309)\tLoss 5.0973e+00 (5.8146e+00)\tAcc@1   8.20 (  4.01)\tAcc@5  22.20 ( 11.73)\n",
      "Epoch: [0][ 400/1282]\tTime  0.845 ( 2.479)\tData  0.096 ( 0.303)\tLoss 5.0363e+00 (5.7934e+00)\tAcc@1   8.20 (  4.13)\tAcc@5  23.40 ( 12.04)\n",
      "Epoch: [0][ 410/1282]\tTime  0.928 ( 2.477)\tData  0.178 ( 0.298)\tLoss 5.0012e+00 (5.7733e+00)\tAcc@1   9.20 (  4.24)\tAcc@5  21.80 ( 12.33)\n",
      "Epoch: [0][ 420/1282]\tTime  0.771 ( 2.477)\tData  0.003 ( 0.291)\tLoss 4.9643e+00 (5.7537e+00)\tAcc@1   8.60 (  4.36)\tAcc@5  23.40 ( 12.61)\n",
      "Epoch: [0][ 430/1282]\tTime  0.859 ( 2.475)\tData  0.090 ( 0.285)\tLoss 4.9940e+00 (5.7358e+00)\tAcc@1   9.80 (  4.46)\tAcc@5  25.00 ( 12.86)\n",
      "Epoch: [0][ 440/1282]\tTime  0.837 ( 2.472)\tData  0.091 ( 0.280)\tLoss 4.9445e+00 (5.7172e+00)\tAcc@1   8.80 (  4.57)\tAcc@5  23.60 ( 13.13)\n",
      "Epoch: [0][ 450/1282]\tTime  0.747 ( 2.472)\tData  0.002 ( 0.274)\tLoss 4.8064e+00 (5.6980e+00)\tAcc@1  11.00 (  4.70)\tAcc@5  27.20 ( 13.42)\n",
      "Epoch: [0][ 460/1282]\tTime  0.748 ( 2.472)\tData  0.002 ( 0.268)\tLoss 4.8956e+00 (5.6793e+00)\tAcc@1   9.00 (  4.81)\tAcc@5  23.40 ( 13.69)\n",
      "Epoch: [0][ 470/1282]\tTime  0.749 ( 2.473)\tData  0.002 ( 0.263)\tLoss 4.8250e+00 (5.6617e+00)\tAcc@1   9.20 (  4.92)\tAcc@5  24.80 ( 13.94)\n",
      "Epoch: [0][ 480/1282]\tTime  0.773 ( 2.474)\tData  0.002 ( 0.257)\tLoss 4.6999e+00 (5.6430e+00)\tAcc@1  11.00 (  5.04)\tAcc@5  28.80 ( 14.22)\n",
      "Epoch: [0][ 490/1282]\tTime  0.836 ( 2.472)\tData  0.087 ( 0.252)\tLoss 4.7455e+00 (5.6251e+00)\tAcc@1  12.80 (  5.17)\tAcc@5  27.60 ( 14.48)\n",
      "Epoch: [0][ 500/1282]\tTime  0.749 ( 2.470)\tData  0.002 ( 0.248)\tLoss 4.8258e+00 (5.6070e+00)\tAcc@1  10.20 (  5.29)\tAcc@5  26.40 ( 14.76)\n",
      "Epoch: [0][ 510/1282]\tTime  0.834 ( 2.470)\tData  0.092 ( 0.244)\tLoss 4.7780e+00 (5.5894e+00)\tAcc@1  12.00 (  5.40)\tAcc@5  29.00 ( 15.04)\n",
      "Epoch: [0][ 520/1282]\tTime  0.751 ( 2.470)\tData  0.003 ( 0.240)\tLoss 4.7149e+00 (5.5723e+00)\tAcc@1  12.60 (  5.52)\tAcc@5  27.80 ( 15.30)\n",
      "Epoch: [0][ 530/1282]\tTime  0.774 ( 2.473)\tData  0.002 ( 0.235)\tLoss 4.5364e+00 (5.5558e+00)\tAcc@1  11.80 (  5.64)\tAcc@5  33.00 ( 15.56)\n",
      "Epoch: [0][ 540/1282]\tTime  0.783 ( 2.474)\tData  0.002 ( 0.231)\tLoss 4.7382e+00 (5.5399e+00)\tAcc@1  11.40 (  5.74)\tAcc@5  27.80 ( 15.79)\n",
      "Epoch: [0][ 550/1282]\tTime  0.781 ( 2.474)\tData  0.002 ( 0.227)\tLoss 4.7410e+00 (5.5236e+00)\tAcc@1  12.20 (  5.86)\tAcc@5  27.20 ( 16.06)\n",
      "Epoch: [0][ 560/1282]\tTime  0.750 ( 2.473)\tData  0.003 ( 0.223)\tLoss 4.5894e+00 (5.5069e+00)\tAcc@1  12.00 (  5.98)\tAcc@5  30.00 ( 16.32)\n",
      "Epoch: [0][ 570/1282]\tTime  0.749 ( 2.474)\tData  0.002 ( 0.219)\tLoss 4.4392e+00 (5.4907e+00)\tAcc@1  11.60 (  6.10)\tAcc@5  32.60 ( 16.57)\n",
      "Epoch: [0][ 580/1282]\tTime  0.748 ( 2.476)\tData  0.002 ( 0.215)\tLoss 4.6260e+00 (5.4745e+00)\tAcc@1  14.00 (  6.22)\tAcc@5  30.80 ( 16.81)\n",
      "Epoch: [0][ 590/1282]\tTime  0.775 ( 2.477)\tData  0.002 ( 0.212)\tLoss 4.5158e+00 (5.4584e+00)\tAcc@1  12.60 (  6.34)\tAcc@5  30.60 ( 17.07)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 600/1282]\tTime  0.748 ( 2.479)\tData  0.002 ( 0.208)\tLoss 4.6287e+00 (5.4434e+00)\tAcc@1  10.40 (  6.45)\tAcc@5  31.60 ( 17.31)\n",
      "Epoch: [0][ 610/1282]\tTime  0.777 ( 2.480)\tData  0.003 ( 0.205)\tLoss 4.5133e+00 (5.4279e+00)\tAcc@1  14.20 (  6.57)\tAcc@5  31.60 ( 17.56)\n",
      "Epoch: [0][ 620/1282]\tTime  0.767 ( 2.483)\tData  0.002 ( 0.202)\tLoss 4.4886e+00 (5.4126e+00)\tAcc@1  13.80 (  6.70)\tAcc@5  34.20 ( 17.81)\n",
      "Epoch: [0][ 630/1282]\tTime  0.764 ( 2.485)\tData  0.003 ( 0.198)\tLoss 4.4832e+00 (5.3972e+00)\tAcc@1  14.80 (  6.82)\tAcc@5  35.40 ( 18.06)\n",
      "Epoch: [0][ 640/1282]\tTime  0.762 ( 2.486)\tData  0.003 ( 0.195)\tLoss 4.4837e+00 (5.3828e+00)\tAcc@1  13.40 (  6.93)\tAcc@5  34.00 ( 18.30)\n",
      "Epoch: [0][ 650/1282]\tTime  0.741 ( 2.485)\tData  0.003 ( 0.192)\tLoss 4.4382e+00 (5.3677e+00)\tAcc@1  14.00 (  7.05)\tAcc@5  35.40 ( 18.55)\n",
      "Epoch: [0][ 660/1282]\tTime  0.736 ( 2.485)\tData  0.002 ( 0.190)\tLoss 4.4752e+00 (5.3526e+00)\tAcc@1  12.40 (  7.16)\tAcc@5  32.20 ( 18.79)\n",
      "Epoch: [0][ 670/1282]\tTime  0.762 ( 2.486)\tData  0.003 ( 0.187)\tLoss 4.3618e+00 (5.3382e+00)\tAcc@1  13.20 (  7.28)\tAcc@5  32.00 ( 19.02)\n",
      "Epoch: [0][ 680/1282]\tTime  0.770 ( 2.487)\tData  0.002 ( 0.184)\tLoss 4.4093e+00 (5.3247e+00)\tAcc@1  17.60 (  7.39)\tAcc@5  37.80 ( 19.23)\n",
      "Epoch: [0][ 690/1282]\tTime  0.737 ( 2.489)\tData  0.003 ( 0.181)\tLoss 4.2166e+00 (5.3100e+00)\tAcc@1  16.80 (  7.51)\tAcc@5  35.20 ( 19.47)\n",
      "Epoch: [0][ 700/1282]\tTime  0.768 ( 2.491)\tData  0.002 ( 0.179)\tLoss 4.3278e+00 (5.2956e+00)\tAcc@1  16.60 (  7.63)\tAcc@5  36.80 ( 19.71)\n",
      "Epoch: [0][ 710/1282]\tTime  0.772 ( 2.493)\tData  0.002 ( 0.176)\tLoss 4.2906e+00 (5.2815e+00)\tAcc@1  16.40 (  7.74)\tAcc@5  38.00 ( 19.94)\n",
      "Epoch: [0][ 720/1282]\tTime  0.829 ( 2.493)\tData  0.090 ( 0.174)\tLoss 4.2480e+00 (5.2672e+00)\tAcc@1  16.80 (  7.86)\tAcc@5  35.00 ( 20.17)\n",
      "Epoch: [0][ 730/1282]\tTime  0.828 ( 2.493)\tData  0.092 ( 0.173)\tLoss 4.1997e+00 (5.2544e+00)\tAcc@1  16.20 (  7.97)\tAcc@5  35.00 ( 20.38)\n",
      "Epoch: [0][ 740/1282]\tTime  0.824 ( 2.492)\tData  0.091 ( 0.171)\tLoss 4.2940e+00 (5.2415e+00)\tAcc@1  14.80 (  8.08)\tAcc@5  35.60 ( 20.60)\n",
      "Epoch: [0][ 750/1282]\tTime  0.905 ( 2.493)\tData  0.177 ( 0.170)\tLoss 4.3950e+00 (5.2295e+00)\tAcc@1  14.20 (  8.17)\tAcc@5  35.00 ( 20.79)\n",
      "Epoch: [0][ 760/1282]\tTime  0.913 ( 2.493)\tData  0.176 ( 0.169)\tLoss 4.1134e+00 (5.2158e+00)\tAcc@1  18.80 (  8.28)\tAcc@5  38.60 ( 21.02)\n",
      "Epoch: [0][ 770/1282]\tTime  0.744 ( 2.494)\tData  0.003 ( 0.168)\tLoss 4.1547e+00 (5.2027e+00)\tAcc@1  16.40 (  8.39)\tAcc@5  37.60 ( 21.24)\n",
      "Epoch: [0][ 780/1282]\tTime  0.740 ( 2.494)\tData  0.002 ( 0.165)\tLoss 4.1639e+00 (5.1897e+00)\tAcc@1  17.60 (  8.50)\tAcc@5  38.60 ( 21.45)\n",
      "Epoch: [0][ 790/1282]\tTime  0.735 ( 2.495)\tData  0.002 ( 0.163)\tLoss 4.3012e+00 (5.1769e+00)\tAcc@1  13.40 (  8.61)\tAcc@5  35.60 ( 21.66)\n",
      "Epoch: [0][ 800/1282]\tTime  0.766 ( 2.495)\tData  0.003 ( 0.161)\tLoss 4.0145e+00 (5.1637e+00)\tAcc@1  19.40 (  8.73)\tAcc@5  40.00 ( 21.89)\n",
      "Epoch: [0][ 810/1282]\tTime  0.735 ( 2.494)\tData  0.002 ( 0.159)\tLoss 4.1867e+00 (5.1512e+00)\tAcc@1  15.80 (  8.84)\tAcc@5  37.60 ( 22.10)\n",
      "Epoch: [0][ 820/1282]\tTime  0.763 ( 2.492)\tData  0.002 ( 0.158)\tLoss 3.9892e+00 (5.1380e+00)\tAcc@1  19.40 (  8.95)\tAcc@5  42.60 ( 22.32)\n",
      "Epoch: [0][ 830/1282]\tTime  0.741 ( 2.490)\tData  0.002 ( 0.156)\tLoss 3.9719e+00 (5.1257e+00)\tAcc@1  19.80 (  9.06)\tAcc@5  43.20 ( 22.53)\n",
      "Epoch: [0][ 840/1282]\tTime  0.739 ( 2.489)\tData  0.003 ( 0.154)\tLoss 4.0293e+00 (5.1131e+00)\tAcc@1  19.60 (  9.18)\tAcc@5  42.80 ( 22.74)\n",
      "Epoch: [0][ 850/1282]\tTime  0.764 ( 2.488)\tData  0.002 ( 0.152)\tLoss 3.9157e+00 (5.1000e+00)\tAcc@1  19.00 (  9.29)\tAcc@5  42.40 ( 22.97)\n",
      "Epoch: [0][ 860/1282]\tTime  0.741 ( 2.488)\tData  0.002 ( 0.150)\tLoss 4.1447e+00 (5.0872e+00)\tAcc@1  17.00 (  9.40)\tAcc@5  39.20 ( 23.18)\n",
      "Epoch: [0][ 870/1282]\tTime  0.742 ( 2.487)\tData  0.002 ( 0.149)\tLoss 4.0470e+00 (5.0748e+00)\tAcc@1  21.60 (  9.51)\tAcc@5  43.00 ( 23.39)\n",
      "Epoch: [0][ 880/1282]\tTime  0.830 ( 2.486)\tData  0.094 ( 0.147)\tLoss 4.0583e+00 (5.0629e+00)\tAcc@1  21.00 (  9.62)\tAcc@5  41.00 ( 23.60)\n",
      "Epoch: [0][ 890/1282]\tTime  0.836 ( 2.486)\tData  0.093 ( 0.146)\tLoss 3.9858e+00 (5.0509e+00)\tAcc@1  21.40 (  9.73)\tAcc@5  39.60 ( 23.80)\n",
      "Epoch: [0][ 900/1282]\tTime  0.953 ( 2.486)\tData  0.208 ( 0.145)\tLoss 3.9638e+00 (5.0390e+00)\tAcc@1  20.80 (  9.86)\tAcc@5  42.00 ( 24.01)\n",
      "Epoch: [0][ 910/1282]\tTime  0.929 ( 2.484)\tData  0.185 ( 0.145)\tLoss 4.0080e+00 (5.0272e+00)\tAcc@1  19.20 (  9.97)\tAcc@5  39.60 ( 24.21)\n",
      "Epoch: [0][ 920/1282]\tTime  0.927 ( 2.483)\tData  0.182 ( 0.144)\tLoss 4.1209e+00 (5.0154e+00)\tAcc@1  19.20 ( 10.08)\tAcc@5  40.60 ( 24.41)\n",
      "Epoch: [0][ 930/1282]\tTime  0.933 ( 2.481)\tData  0.186 ( 0.143)\tLoss 4.0176e+00 (5.0035e+00)\tAcc@1  16.60 ( 10.18)\tAcc@5  40.80 ( 24.61)\n",
      "Epoch: [0][ 940/1282]\tTime  0.926 ( 2.481)\tData  0.181 ( 0.143)\tLoss 3.9250e+00 (4.9922e+00)\tAcc@1  21.80 ( 10.30)\tAcc@5  45.00 ( 24.81)\n",
      "Epoch: [0][ 950/1282]\tTime  1.320 ( 2.481)\tData  0.573 ( 0.144)\tLoss 3.8140e+00 (4.9811e+00)\tAcc@1  23.40 ( 10.41)\tAcc@5  43.60 ( 25.00)\n",
      "Epoch: [0][ 960/1282]\tTime  3.691 ( 2.482)\tData  2.897 ( 0.153)\tLoss 3.9761e+00 (4.9702e+00)\tAcc@1  21.00 ( 10.53)\tAcc@5  41.60 ( 25.18)\n",
      "Epoch: [0][ 970/1282]\tTime  4.147 ( 2.483)\tData  3.355 ( 0.168)\tLoss 3.9421e+00 (4.9596e+00)\tAcc@1  21.60 ( 10.63)\tAcc@5  44.20 ( 25.37)\n",
      "Epoch: [0][ 980/1282]\tTime  3.650 ( 2.482)\tData  2.869 ( 0.181)\tLoss 3.9808e+00 (4.9487e+00)\tAcc@1  20.20 ( 10.74)\tAcc@5  42.20 ( 25.55)\n",
      "Epoch: [0][ 990/1282]\tTime  3.111 ( 2.481)\tData  2.334 ( 0.189)\tLoss 3.8176e+00 (4.9381e+00)\tAcc@1  23.40 ( 10.85)\tAcc@5  46.80 ( 25.74)\n",
      "Epoch: [0][1000/1282]\tTime  1.762 ( 2.478)\tData  1.029 ( 0.195)\tLoss 3.9450e+00 (4.9273e+00)\tAcc@1  19.40 ( 10.96)\tAcc@5  45.40 ( 25.93)\n",
      "Epoch: [0][1010/1282]\tTime  4.304 ( 2.480)\tData  3.522 ( 0.206)\tLoss 3.8657e+00 (4.9162e+00)\tAcc@1  20.80 ( 11.07)\tAcc@5  44.60 ( 26.12)\n",
      "Epoch: [0][1020/1282]\tTime  3.870 ( 2.480)\tData  3.095 ( 0.221)\tLoss 3.8428e+00 (4.9053e+00)\tAcc@1  20.20 ( 11.18)\tAcc@5  43.00 ( 26.31)\n",
      "Epoch: [0][1030/1282]\tTime  4.253 ( 2.481)\tData  3.456 ( 0.236)\tLoss 3.9105e+00 (4.8949e+00)\tAcc@1  19.60 ( 11.29)\tAcc@5  43.20 ( 26.50)\n",
      "Epoch: [0][1040/1282]\tTime  4.085 ( 2.480)\tData  3.288 ( 0.249)\tLoss 3.9672e+00 (4.8843e+00)\tAcc@1  20.40 ( 11.39)\tAcc@5  43.00 ( 26.68)\n",
      "Epoch: [0][1050/1282]\tTime  3.579 ( 2.478)\tData  2.801 ( 0.261)\tLoss 3.9919e+00 (4.8743e+00)\tAcc@1  20.00 ( 11.49)\tAcc@5  43.00 ( 26.85)\n",
      "Epoch: [0][1060/1282]\tTime  3.504 ( 2.477)\tData  2.735 ( 0.274)\tLoss 3.6467e+00 (4.8638e+00)\tAcc@1  24.60 ( 11.60)\tAcc@5  50.00 ( 27.04)\n",
      "Epoch: [0][1070/1282]\tTime  3.228 ( 2.476)\tData  2.451 ( 0.284)\tLoss 3.8567e+00 (4.8540e+00)\tAcc@1  20.80 ( 11.69)\tAcc@5  43.00 ( 27.21)\n",
      "Epoch: [0][1080/1282]\tTime  3.578 ( 2.476)\tData  2.778 ( 0.293)\tLoss 3.7058e+00 (4.8441e+00)\tAcc@1  23.60 ( 11.80)\tAcc@5  47.00 ( 27.38)\n",
      "Epoch: [0][1090/1282]\tTime  1.555 ( 2.474)\tData  0.821 ( 0.302)\tLoss 3.6137e+00 (4.8338e+00)\tAcc@1  26.60 ( 11.91)\tAcc@5  50.00 ( 27.56)\n",
      "Epoch: [0][1100/1282]\tTime  0.949 ( 2.473)\tData  0.213 ( 0.307)\tLoss 3.6702e+00 (4.8237e+00)\tAcc@1  24.40 ( 12.02)\tAcc@5  45.60 ( 27.74)\n",
      "Epoch: [0][1110/1282]\tTime  0.826 ( 2.473)\tData  0.088 ( 0.311)\tLoss 3.7663e+00 (4.8132e+00)\tAcc@1  23.40 ( 12.13)\tAcc@5  46.20 ( 27.93)\n",
      "Epoch: [0][1120/1282]\tTime  0.832 ( 2.473)\tData  0.090 ( 0.315)\tLoss 3.6482e+00 (4.8033e+00)\tAcc@1  23.80 ( 12.24)\tAcc@5  48.20 ( 28.10)\n",
      "Epoch: [0][1130/1282]\tTime  0.838 ( 2.472)\tData  0.096 ( 0.313)\tLoss 3.5867e+00 (4.7934e+00)\tAcc@1  27.80 ( 12.35)\tAcc@5  51.00 ( 28.27)\n",
      "Epoch: [0][1140/1282]\tTime  0.862 ( 2.471)\tData  0.090 ( 0.311)\tLoss 3.6591e+00 (4.7836e+00)\tAcc@1  23.00 ( 12.45)\tAcc@5  49.20 ( 28.45)\n",
      "Epoch: [0][1150/1282]\tTime  0.828 ( 2.471)\tData  0.087 ( 0.310)\tLoss 3.6187e+00 (4.7739e+00)\tAcc@1  22.80 ( 12.55)\tAcc@5  49.40 ( 28.63)\n",
      "Epoch: [0][1160/1282]\tTime  1.951 ( 2.472)\tData  1.173 ( 0.319)\tLoss 3.5418e+00 (4.7639e+00)\tAcc@1  22.40 ( 12.64)\tAcc@5  51.20 ( 28.80)\n",
      "Epoch: [0][1170/1282]\tTime  1.877 ( 2.473)\tData  1.129 ( 0.332)\tLoss 3.4948e+00 (4.7539e+00)\tAcc@1  27.60 ( 12.75)\tAcc@5  52.80 ( 28.98)\n",
      "Epoch: [0][1180/1282]\tTime  1.031 ( 2.472)\tData  0.279 ( 0.343)\tLoss 3.6288e+00 (4.7440e+00)\tAcc@1  23.80 ( 12.85)\tAcc@5  48.60 ( 29.15)\n",
      "Epoch: [0][1190/1282]\tTime  0.793 ( 2.472)\tData  0.002 ( 0.354)\tLoss 3.7040e+00 (4.7342e+00)\tAcc@1  23.00 ( 12.96)\tAcc@5  48.60 ( 29.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1200/1282]\tTime  0.755 ( 2.471)\tData  0.002 ( 0.364)\tLoss 3.4975e+00 (4.7250e+00)\tAcc@1  28.60 ( 13.06)\tAcc@5  53.80 ( 29.50)\n",
      "Epoch: [0][1210/1282]\tTime  0.758 ( 2.471)\tData  0.002 ( 0.375)\tLoss 3.5378e+00 (4.7156e+00)\tAcc@1  27.40 ( 13.17)\tAcc@5  49.60 ( 29.67)\n",
      "Epoch: [0][1220/1282]\tTime  0.755 ( 2.469)\tData  0.002 ( 0.384)\tLoss 3.5745e+00 (4.7065e+00)\tAcc@1  26.40 ( 13.27)\tAcc@5  50.20 ( 29.84)\n",
      "Epoch: [0][1230/1282]\tTime  0.755 ( 2.468)\tData  0.002 ( 0.394)\tLoss 3.5085e+00 (4.6970e+00)\tAcc@1  26.60 ( 13.37)\tAcc@5  51.60 ( 30.01)\n",
      "Epoch: [0][1240/1282]\tTime  0.739 ( 2.468)\tData  0.002 ( 0.404)\tLoss 3.6303e+00 (4.6876e+00)\tAcc@1  24.60 ( 13.47)\tAcc@5  47.00 ( 30.18)\n",
      "Epoch: [0][1250/1282]\tTime  0.735 ( 2.467)\tData  0.002 ( 0.414)\tLoss 3.4979e+00 (4.6781e+00)\tAcc@1  27.20 ( 13.57)\tAcc@5  52.60 ( 30.35)\n",
      "Epoch: [0][1260/1282]\tTime  0.729 ( 2.466)\tData  0.002 ( 0.423)\tLoss 3.4259e+00 (4.6690e+00)\tAcc@1  25.20 ( 13.66)\tAcc@5  53.80 ( 30.51)\n",
      "Epoch: [0][1270/1282]\tTime  0.731 ( 2.466)\tData  0.002 ( 0.433)\tLoss 3.4059e+00 (4.6597e+00)\tAcc@1  29.60 ( 13.77)\tAcc@5  52.60 ( 30.67)\n",
      "Epoch: [0][1280/1282]\tTime  0.729 ( 2.464)\tData  0.002 ( 0.441)\tLoss 3.6201e+00 (4.6507e+00)\tAcc@1  24.20 ( 13.87)\tAcc@5  49.40 ( 30.84)\n",
      "Test: [0/3]\tTime  9.003 ( 9.003)\tLoss 3.7918e+00 (3.7918e+00)\tAcc@1  20.80 ( 20.80)\tAcc@5  45.60 ( 45.60)\n",
      " * Acc@1 20.280 Acc@5 43.257\n",
      "lr: [0.0]\n",
      "Epoch: [1][   0/1282]\tTime  6.125 ( 6.125)\tData  4.912 ( 4.912)\tLoss 3.4886e+00 (3.4886e+00)\tAcc@1  28.00 ( 28.00)\tAcc@5  53.40 ( 53.40)\n",
      "Epoch: [1][  10/1282]\tTime  4.059 ( 2.794)\tData  3.279 ( 1.945)\tLoss 3.7624e+00 (3.5245e+00)\tAcc@1  21.40 ( 26.40)\tAcc@5  46.00 ( 50.42)\n",
      "Epoch: [1][  20/1282]\tTime  3.981 ( 2.576)\tData  3.196 ( 1.772)\tLoss 3.4935e+00 (3.5133e+00)\tAcc@1  29.40 ( 26.55)\tAcc@5  50.40 ( 50.86)\n",
      "Epoch: [1][  30/1282]\tTime  4.280 ( 2.534)\tData  3.492 ( 1.745)\tLoss 3.5135e+00 (3.5230e+00)\tAcc@1  26.80 ( 26.53)\tAcc@5  53.20 ( 51.00)\n",
      "Epoch: [1][  40/1282]\tTime  4.318 ( 2.549)\tData  3.533 ( 1.768)\tLoss 3.5495e+00 (3.5396e+00)\tAcc@1  28.20 ( 26.18)\tAcc@5  52.80 ( 50.76)\n",
      "Epoch: [1][  50/1282]\tTime  3.757 ( 2.506)\tData  2.965 ( 1.729)\tLoss 3.5545e+00 (3.5346e+00)\tAcc@1  26.00 ( 26.18)\tAcc@5  50.60 ( 50.71)\n",
      "Epoch: [1][  60/1282]\tTime  2.784 ( 2.492)\tData  1.990 ( 1.718)\tLoss 3.5766e+00 (3.5312e+00)\tAcc@1  25.20 ( 26.24)\tAcc@5  53.20 ( 50.82)\n",
      "Epoch: [1][  70/1282]\tTime  3.635 ( 2.505)\tData  2.862 ( 1.733)\tLoss 3.5884e+00 (3.5346e+00)\tAcc@1  24.20 ( 26.23)\tAcc@5  46.60 ( 50.75)\n",
      "Epoch: [1][  80/1282]\tTime  2.498 ( 2.499)\tData  1.760 ( 1.727)\tLoss 3.5545e+00 (3.5390e+00)\tAcc@1  25.20 ( 26.17)\tAcc@5  50.00 ( 50.70)\n",
      "Epoch: [1][  90/1282]\tTime  3.353 ( 2.496)\tData  2.570 ( 1.725)\tLoss 3.3668e+00 (3.5367e+00)\tAcc@1  28.80 ( 26.27)\tAcc@5  52.80 ( 50.73)\n",
      "Epoch: [1][ 100/1282]\tTime  2.610 ( 2.499)\tData  1.835 ( 1.729)\tLoss 3.4809e+00 (3.5328e+00)\tAcc@1  27.00 ( 26.31)\tAcc@5  52.60 ( 50.85)\n",
      "Epoch: [1][ 110/1282]\tTime  2.172 ( 2.493)\tData  1.425 ( 1.724)\tLoss 3.3561e+00 (3.5333e+00)\tAcc@1  26.80 ( 26.31)\tAcc@5  51.20 ( 50.81)\n",
      "Epoch: [1][ 120/1282]\tTime  2.677 ( 2.503)\tData  1.906 ( 1.734)\tLoss 3.5684e+00 (3.5316e+00)\tAcc@1  24.80 ( 26.36)\tAcc@5  49.40 ( 50.85)\n",
      "Epoch: [1][ 130/1282]\tTime  3.265 ( 2.512)\tData  2.498 ( 1.743)\tLoss 3.5203e+00 (3.5335e+00)\tAcc@1  27.40 ( 26.36)\tAcc@5  54.60 ( 50.82)\n",
      "Epoch: [1][ 140/1282]\tTime  2.612 ( 2.502)\tData  1.859 ( 1.732)\tLoss 3.4830e+00 (3.5287e+00)\tAcc@1  26.20 ( 26.40)\tAcc@5  49.40 ( 50.88)\n",
      "Epoch: [1][ 150/1282]\tTime  1.490 ( 2.488)\tData  0.703 ( 1.718)\tLoss 3.6001e+00 (3.5278e+00)\tAcc@1  24.40 ( 26.37)\tAcc@5  48.60 ( 50.92)\n",
      "Epoch: [1][ 160/1282]\tTime  1.034 ( 2.479)\tData  0.280 ( 1.708)\tLoss 3.4330e+00 (3.5270e+00)\tAcc@1  26.80 ( 26.32)\tAcc@5  49.80 ( 50.96)\n",
      "Epoch: [1][ 170/1282]\tTime  1.808 ( 2.474)\tData  1.051 ( 1.703)\tLoss 3.6142e+00 (3.5247e+00)\tAcc@1  24.40 ( 26.34)\tAcc@5  47.60 ( 50.95)\n",
      "Epoch: [1][ 180/1282]\tTime  2.144 ( 2.467)\tData  1.388 ( 1.697)\tLoss 3.4609e+00 (3.5234e+00)\tAcc@1  26.60 ( 26.37)\tAcc@5  52.20 ( 50.95)\n",
      "Epoch: [1][ 190/1282]\tTime  3.451 ( 2.465)\tData  2.682 ( 1.696)\tLoss 3.4752e+00 (3.5242e+00)\tAcc@1  24.20 ( 26.36)\tAcc@5  51.60 ( 50.93)\n",
      "Epoch: [1][ 200/1282]\tTime  2.035 ( 2.456)\tData  1.279 ( 1.671)\tLoss 3.4528e+00 (3.5251e+00)\tAcc@1  27.60 ( 26.37)\tAcc@5  51.00 ( 50.93)\n",
      "Epoch: [1][ 210/1282]\tTime  2.908 ( 2.456)\tData  2.137 ( 1.648)\tLoss 3.6085e+00 (3.5260e+00)\tAcc@1  23.60 ( 26.34)\tAcc@5  47.00 ( 50.92)\n",
      "Epoch: [1][ 220/1282]\tTime  1.838 ( 2.450)\tData  1.083 ( 1.611)\tLoss 3.6135e+00 (3.5260e+00)\tAcc@1  24.80 ( 26.37)\tAcc@5  47.40 ( 50.91)\n",
      "Epoch: [1][ 230/1282]\tTime  1.515 ( 2.445)\tData  0.760 ( 1.568)\tLoss 3.5155e+00 (3.5258e+00)\tAcc@1  25.80 ( 26.37)\tAcc@5  50.80 ( 50.88)\n",
      "Epoch: [1][ 240/1282]\tTime  1.785 ( 2.442)\tData  1.028 ( 1.525)\tLoss 3.5890e+00 (3.5261e+00)\tAcc@1  24.80 ( 26.38)\tAcc@5  49.20 ( 50.86)\n",
      "Epoch: [1][ 250/1282]\tTime  2.148 ( 2.442)\tData  1.392 ( 1.494)\tLoss 3.4596e+00 (3.5244e+00)\tAcc@1  26.60 ( 26.43)\tAcc@5  53.20 ( 50.92)\n",
      "Epoch: [1][ 260/1282]\tTime  3.308 ( 2.446)\tData  2.534 ( 1.479)\tLoss 3.4644e+00 (3.5216e+00)\tAcc@1  28.00 ( 26.47)\tAcc@5  53.00 ( 50.98)\n",
      "Epoch: [1][ 270/1282]\tTime  4.148 ( 2.449)\tData  3.360 ( 1.482)\tLoss 3.5185e+00 (3.5211e+00)\tAcc@1  28.80 ( 26.49)\tAcc@5  54.00 ( 51.01)\n",
      "Epoch: [1][ 280/1282]\tTime  3.364 ( 2.446)\tData  2.572 ( 1.485)\tLoss 3.7025e+00 (3.5203e+00)\tAcc@1  22.40 ( 26.51)\tAcc@5  48.00 ( 51.06)\n",
      "Epoch: [1][ 290/1282]\tTime  3.556 ( 2.446)\tData  2.772 ( 1.479)\tLoss 3.6602e+00 (3.5200e+00)\tAcc@1  25.40 ( 26.52)\tAcc@5  48.00 ( 51.08)\n",
      "Epoch: [1][ 300/1282]\tTime  4.318 ( 2.449)\tData  3.541 ( 1.485)\tLoss 3.6315e+00 (3.5214e+00)\tAcc@1  24.80 ( 26.50)\tAcc@5  48.40 ( 51.04)\n",
      "Epoch: [1][ 310/1282]\tTime  4.538 ( 2.453)\tData  3.763 ( 1.495)\tLoss 3.3951e+00 (3.5212e+00)\tAcc@1  28.80 ( 26.51)\tAcc@5  52.60 ( 51.04)\n",
      "Epoch: [1][ 320/1282]\tTime  4.043 ( 2.456)\tData  3.253 ( 1.504)\tLoss 3.4597e+00 (3.5227e+00)\tAcc@1  27.00 ( 26.48)\tAcc@5  53.00 ( 51.00)\n",
      "Epoch: [1][ 330/1282]\tTime  3.697 ( 2.452)\tData  2.911 ( 1.505)\tLoss 3.4304e+00 (3.5234e+00)\tAcc@1  28.00 ( 26.49)\tAcc@5  51.60 ( 50.99)\n",
      "Epoch: [1][ 340/1282]\tTime  4.183 ( 2.449)\tData  3.409 ( 1.507)\tLoss 3.5270e+00 (3.5223e+00)\tAcc@1  27.20 ( 26.52)\tAcc@5  51.40 ( 51.02)\n",
      "Epoch: [1][ 350/1282]\tTime  4.120 ( 2.446)\tData  3.322 ( 1.510)\tLoss 3.5727e+00 (3.5212e+00)\tAcc@1  27.40 ( 26.53)\tAcc@5  50.80 ( 51.05)\n",
      "Epoch: [1][ 360/1282]\tTime  3.638 ( 2.443)\tData  2.839 ( 1.509)\tLoss 3.5854e+00 (3.5214e+00)\tAcc@1  24.40 ( 26.52)\tAcc@5  49.80 ( 51.02)\n",
      "Epoch: [1][ 370/1282]\tTime  4.100 ( 2.443)\tData  3.310 ( 1.509)\tLoss 3.4576e+00 (3.5216e+00)\tAcc@1  27.20 ( 26.50)\tAcc@5  49.80 ( 51.01)\n",
      "Epoch: [1][ 380/1282]\tTime  3.788 ( 2.440)\tData  3.017 ( 1.509)\tLoss 3.5609e+00 (3.5210e+00)\tAcc@1  29.00 ( 26.53)\tAcc@5  53.00 ( 51.04)\n",
      "Epoch: [1][ 390/1282]\tTime  4.304 ( 2.440)\tData  3.526 ( 1.512)\tLoss 3.5661e+00 (3.5223e+00)\tAcc@1  27.80 ( 26.51)\tAcc@5  51.00 ( 51.02)\n",
      "Epoch: [1][ 400/1282]\tTime  3.837 ( 2.438)\tData  3.044 ( 1.513)\tLoss 3.6909e+00 (3.5211e+00)\tAcc@1  23.60 ( 26.52)\tAcc@5  50.80 ( 51.04)\n",
      "Epoch: [1][ 410/1282]\tTime  3.929 ( 2.437)\tData  3.132 ( 1.516)\tLoss 3.6163e+00 (3.5208e+00)\tAcc@1  24.20 ( 26.52)\tAcc@5  47.80 ( 51.05)\n",
      "Epoch: [1][ 420/1282]\tTime  3.881 ( 2.437)\tData  3.096 ( 1.519)\tLoss 3.4503e+00 (3.5202e+00)\tAcc@1  27.40 ( 26.55)\tAcc@5  51.00 ( 51.07)\n",
      "Epoch: [1][ 430/1282]\tTime  3.008 ( 2.435)\tData  2.231 ( 1.515)\tLoss 3.5892e+00 (3.5213e+00)\tAcc@1  25.80 ( 26.54)\tAcc@5  51.40 ( 51.05)\n",
      "Epoch: [1][ 440/1282]\tTime  3.973 ( 2.435)\tData  3.179 ( 1.516)\tLoss 3.6027e+00 (3.5213e+00)\tAcc@1  25.80 ( 26.55)\tAcc@5  52.40 ( 51.07)\n",
      "Epoch: [1][ 450/1282]\tTime  3.890 ( 2.434)\tData  3.123 ( 1.517)\tLoss 3.5673e+00 (3.5207e+00)\tAcc@1  25.40 ( 26.56)\tAcc@5  49.00 ( 51.07)\n",
      "Epoch: [1][ 460/1282]\tTime  4.197 ( 2.436)\tData  3.408 ( 1.516)\tLoss 3.5098e+00 (3.5198e+00)\tAcc@1  25.80 ( 26.57)\tAcc@5  52.20 ( 51.10)\n",
      "Epoch: [1][ 470/1282]\tTime  4.186 ( 2.436)\tData  3.420 ( 1.518)\tLoss 3.4859e+00 (3.5197e+00)\tAcc@1  26.80 ( 26.57)\tAcc@5  52.40 ( 51.09)\n",
      "Epoch: [1][ 480/1282]\tTime  3.768 ( 2.439)\tData  2.981 ( 1.521)\tLoss 3.5115e+00 (3.5192e+00)\tAcc@1  28.40 ( 26.57)\tAcc@5  51.20 ( 51.10)\n",
      "Epoch: [1][ 490/1282]\tTime  3.755 ( 2.440)\tData  2.989 ( 1.525)\tLoss 3.4565e+00 (3.5187e+00)\tAcc@1  28.20 ( 26.60)\tAcc@5  51.00 ( 51.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][ 500/1282]\tTime  5.040 ( 2.444)\tData  4.247 ( 1.532)\tLoss 3.6282e+00 (3.5187e+00)\tAcc@1  24.60 ( 26.59)\tAcc@5  50.00 ( 51.10)\n",
      "Epoch: [1][ 510/1282]\tTime  4.304 ( 2.446)\tData  3.509 ( 1.536)\tLoss 3.5319e+00 (3.5188e+00)\tAcc@1  26.20 ( 26.58)\tAcc@5  51.20 ( 51.09)\n",
      "Epoch: [1][ 520/1282]\tTime  4.336 ( 2.448)\tData  3.542 ( 1.541)\tLoss 3.3892e+00 (3.5179e+00)\tAcc@1  28.00 ( 26.59)\tAcc@5  54.60 ( 51.10)\n",
      "Epoch: [1][ 530/1282]\tTime  3.801 ( 2.446)\tData  2.999 ( 1.541)\tLoss 3.4252e+00 (3.5181e+00)\tAcc@1  27.80 ( 26.60)\tAcc@5  51.60 ( 51.10)\n",
      "Epoch: [1][ 540/1282]\tTime  4.070 ( 2.445)\tData  3.264 ( 1.543)\tLoss 3.5008e+00 (3.5177e+00)\tAcc@1  25.60 ( 26.59)\tAcc@5  51.20 ( 51.10)\n",
      "Epoch: [1][ 550/1282]\tTime  4.198 ( 2.445)\tData  3.407 ( 1.545)\tLoss 3.6213e+00 (3.5176e+00)\tAcc@1  26.00 ( 26.60)\tAcc@5  50.00 ( 51.11)\n",
      "Epoch: [1][ 560/1282]\tTime  4.328 ( 2.446)\tData  3.555 ( 1.549)\tLoss 3.5357e+00 (3.5175e+00)\tAcc@1  25.60 ( 26.59)\tAcc@5  51.00 ( 51.11)\n",
      "Epoch: [1][ 570/1282]\tTime  3.948 ( 2.446)\tData  3.152 ( 1.551)\tLoss 3.4871e+00 (3.5174e+00)\tAcc@1  26.20 ( 26.60)\tAcc@5  53.60 ( 51.12)\n",
      "Epoch: [1][ 580/1282]\tTime  5.557 ( 2.450)\tData  4.775 ( 1.557)\tLoss 3.5223e+00 (3.5171e+00)\tAcc@1  26.40 ( 26.60)\tAcc@5  51.40 ( 51.12)\n",
      "Epoch: [1][ 590/1282]\tTime  4.316 ( 2.449)\tData  3.532 ( 1.557)\tLoss 3.3774e+00 (3.5161e+00)\tAcc@1  30.00 ( 26.62)\tAcc@5  52.40 ( 51.15)\n",
      "Epoch: [1][ 600/1282]\tTime  4.053 ( 2.448)\tData  3.268 ( 1.559)\tLoss 3.6917e+00 (3.5160e+00)\tAcc@1  22.40 ( 26.61)\tAcc@5  46.00 ( 51.15)\n",
      "Epoch: [1][ 610/1282]\tTime  4.051 ( 2.447)\tData  3.270 ( 1.560)\tLoss 3.4587e+00 (3.5153e+00)\tAcc@1  27.00 ( 26.61)\tAcc@5  52.40 ( 51.15)\n",
      "Epoch: [1][ 620/1282]\tTime  4.460 ( 2.446)\tData  3.670 ( 1.561)\tLoss 3.4818e+00 (3.5152e+00)\tAcc@1  26.60 ( 26.62)\tAcc@5  50.00 ( 51.15)\n",
      "Epoch: [1][ 630/1282]\tTime  3.675 ( 2.445)\tData  2.901 ( 1.561)\tLoss 3.5463e+00 (3.5147e+00)\tAcc@1  27.80 ( 26.64)\tAcc@5  51.20 ( 51.17)\n",
      "Epoch: [1][ 640/1282]\tTime  4.014 ( 2.445)\tData  3.227 ( 1.563)\tLoss 3.6180e+00 (3.5145e+00)\tAcc@1  25.20 ( 26.64)\tAcc@5  49.40 ( 51.18)\n",
      "Epoch: [1][ 650/1282]\tTime  3.958 ( 2.445)\tData  3.163 ( 1.563)\tLoss 3.3795e+00 (3.5135e+00)\tAcc@1  28.00 ( 26.64)\tAcc@5  54.60 ( 51.20)\n",
      "Epoch: [1][ 660/1282]\tTime  3.743 ( 2.444)\tData  2.971 ( 1.564)\tLoss 3.5383e+00 (3.5125e+00)\tAcc@1  25.40 ( 26.66)\tAcc@5  51.20 ( 51.23)\n",
      "Epoch: [1][ 670/1282]\tTime  4.225 ( 2.443)\tData  3.452 ( 1.564)\tLoss 3.4110e+00 (3.5122e+00)\tAcc@1  27.60 ( 26.66)\tAcc@5  53.00 ( 51.24)\n",
      "Epoch: [1][ 680/1282]\tTime  3.818 ( 2.442)\tData  3.022 ( 1.565)\tLoss 3.5716e+00 (3.5125e+00)\tAcc@1  25.60 ( 26.65)\tAcc@5  49.60 ( 51.24)\n",
      "Epoch: [1][ 690/1282]\tTime  4.322 ( 2.442)\tData  3.553 ( 1.567)\tLoss 3.3406e+00 (3.5116e+00)\tAcc@1  28.40 ( 26.64)\tAcc@5  53.40 ( 51.24)\n",
      "Epoch: [1][ 700/1282]\tTime  3.656 ( 2.441)\tData  2.888 ( 1.567)\tLoss 3.5671e+00 (3.5114e+00)\tAcc@1  25.60 ( 26.62)\tAcc@5  51.60 ( 51.24)\n",
      "Epoch: [1][ 710/1282]\tTime  3.734 ( 2.441)\tData  2.955 ( 1.568)\tLoss 3.4404e+00 (3.5109e+00)\tAcc@1  27.80 ( 26.63)\tAcc@5  51.20 ( 51.24)\n",
      "Epoch: [1][ 720/1282]\tTime  3.913 ( 2.441)\tData  3.114 ( 1.569)\tLoss 3.4717e+00 (3.5099e+00)\tAcc@1  26.60 ( 26.64)\tAcc@5  51.00 ( 51.25)\n",
      "Epoch: [1][ 730/1282]\tTime  4.422 ( 2.441)\tData  3.628 ( 1.570)\tLoss 3.5860e+00 (3.5111e+00)\tAcc@1  25.00 ( 26.62)\tAcc@5  49.40 ( 51.23)\n",
      "Epoch: [1][ 740/1282]\tTime  4.905 ( 2.444)\tData  4.132 ( 1.575)\tLoss 3.5644e+00 (3.5109e+00)\tAcc@1  24.80 ( 26.63)\tAcc@5  48.00 ( 51.23)\n",
      "Epoch: [1][ 750/1282]\tTime  4.099 ( 2.446)\tData  3.319 ( 1.578)\tLoss 3.7488e+00 (3.5119e+00)\tAcc@1  25.00 ( 26.61)\tAcc@5  45.80 ( 51.21)\n",
      "Epoch: [1][ 760/1282]\tTime  4.192 ( 2.446)\tData  3.393 ( 1.580)\tLoss 3.4395e+00 (3.5115e+00)\tAcc@1  27.00 ( 26.60)\tAcc@5  50.60 ( 51.22)\n",
      "Epoch: [1][ 770/1282]\tTime  4.202 ( 2.446)\tData  3.402 ( 1.580)\tLoss 3.4272e+00 (3.5114e+00)\tAcc@1  26.00 ( 26.59)\tAcc@5  50.40 ( 51.22)\n",
      "Epoch: [1][ 780/1282]\tTime  4.114 ( 2.445)\tData  3.342 ( 1.581)\tLoss 3.4304e+00 (3.5109e+00)\tAcc@1  27.20 ( 26.59)\tAcc@5  52.00 ( 51.24)\n",
      "Epoch: [1][ 790/1282]\tTime  4.102 ( 2.445)\tData  3.313 ( 1.582)\tLoss 3.6184e+00 (3.5108e+00)\tAcc@1  24.00 ( 26.58)\tAcc@5  49.40 ( 51.23)\n",
      "Epoch: [1][ 800/1282]\tTime  4.013 ( 2.445)\tData  3.212 ( 1.583)\tLoss 3.3743e+00 (3.5099e+00)\tAcc@1  28.20 ( 26.60)\tAcc@5  53.00 ( 51.25)\n",
      "Epoch: [1][ 810/1282]\tTime  4.047 ( 2.446)\tData  3.279 ( 1.585)\tLoss 3.4649e+00 (3.5097e+00)\tAcc@1  27.80 ( 26.60)\tAcc@5  53.40 ( 51.25)\n",
      "Epoch: [1][ 820/1282]\tTime  4.233 ( 2.446)\tData  3.442 ( 1.586)\tLoss 3.3380e+00 (3.5085e+00)\tAcc@1  30.80 ( 26.62)\tAcc@5  53.60 ( 51.27)\n",
      "Epoch: [1][ 830/1282]\tTime  4.859 ( 2.447)\tData  4.060 ( 1.588)\tLoss 3.3002e+00 (3.5082e+00)\tAcc@1  30.80 ( 26.61)\tAcc@5  55.60 ( 51.28)\n",
      "Epoch: [1][ 840/1282]\tTime  4.025 ( 2.447)\tData  3.243 ( 1.589)\tLoss 3.4648e+00 (3.5073e+00)\tAcc@1  26.00 ( 26.63)\tAcc@5  52.20 ( 51.31)\n",
      "Epoch: [1][ 850/1282]\tTime  4.609 ( 2.447)\tData  3.815 ( 1.590)\tLoss 3.2428e+00 (3.5064e+00)\tAcc@1  30.00 ( 26.64)\tAcc@5  55.60 ( 51.32)\n",
      "Epoch: [1][ 860/1282]\tTime  3.702 ( 2.446)\tData  2.913 ( 1.590)\tLoss 3.6045e+00 (3.5059e+00)\tAcc@1  25.60 ( 26.63)\tAcc@5  50.40 ( 51.32)\n",
      "Epoch: [1][ 870/1282]\tTime  4.077 ( 2.445)\tData  3.304 ( 1.590)\tLoss 3.4988e+00 (3.5053e+00)\tAcc@1  28.40 ( 26.64)\tAcc@5  53.20 ( 51.33)\n",
      "Epoch: [1][ 880/1282]\tTime  4.478 ( 2.446)\tData  3.691 ( 1.592)\tLoss 3.3767e+00 (3.5050e+00)\tAcc@1  29.20 ( 26.64)\tAcc@5  53.80 ( 51.33)\n",
      "Epoch: [1][ 890/1282]\tTime  4.130 ( 2.446)\tData  3.340 ( 1.593)\tLoss 3.5078e+00 (3.5044e+00)\tAcc@1  28.00 ( 26.66)\tAcc@5  50.20 ( 51.34)\n",
      "Epoch: [1][ 900/1282]\tTime  4.094 ( 2.446)\tData  3.315 ( 1.594)\tLoss 3.4427e+00 (3.5038e+00)\tAcc@1  27.80 ( 26.66)\tAcc@5  50.40 ( 51.35)\n",
      "Epoch: [1][ 910/1282]\tTime  3.944 ( 2.445)\tData  3.156 ( 1.594)\tLoss 3.3896e+00 (3.5031e+00)\tAcc@1  26.80 ( 26.67)\tAcc@5  53.40 ( 51.36)\n",
      "Epoch: [1][ 920/1282]\tTime  3.969 ( 2.446)\tData  3.187 ( 1.595)\tLoss 3.5866e+00 (3.5028e+00)\tAcc@1  25.20 ( 26.67)\tAcc@5  48.20 ( 51.37)\n",
      "Epoch: [1][ 930/1282]\tTime  4.255 ( 2.445)\tData  3.484 ( 1.596)\tLoss 3.5353e+00 (3.5019e+00)\tAcc@1  25.20 ( 26.68)\tAcc@5  47.40 ( 51.38)\n",
      "Epoch: [1][ 940/1282]\tTime  4.164 ( 2.444)\tData  3.388 ( 1.595)\tLoss 3.4585e+00 (3.5016e+00)\tAcc@1  26.80 ( 26.68)\tAcc@5  54.20 ( 51.39)\n",
      "Epoch: [1][ 950/1282]\tTime  4.048 ( 2.444)\tData  3.250 ( 1.596)\tLoss 3.3469e+00 (3.5012e+00)\tAcc@1  28.60 ( 26.69)\tAcc@5  53.80 ( 51.40)\n",
      "Epoch: [1][ 960/1282]\tTime  3.861 ( 2.446)\tData  3.064 ( 1.599)\tLoss 3.4724e+00 (3.5007e+00)\tAcc@1  28.80 ( 26.70)\tAcc@5  49.80 ( 51.40)\n",
      "Epoch: [1][ 970/1282]\tTime  4.028 ( 2.446)\tData  3.238 ( 1.600)\tLoss 3.4396e+00 (3.5003e+00)\tAcc@1  28.00 ( 26.70)\tAcc@5  49.60 ( 51.40)\n",
      "Epoch: [1][ 980/1282]\tTime  4.162 ( 2.448)\tData  3.371 ( 1.603)\tLoss 3.6337e+00 (3.5001e+00)\tAcc@1  24.60 ( 26.70)\tAcc@5  49.60 ( 51.41)\n",
      "Epoch: [1][ 990/1282]\tTime  4.475 ( 2.448)\tData  3.684 ( 1.603)\tLoss 3.4325e+00 (3.4996e+00)\tAcc@1  28.40 ( 26.71)\tAcc@5  52.80 ( 51.41)\n",
      "Epoch: [1][1000/1282]\tTime  3.932 ( 2.447)\tData  3.149 ( 1.603)\tLoss 3.5876e+00 (3.4992e+00)\tAcc@1  26.40 ( 26.72)\tAcc@5  51.40 ( 51.42)\n",
      "Epoch: [1][1010/1282]\tTime  4.242 ( 2.448)\tData  3.458 ( 1.604)\tLoss 3.4907e+00 (3.4987e+00)\tAcc@1  26.20 ( 26.73)\tAcc@5  53.80 ( 51.43)\n",
      "Epoch: [1][1020/1282]\tTime  3.626 ( 2.449)\tData  2.841 ( 1.606)\tLoss 3.5284e+00 (3.4982e+00)\tAcc@1  25.20 ( 26.73)\tAcc@5  51.00 ( 51.44)\n",
      "Epoch: [1][1030/1282]\tTime  4.195 ( 2.450)\tData  3.414 ( 1.608)\tLoss 3.4904e+00 (3.4979e+00)\tAcc@1  25.00 ( 26.74)\tAcc@5  51.80 ( 51.44)\n",
      "Epoch: [1][1040/1282]\tTime  5.242 ( 2.452)\tData  4.456 ( 1.611)\tLoss 3.5915e+00 (3.4974e+00)\tAcc@1  25.60 ( 26.75)\tAcc@5  49.40 ( 51.45)\n",
      "Epoch: [1][1050/1282]\tTime  3.891 ( 2.452)\tData  3.118 ( 1.611)\tLoss 3.6456e+00 (3.4972e+00)\tAcc@1  24.40 ( 26.75)\tAcc@5  50.20 ( 51.46)\n",
      "Epoch: [1][1060/1282]\tTime  4.801 ( 2.453)\tData  4.008 ( 1.613)\tLoss 3.3539e+00 (3.4967e+00)\tAcc@1  29.40 ( 26.75)\tAcc@5  55.00 ( 51.47)\n",
      "Epoch: [1][1070/1282]\tTime  4.407 ( 2.454)\tData  3.613 ( 1.614)\tLoss 3.4188e+00 (3.4960e+00)\tAcc@1  27.60 ( 26.76)\tAcc@5  52.60 ( 51.48)\n",
      "Epoch: [1][1080/1282]\tTime  4.070 ( 2.454)\tData  3.300 ( 1.615)\tLoss 3.4106e+00 (3.4955e+00)\tAcc@1  28.00 ( 26.77)\tAcc@5  51.60 ( 51.49)\n",
      "Epoch: [1][1090/1282]\tTime  4.154 ( 2.453)\tData  3.376 ( 1.615)\tLoss 3.3465e+00 (3.4946e+00)\tAcc@1  27.80 ( 26.78)\tAcc@5  56.20 ( 51.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1100/1282]\tTime  3.568 ( 2.453)\tData  2.803 ( 1.615)\tLoss 3.2887e+00 (3.4941e+00)\tAcc@1  28.60 ( 26.79)\tAcc@5  56.00 ( 51.52)\n",
      "Epoch: [1][1110/1282]\tTime  4.444 ( 2.454)\tData  3.674 ( 1.617)\tLoss 3.3266e+00 (3.4929e+00)\tAcc@1  28.40 ( 26.81)\tAcc@5  52.20 ( 51.55)\n",
      "Epoch: [1][1120/1282]\tTime  4.304 ( 2.453)\tData  3.505 ( 1.617)\tLoss 3.4088e+00 (3.4922e+00)\tAcc@1  30.40 ( 26.82)\tAcc@5  53.80 ( 51.56)\n",
      "Epoch: [1][1130/1282]\tTime  3.987 ( 2.453)\tData  3.186 ( 1.617)\tLoss 3.3181e+00 (3.4914e+00)\tAcc@1  31.80 ( 26.83)\tAcc@5  57.00 ( 51.58)\n",
      "Epoch: [1][1140/1282]\tTime  3.978 ( 2.453)\tData  3.186 ( 1.618)\tLoss 3.4190e+00 (3.4906e+00)\tAcc@1  25.20 ( 26.85)\tAcc@5  53.20 ( 51.59)\n",
      "Epoch: [1][1150/1282]\tTime  4.266 ( 2.453)\tData  3.484 ( 1.619)\tLoss 3.4200e+00 (3.4897e+00)\tAcc@1  28.80 ( 26.85)\tAcc@5  51.80 ( 51.61)\n",
      "Epoch: [1][1160/1282]\tTime  3.981 ( 2.453)\tData  3.195 ( 1.619)\tLoss 3.3663e+00 (3.4884e+00)\tAcc@1  27.80 ( 26.87)\tAcc@5  53.40 ( 51.63)\n",
      "Epoch: [1][1170/1282]\tTime  4.438 ( 2.453)\tData  3.661 ( 1.619)\tLoss 3.2378e+00 (3.4872e+00)\tAcc@1  31.60 ( 26.89)\tAcc@5  57.40 ( 51.65)\n",
      "Epoch: [1][1180/1282]\tTime  3.645 ( 2.452)\tData  2.857 ( 1.618)\tLoss 3.4346e+00 (3.4859e+00)\tAcc@1  25.20 ( 26.90)\tAcc@5  54.00 ( 51.67)\n",
      "Epoch: [1][1190/1282]\tTime  3.747 ( 2.451)\tData  2.977 ( 1.618)\tLoss 3.3417e+00 (3.4844e+00)\tAcc@1  30.40 ( 26.93)\tAcc@5  54.20 ( 51.70)\n",
      "Epoch: [1][1200/1282]\tTime  3.669 ( 2.450)\tData  2.888 ( 1.617)\tLoss 3.1412e+00 (3.4832e+00)\tAcc@1  34.00 ( 26.95)\tAcc@5  59.40 ( 51.73)\n",
      "Epoch: [1][1210/1282]\tTime  3.486 ( 2.449)\tData  2.705 ( 1.617)\tLoss 3.3474e+00 (3.4819e+00)\tAcc@1  28.20 ( 26.97)\tAcc@5  51.40 ( 51.75)\n",
      "Epoch: [1][1220/1282]\tTime  2.529 ( 2.448)\tData  1.751 ( 1.614)\tLoss 3.4009e+00 (3.4810e+00)\tAcc@1  28.60 ( 26.99)\tAcc@5  54.00 ( 51.77)\n",
      "Epoch: [1][1230/1282]\tTime  0.844 ( 2.448)\tData  0.090 ( 1.605)\tLoss 3.4070e+00 (3.4795e+00)\tAcc@1  27.80 ( 27.01)\tAcc@5  53.00 ( 51.80)\n",
      "Epoch: [1][1240/1282]\tTime  0.844 ( 2.448)\tData  0.091 ( 1.592)\tLoss 3.4072e+00 (3.4779e+00)\tAcc@1  29.20 ( 27.04)\tAcc@5  52.40 ( 51.83)\n",
      "Epoch: [1][1250/1282]\tTime  0.864 ( 2.447)\tData  0.109 ( 1.580)\tLoss 3.2270e+00 (3.4758e+00)\tAcc@1  31.40 ( 27.07)\tAcc@5  57.00 ( 51.87)\n",
      "Epoch: [1][1260/1282]\tTime  0.841 ( 2.447)\tData  0.092 ( 1.570)\tLoss 3.1413e+00 (3.4739e+00)\tAcc@1  32.80 ( 27.09)\tAcc@5  58.20 ( 51.90)\n",
      "Epoch: [1][1270/1282]\tTime  0.837 ( 2.446)\tData  0.087 ( 1.563)\tLoss 3.0473e+00 (3.4716e+00)\tAcc@1  33.80 ( 27.13)\tAcc@5  60.20 ( 51.95)\n",
      "Epoch: [1][1280/1282]\tTime  0.851 ( 2.445)\tData  0.106 ( 1.557)\tLoss 3.3829e+00 (3.4691e+00)\tAcc@1  29.60 ( 27.17)\tAcc@5  51.40 ( 52.00)\n",
      "Test: [0/3]\tTime  6.068 ( 6.068)\tLoss 3.3379e+00 (3.3379e+00)\tAcc@1  27.80 ( 27.80)\tAcc@5  56.00 ( 56.00)\n",
      " * Acc@1 26.274 Acc@5 51.049\n",
      "lr: [0.1]\n",
      "CPU times: user 1h 36min 22s, sys: 26min 10s, total: 2h 2min 32s\n",
      "Wall time: 1h 45min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "russian-european",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "governmental-columbia",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4703), started 0:00:00 ago. (Use '!kill 4703' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd613e30d8f16adf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd613e30d8f16adf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-soccer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
