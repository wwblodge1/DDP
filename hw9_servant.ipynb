{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-mounting",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modular-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: wandb in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.12.6)\n",
      "Requirement already satisfied: configparser>=3.8.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: pathtools in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.18.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: six>=1.13.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwwblodge1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demanding-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/2o40xki5\" target=\"_blank\">elated-field-39</a></strong> to <a href=\"https://wandb.ai/wwblodge1/hw9_instance\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/hw9_instance/runs/2o40xki5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f05b957a110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"hw9_instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-mortality",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "# Assume that this notebook only sees one GPU.\n",
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-mixer",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-commonwealth",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-morgan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "departmental-listing",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-hammer",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 1\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\"\n",
    "\n",
    "global_step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-elite",
   "metadata": {
    "id": "85299ee3"
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pretty-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2o40xki5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3714... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">elated-field-39</strong>: <a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/2o40xki5\" target=\"_blank\">https://wandb.ai/wwblodge1/hw9_instance/runs/2o40xki5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211119_221210-2o40xki5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2o40xki5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/uncategorized/runs/34s4y0sv\" target=\"_blank\">silvery-aardvark-20</a></strong> to <a href=\"https://wandb.ai/wwblodge1/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/uncategorized/runs/34s4y0sv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f05b84dd790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-eugene",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many processes in cluster?\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "# where is the master?\n",
    "# export NCCL_SOCKET_IFNAME=172.31.24.47\n",
    "URL = 'tcp://172.31.24.176:1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is my rank?\n",
    "RANK = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-melbourne",
   "metadata": {
    "id": "68491838"
   },
   "outputs": [],
   "source": [
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "disturbed-swimming",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device('cpu')\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mineral-gibson",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-fireplace",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "# def train(train_loader, model, criterion, optimizer, epoch):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     data_time = AverageMeter('Data', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(train_loader),\n",
    "#         [batch_time, data_time, losses, top1, top5],\n",
    "#         prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "#     # switch to train mode\n",
    "#     model.train()\n",
    "\n",
    "#     end = time.time()\n",
    "#     for i, (images, target) in enumerate(train_loader):\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # measure accuracy and record loss\n",
    "#         acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#         losses.update(loss.item(), images.size(0))\n",
    "#         top1.update(acc1[0], images.size(0))\n",
    "#         top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if i % PRINT_FREQ == 0:\n",
    "#             progress.display(i)\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-cathedral",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "# def validate(val_loader, model, criterion):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(val_loader),\n",
    "#         [batch_time, losses, top1, top5],\n",
    "#         prefix='Test: ')\n",
    "\n",
    "#     # switch to evaluate mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         end = time.time()\n",
    "#         for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#             # compute output\n",
    "#             output = model(images)\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # measure accuracy and record loss\n",
    "#             acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#             losses.update(loss.item(), images.size(0))\n",
    "#             top1.update(acc1[0], images.size(0))\n",
    "#             top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#             # measure elapsed time\n",
    "#             batch_time.update(time.time() - end)\n",
    "#             end = time.time()\n",
    "\n",
    "#             if i % PRINT_FREQ == 0:\n",
    "#                 progress.display(i)\n",
    "\n",
    "#         # TODO: this should also be done with the ProgressMeter\n",
    "#         print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "#               .format(top1=top1, top5=top5))\n",
    "\n",
    "#     return top1.avg\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-cover",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-cross",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informal-tunisia",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fresh-illustration",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rolled-bullet",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "muslim-edition",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advisory-flesh",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "linear-louisiana",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "anticipated-wound",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "organizational-format",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sacred-welsh",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varying-berry",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "detailed-hungary",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])\n",
    "# model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "homeless-ethernet",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-explorer",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "temporal-attachment",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seven-forum",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "painful-badge",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "durable-median",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparable-anderson",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "damaged-genre",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "productive-optimum",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-commercial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "grateful-margin",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spanish-manitoba",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 13.489 (13.489)\tData  5.970 ( 5.970)\tLoss 7.0184e+00 (7.0184e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.80 (  0.80)\n",
      "Epoch: [0][  10/1282]\tTime  1.943 ( 2.814)\tData  1.220 ( 1.400)\tLoss 6.9149e+00 (6.9761e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   1.00 (  0.65)\n",
      "Epoch: [0][  20/1282]\tTime  1.097 ( 2.601)\tData  0.377 ( 1.421)\tLoss 6.9152e+00 (6.9534e+00)\tAcc@1   0.80 (  0.23)\tAcc@5   2.00 (  0.80)\n",
      "Epoch: [0][  30/1282]\tTime  0.821 ( 2.561)\tData  0.098 ( 1.372)\tLoss 6.8268e+00 (6.9289e+00)\tAcc@1   0.20 (  0.24)\tAcc@5   1.80 (  0.99)\n",
      "Epoch: [0][  40/1282]\tTime  0.811 ( 2.524)\tData  0.091 ( 1.394)\tLoss 6.7024e+00 (6.8847e+00)\tAcc@1   0.40 (  0.39)\tAcc@5   2.60 (  1.40)\n",
      "Epoch: [0][  50/1282]\tTime  1.526 ( 2.538)\tData  0.801 ( 1.395)\tLoss 6.6688e+00 (6.8416e+00)\tAcc@1   0.40 (  0.49)\tAcc@5   2.20 (  1.66)\n",
      "Epoch: [0][  60/1282]\tTime  1.478 ( 2.531)\tData  0.756 ( 1.413)\tLoss 6.4906e+00 (6.7931e+00)\tAcc@1   0.80 (  0.57)\tAcc@5   3.60 (  1.93)\n",
      "Epoch: [0][  70/1282]\tTime  2.113 ( 2.534)\tData  1.388 ( 1.401)\tLoss 6.4559e+00 (6.7531e+00)\tAcc@1   1.20 (  0.60)\tAcc@5   3.60 (  2.16)\n",
      "Epoch: [0][  80/1282]\tTime  2.908 ( 2.534)\tData  2.127 ( 1.402)\tLoss 6.3932e+00 (6.7096e+00)\tAcc@1   1.40 (  0.73)\tAcc@5   4.40 (  2.49)\n",
      "Epoch: [0][  90/1282]\tTime  3.486 ( 2.521)\tData  2.716 ( 1.412)\tLoss 6.3373e+00 (6.6670e+00)\tAcc@1   1.40 (  0.82)\tAcc@5   5.40 (  2.83)\n",
      "Epoch: [0][ 100/1282]\tTime  3.998 ( 2.517)\tData  3.227 ( 1.435)\tLoss 6.1317e+00 (6.6257e+00)\tAcc@1   2.00 (  0.90)\tAcc@5   7.40 (  3.11)\n",
      "Epoch: [0][ 110/1282]\tTime  3.683 ( 2.517)\tData  2.901 ( 1.465)\tLoss 6.0516e+00 (6.5830e+00)\tAcc@1   3.00 (  0.99)\tAcc@5   8.60 (  3.47)\n",
      "Epoch: [0][ 120/1282]\tTime  3.941 ( 2.522)\tData  3.160 ( 1.494)\tLoss 6.1966e+00 (6.5472e+00)\tAcc@1   2.20 (  1.05)\tAcc@5   7.60 (  3.76)\n",
      "Epoch: [0][ 130/1282]\tTime  3.549 ( 2.523)\tData  2.747 ( 1.515)\tLoss 5.9920e+00 (6.5119e+00)\tAcc@1   2.20 (  1.13)\tAcc@5   8.00 (  3.99)\n",
      "Epoch: [0][ 140/1282]\tTime  2.639 ( 2.517)\tData  1.862 ( 1.527)\tLoss 6.0541e+00 (6.4776e+00)\tAcc@1   2.20 (  1.23)\tAcc@5   6.20 (  4.25)\n",
      "Epoch: [0][ 150/1282]\tTime  2.226 ( 2.515)\tData  1.490 ( 1.541)\tLoss 5.9269e+00 (6.4405e+00)\tAcc@1   3.80 (  1.32)\tAcc@5  10.60 (  4.59)\n",
      "Epoch: [0][ 160/1282]\tTime  1.596 ( 2.511)\tData  0.851 ( 1.550)\tLoss 5.8422e+00 (6.4055e+00)\tAcc@1   1.80 (  1.41)\tAcc@5   9.40 (  4.92)\n",
      "Epoch: [0][ 170/1282]\tTime  1.495 ( 2.509)\tData  0.751 ( 1.559)\tLoss 5.7815e+00 (6.3719e+00)\tAcc@1   5.00 (  1.50)\tAcc@5  10.20 (  5.20)\n",
      "Epoch: [0][ 180/1282]\tTime  0.832 ( 2.509)\tData  0.089 ( 1.569)\tLoss 5.9148e+00 (6.3407e+00)\tAcc@1   1.60 (  1.61)\tAcc@5   8.60 (  5.47)\n",
      "Epoch: [0][ 190/1282]\tTime  0.749 ( 2.512)\tData  0.002 ( 1.580)\tLoss 5.7514e+00 (6.3105e+00)\tAcc@1   3.20 (  1.68)\tAcc@5  11.20 (  5.75)\n",
      "Epoch: [0][ 200/1282]\tTime  0.748 ( 2.516)\tData  0.002 ( 1.592)\tLoss 5.7524e+00 (6.2813e+00)\tAcc@1   4.00 (  1.78)\tAcc@5  11.00 (  6.05)\n",
      "Epoch: [0][ 210/1282]\tTime  0.750 ( 2.515)\tData  0.002 ( 1.598)\tLoss 5.6389e+00 (6.2516e+00)\tAcc@1   3.80 (  1.89)\tAcc@5  12.60 (  6.35)\n",
      "Epoch: [0][ 220/1282]\tTime  0.764 ( 2.517)\tData  0.002 ( 1.606)\tLoss 5.5980e+00 (6.2244e+00)\tAcc@1   5.00 (  1.99)\tAcc@5  13.40 (  6.64)\n",
      "Epoch: [0][ 230/1282]\tTime  0.777 ( 2.515)\tData  0.003 ( 1.611)\tLoss 5.5058e+00 (6.1971e+00)\tAcc@1   5.80 (  2.11)\tAcc@5  14.00 (  6.94)\n",
      "Epoch: [0][ 240/1282]\tTime  0.744 ( 2.510)\tData  0.002 ( 1.611)\tLoss 5.5223e+00 (6.1685e+00)\tAcc@1   5.40 (  2.24)\tAcc@5  14.60 (  7.28)\n",
      "Epoch: [0][ 250/1282]\tTime  0.767 ( 2.509)\tData  0.003 ( 1.615)\tLoss 5.5325e+00 (6.1409e+00)\tAcc@1   4.40 (  2.35)\tAcc@5  14.00 (  7.59)\n",
      "Epoch: [0][ 260/1282]\tTime  0.748 ( 2.507)\tData  0.002 ( 1.618)\tLoss 5.5631e+00 (6.1134e+00)\tAcc@1   4.40 (  2.47)\tAcc@5  14.60 (  7.90)\n",
      "Epoch: [0][ 270/1282]\tTime  0.750 ( 2.503)\tData  0.002 ( 1.617)\tLoss 5.3068e+00 (6.0876e+00)\tAcc@1   4.80 (  2.57)\tAcc@5  18.00 (  8.20)\n",
      "Epoch: [0][ 280/1282]\tTime  0.775 ( 2.499)\tData  0.003 ( 1.617)\tLoss 5.3329e+00 (6.0625e+00)\tAcc@1   5.00 (  2.70)\tAcc@5  17.00 (  8.51)\n",
      "Epoch: [0][ 290/1282]\tTime  0.750 ( 2.496)\tData  0.002 ( 1.617)\tLoss 5.3104e+00 (6.0384e+00)\tAcc@1   7.80 (  2.81)\tAcc@5  18.00 (  8.80)\n",
      "Epoch: [0][ 300/1282]\tTime  0.835 ( 2.491)\tData  0.002 ( 1.614)\tLoss 5.2315e+00 (6.0130e+00)\tAcc@1   7.40 (  2.93)\tAcc@5  19.00 (  9.12)\n",
      "Epoch: [0][ 310/1282]\tTime  0.748 ( 2.489)\tData  0.002 ( 1.615)\tLoss 5.2338e+00 (5.9882e+00)\tAcc@1   6.20 (  3.05)\tAcc@5  17.00 (  9.44)\n",
      "Epoch: [0][ 320/1282]\tTime  0.838 ( 2.487)\tData  0.002 ( 1.614)\tLoss 5.1895e+00 (5.9652e+00)\tAcc@1   7.00 (  3.16)\tAcc@5  20.80 (  9.74)\n",
      "Epoch: [0][ 330/1282]\tTime  0.929 ( 2.485)\tData  0.002 ( 1.612)\tLoss 5.2454e+00 (5.9419e+00)\tAcc@1   7.00 (  3.28)\tAcc@5  19.00 ( 10.05)\n",
      "Epoch: [0][ 340/1282]\tTime  0.838 ( 2.483)\tData  0.003 ( 1.611)\tLoss 5.0033e+00 (5.9177e+00)\tAcc@1   7.20 (  3.40)\tAcc@5  19.20 ( 10.34)\n",
      "Epoch: [0][ 350/1282]\tTime  0.949 ( 2.482)\tData  0.003 ( 1.611)\tLoss 5.2152e+00 (5.8951e+00)\tAcc@1   7.20 (  3.53)\tAcc@5  18.20 ( 10.64)\n",
      "Epoch: [0][ 360/1282]\tTime  0.775 ( 2.481)\tData  0.003 ( 1.611)\tLoss 5.0910e+00 (5.8716e+00)\tAcc@1   9.00 (  3.66)\tAcc@5  20.60 ( 10.95)\n",
      "Epoch: [0][ 370/1282]\tTime  0.833 ( 2.479)\tData  0.002 ( 1.610)\tLoss 5.0758e+00 (5.8513e+00)\tAcc@1   9.00 (  3.77)\tAcc@5  22.80 ( 11.21)\n",
      "Epoch: [0][ 380/1282]\tTime  0.931 ( 2.476)\tData  0.002 ( 1.610)\tLoss 4.9583e+00 (5.8300e+00)\tAcc@1   9.20 (  3.89)\tAcc@5  25.20 ( 11.51)\n",
      "Epoch: [0][ 390/1282]\tTime  0.927 ( 2.475)\tData  0.002 ( 1.608)\tLoss 5.0280e+00 (5.8090e+00)\tAcc@1   6.60 (  4.01)\tAcc@5  21.60 ( 11.81)\n",
      "Epoch: [0][ 400/1282]\tTime  0.847 ( 2.474)\tData  0.002 ( 1.608)\tLoss 4.9597e+00 (5.7893e+00)\tAcc@1   8.20 (  4.12)\tAcc@5  22.80 ( 12.09)\n",
      "Epoch: [0][ 410/1282]\tTime  0.930 ( 2.472)\tData  0.002 ( 1.606)\tLoss 4.7790e+00 (5.7701e+00)\tAcc@1  11.40 (  4.24)\tAcc@5  25.60 ( 12.37)\n",
      "Epoch: [0][ 420/1282]\tTime  0.771 ( 2.472)\tData  0.003 ( 1.608)\tLoss 4.8986e+00 (5.7507e+00)\tAcc@1   8.40 (  4.34)\tAcc@5  25.40 ( 12.65)\n",
      "Epoch: [0][ 430/1282]\tTime  0.859 ( 2.470)\tData  0.002 ( 1.607)\tLoss 4.9363e+00 (5.7309e+00)\tAcc@1   9.60 (  4.47)\tAcc@5  23.40 ( 12.94)\n",
      "Epoch: [0][ 440/1282]\tTime  0.838 ( 2.468)\tData  0.003 ( 1.606)\tLoss 5.0107e+00 (5.7128e+00)\tAcc@1   7.20 (  4.59)\tAcc@5  21.40 ( 13.20)\n",
      "Epoch: [0][ 450/1282]\tTime  0.747 ( 2.468)\tData  0.002 ( 1.608)\tLoss 4.5400e+00 (5.6934e+00)\tAcc@1  10.20 (  4.71)\tAcc@5  30.00 ( 13.49)\n",
      "Epoch: [0][ 460/1282]\tTime  0.747 ( 2.468)\tData  0.002 ( 1.609)\tLoss 4.9542e+00 (5.6754e+00)\tAcc@1   9.20 (  4.82)\tAcc@5  26.80 ( 13.75)\n",
      "Epoch: [0][ 470/1282]\tTime  0.751 ( 2.469)\tData  0.002 ( 1.612)\tLoss 4.9081e+00 (5.6575e+00)\tAcc@1  10.20 (  4.93)\tAcc@5  25.00 ( 14.00)\n",
      "Epoch: [0][ 480/1282]\tTime  0.772 ( 2.470)\tData  0.002 ( 1.615)\tLoss 4.6511e+00 (5.6389e+00)\tAcc@1  13.60 (  5.06)\tAcc@5  31.00 ( 14.28)\n",
      "Epoch: [0][ 490/1282]\tTime  0.837 ( 2.468)\tData  0.002 ( 1.614)\tLoss 4.6848e+00 (5.6209e+00)\tAcc@1  10.80 (  5.18)\tAcc@5  28.40 ( 14.55)\n",
      "Epoch: [0][ 500/1282]\tTime  0.752 ( 2.466)\tData  0.002 ( 1.613)\tLoss 4.8259e+00 (5.6037e+00)\tAcc@1  12.80 (  5.30)\tAcc@5  27.00 ( 14.81)\n",
      "Epoch: [0][ 510/1282]\tTime  0.835 ( 2.466)\tData  0.002 ( 1.613)\tLoss 4.8754e+00 (5.5875e+00)\tAcc@1   8.60 (  5.40)\tAcc@5  24.60 ( 15.06)\n",
      "Epoch: [0][ 520/1282]\tTime  0.750 ( 2.466)\tData  0.002 ( 1.615)\tLoss 4.7311e+00 (5.5704e+00)\tAcc@1  10.40 (  5.52)\tAcc@5  26.20 ( 15.30)\n",
      "Epoch: [0][ 530/1282]\tTime  0.774 ( 2.469)\tData  0.003 ( 1.619)\tLoss 4.6215e+00 (5.5532e+00)\tAcc@1  11.40 (  5.64)\tAcc@5  29.20 ( 15.55)\n",
      "Epoch: [0][ 540/1282]\tTime  0.783 ( 2.471)\tData  0.002 ( 1.622)\tLoss 4.5252e+00 (5.5372e+00)\tAcc@1  11.80 (  5.74)\tAcc@5  27.20 ( 15.78)\n",
      "Epoch: [0][ 550/1282]\tTime  0.781 ( 2.471)\tData  0.002 ( 1.623)\tLoss 4.6077e+00 (5.5207e+00)\tAcc@1  11.60 (  5.85)\tAcc@5  30.80 ( 16.03)\n",
      "Epoch: [0][ 560/1282]\tTime  0.750 ( 2.470)\tData  0.002 ( 1.623)\tLoss 4.4756e+00 (5.5042e+00)\tAcc@1  15.40 (  5.97)\tAcc@5  32.60 ( 16.29)\n",
      "Epoch: [0][ 570/1282]\tTime  0.749 ( 2.471)\tData  0.003 ( 1.626)\tLoss 4.5426e+00 (5.4876e+00)\tAcc@1  10.80 (  6.09)\tAcc@5  29.80 ( 16.54)\n",
      "Epoch: [0][ 580/1282]\tTime  0.749 ( 2.473)\tData  0.002 ( 1.629)\tLoss 4.5533e+00 (5.4717e+00)\tAcc@1  14.80 (  6.20)\tAcc@5  31.60 ( 16.77)\n",
      "Epoch: [0][ 590/1282]\tTime  0.774 ( 2.474)\tData  0.002 ( 1.631)\tLoss 4.7032e+00 (5.4564e+00)\tAcc@1  12.80 (  6.32)\tAcc@5  29.00 ( 17.01)\n",
      "Epoch: [0][ 600/1282]\tTime  0.762 ( 2.476)\tData  0.002 ( 1.634)\tLoss 4.7147e+00 (5.4415e+00)\tAcc@1  10.80 (  6.43)\tAcc@5  27.40 ( 17.25)\n",
      "Epoch: [0][ 610/1282]\tTime  0.777 ( 2.477)\tData  0.002 ( 1.636)\tLoss 4.6056e+00 (5.4258e+00)\tAcc@1  13.00 (  6.54)\tAcc@5  30.80 ( 17.51)\n",
      "Epoch: [0][ 620/1282]\tTime  0.768 ( 2.480)\tData  0.002 ( 1.640)\tLoss 4.4533e+00 (5.4108e+00)\tAcc@1  11.80 (  6.66)\tAcc@5  33.60 ( 17.74)\n",
      "Epoch: [0][ 630/1282]\tTime  0.764 ( 2.482)\tData  0.002 ( 1.643)\tLoss 4.3326e+00 (5.3958e+00)\tAcc@1  16.80 (  6.79)\tAcc@5  36.60 ( 17.98)\n",
      "Epoch: [0][ 640/1282]\tTime  0.765 ( 2.483)\tData  0.002 ( 1.645)\tLoss 4.5299e+00 (5.3810e+00)\tAcc@1  13.00 (  6.90)\tAcc@5  30.80 ( 18.22)\n",
      "Epoch: [0][ 650/1282]\tTime  0.740 ( 2.482)\tData  0.002 ( 1.645)\tLoss 4.3092e+00 (5.3667e+00)\tAcc@1  17.40 (  7.02)\tAcc@5  35.60 ( 18.46)\n",
      "Epoch: [0][ 660/1282]\tTime  0.736 ( 2.482)\tData  0.002 ( 1.647)\tLoss 4.3440e+00 (5.3521e+00)\tAcc@1  16.00 (  7.14)\tAcc@5  36.80 ( 18.70)\n",
      "Epoch: [0][ 670/1282]\tTime  0.763 ( 2.483)\tData  0.002 ( 1.648)\tLoss 4.3436e+00 (5.3373e+00)\tAcc@1  13.80 (  7.26)\tAcc@5  36.40 ( 18.95)\n",
      "Epoch: [0][ 680/1282]\tTime  0.770 ( 2.485)\tData  0.002 ( 1.651)\tLoss 4.3613e+00 (5.3229e+00)\tAcc@1  16.40 (  7.38)\tAcc@5  36.20 ( 19.19)\n",
      "Epoch: [0][ 690/1282]\tTime  0.738 ( 2.487)\tData  0.002 ( 1.654)\tLoss 4.3041e+00 (5.3088e+00)\tAcc@1  15.00 (  7.49)\tAcc@5  35.00 ( 19.40)\n",
      "Epoch: [0][ 700/1282]\tTime  0.768 ( 2.489)\tData  0.002 ( 1.657)\tLoss 4.3815e+00 (5.2950e+00)\tAcc@1  14.20 (  7.60)\tAcc@5  34.20 ( 19.63)\n",
      "Epoch: [0][ 710/1282]\tTime  0.770 ( 2.490)\tData  0.002 ( 1.659)\tLoss 4.4407e+00 (5.2806e+00)\tAcc@1  14.20 (  7.73)\tAcc@5  32.40 ( 19.87)\n",
      "Epoch: [0][ 720/1282]\tTime  0.830 ( 2.490)\tData  0.002 ( 1.660)\tLoss 4.1908e+00 (5.2676e+00)\tAcc@1  17.00 (  7.83)\tAcc@5  38.20 ( 20.08)\n",
      "Epoch: [0][ 730/1282]\tTime  0.830 ( 2.490)\tData  0.002 ( 1.660)\tLoss 4.3151e+00 (5.2536e+00)\tAcc@1  15.60 (  7.95)\tAcc@5  35.20 ( 20.31)\n",
      "Epoch: [0][ 740/1282]\tTime  0.824 ( 2.489)\tData  0.002 ( 1.659)\tLoss 4.3720e+00 (5.2401e+00)\tAcc@1  15.20 (  8.07)\tAcc@5  37.40 ( 20.55)\n",
      "Epoch: [0][ 750/1282]\tTime  0.909 ( 2.490)\tData  0.002 ( 1.660)\tLoss 4.2595e+00 (5.2264e+00)\tAcc@1  14.00 (  8.18)\tAcc@5  35.60 ( 20.78)\n",
      "Epoch: [0][ 760/1282]\tTime  0.916 ( 2.491)\tData  0.002 ( 1.660)\tLoss 4.3420e+00 (5.2127e+00)\tAcc@1  16.40 (  8.31)\tAcc@5  35.40 ( 21.01)\n",
      "Epoch: [0][ 770/1282]\tTime  0.740 ( 2.491)\tData  0.003 ( 1.661)\tLoss 3.9809e+00 (5.1989e+00)\tAcc@1  19.60 (  8.43)\tAcc@5  41.60 ( 21.23)\n",
      "Epoch: [0][ 780/1282]\tTime  0.740 ( 2.492)\tData  0.002 ( 1.662)\tLoss 4.0862e+00 (5.1854e+00)\tAcc@1  18.60 (  8.55)\tAcc@5  41.20 ( 21.47)\n",
      "Epoch: [0][ 790/1282]\tTime  0.735 ( 2.492)\tData  0.002 ( 1.664)\tLoss 4.0402e+00 (5.1722e+00)\tAcc@1  16.80 (  8.66)\tAcc@5  41.40 ( 21.69)\n",
      "Epoch: [0][ 800/1282]\tTime  0.766 ( 2.492)\tData  0.002 ( 1.665)\tLoss 4.0705e+00 (5.1593e+00)\tAcc@1  18.00 (  8.78)\tAcc@5  41.00 ( 21.90)\n",
      "Epoch: [0][ 810/1282]\tTime  0.736 ( 2.491)\tData  0.002 ( 1.664)\tLoss 4.1636e+00 (5.1466e+00)\tAcc@1  19.00 (  8.89)\tAcc@5  39.00 ( 22.11)\n",
      "Epoch: [0][ 820/1282]\tTime  0.761 ( 2.489)\tData  0.002 ( 1.663)\tLoss 4.2191e+00 (5.1338e+00)\tAcc@1  17.20 (  9.00)\tAcc@5  39.60 ( 22.33)\n",
      "Epoch: [0][ 830/1282]\tTime  0.742 ( 2.488)\tData  0.002 ( 1.662)\tLoss 4.1265e+00 (5.1213e+00)\tAcc@1  18.20 (  9.12)\tAcc@5  39.60 ( 22.55)\n",
      "Epoch: [0][ 840/1282]\tTime  0.739 ( 2.487)\tData  0.002 ( 1.662)\tLoss 4.1101e+00 (5.1091e+00)\tAcc@1  16.20 (  9.23)\tAcc@5  36.80 ( 22.75)\n",
      "Epoch: [0][ 850/1282]\tTime  0.765 ( 2.486)\tData  0.002 ( 1.662)\tLoss 3.8771e+00 (5.0963e+00)\tAcc@1  20.40 (  9.36)\tAcc@5  43.40 ( 22.97)\n",
      "Epoch: [0][ 860/1282]\tTime  0.741 ( 2.486)\tData  0.002 ( 1.662)\tLoss 4.0636e+00 (5.0841e+00)\tAcc@1  17.60 (  9.48)\tAcc@5  42.20 ( 23.18)\n",
      "Epoch: [0][ 870/1282]\tTime  0.739 ( 2.485)\tData  0.002 ( 1.662)\tLoss 3.9225e+00 (5.0719e+00)\tAcc@1  20.60 (  9.59)\tAcc@5  42.20 ( 23.39)\n",
      "Epoch: [0][ 880/1282]\tTime  0.829 ( 2.484)\tData  0.002 ( 1.661)\tLoss 4.0230e+00 (5.0602e+00)\tAcc@1  19.20 (  9.69)\tAcc@5  41.20 ( 23.59)\n",
      "Epoch: [0][ 890/1282]\tTime  0.836 ( 2.483)\tData  0.002 ( 1.661)\tLoss 4.0297e+00 (5.0481e+00)\tAcc@1  20.40 (  9.81)\tAcc@5  41.60 ( 23.79)\n",
      "Epoch: [0][ 900/1282]\tTime  0.954 ( 2.483)\tData  0.002 ( 1.661)\tLoss 4.0016e+00 (5.0365e+00)\tAcc@1  18.40 (  9.91)\tAcc@5  42.80 ( 23.99)\n",
      "Epoch: [0][ 910/1282]\tTime  0.930 ( 2.482)\tData  0.002 ( 1.659)\tLoss 3.8779e+00 (5.0250e+00)\tAcc@1  20.80 ( 10.02)\tAcc@5  45.20 ( 24.19)\n",
      "Epoch: [0][ 920/1282]\tTime  0.930 ( 2.480)\tData  0.002 ( 1.657)\tLoss 3.8788e+00 (5.0130e+00)\tAcc@1  22.00 ( 10.13)\tAcc@5  44.20 ( 24.40)\n",
      "Epoch: [0][ 930/1282]\tTime  0.931 ( 2.479)\tData  0.002 ( 1.655)\tLoss 3.9177e+00 (5.0013e+00)\tAcc@1  22.40 ( 10.25)\tAcc@5  42.60 ( 24.60)\n",
      "Epoch: [0][ 940/1282]\tTime  0.929 ( 2.478)\tData  0.002 ( 1.655)\tLoss 3.9831e+00 (4.9903e+00)\tAcc@1  23.00 ( 10.36)\tAcc@5  43.80 ( 24.80)\n",
      "Epoch: [0][ 950/1282]\tTime  1.321 ( 2.478)\tData  0.002 ( 1.652)\tLoss 4.0745e+00 (4.9792e+00)\tAcc@1  18.80 ( 10.48)\tAcc@5  39.40 ( 25.00)\n",
      "Epoch: [0][ 960/1282]\tTime  3.690 ( 2.480)\tData  0.002 ( 1.644)\tLoss 3.8915e+00 (4.9680e+00)\tAcc@1  20.80 ( 10.59)\tAcc@5  42.80 ( 25.20)\n",
      "Epoch: [0][ 970/1282]\tTime  4.145 ( 2.481)\tData  0.002 ( 1.629)\tLoss 3.9574e+00 (4.9567e+00)\tAcc@1  18.20 ( 10.70)\tAcc@5  38.60 ( 25.40)\n",
      "Epoch: [0][ 980/1282]\tTime  3.650 ( 2.480)\tData  0.002 ( 1.614)\tLoss 3.7181e+00 (4.9456e+00)\tAcc@1  28.00 ( 10.82)\tAcc@5  48.40 ( 25.59)\n",
      "Epoch: [0][ 990/1282]\tTime  3.111 ( 2.479)\tData  0.002 ( 1.604)\tLoss 3.8471e+00 (4.9344e+00)\tAcc@1  20.80 ( 10.93)\tAcc@5  44.20 ( 25.79)\n",
      "Epoch: [0][1000/1282]\tTime  1.761 ( 2.476)\tData  0.002 ( 1.595)\tLoss 3.9347e+00 (4.9239e+00)\tAcc@1  20.20 ( 11.03)\tAcc@5  45.80 ( 25.98)\n",
      "Epoch: [0][1010/1282]\tTime  4.304 ( 2.478)\tData  0.002 ( 1.586)\tLoss 3.7423e+00 (4.9132e+00)\tAcc@1  23.00 ( 11.13)\tAcc@5  47.60 ( 26.17)\n",
      "Epoch: [0][1020/1282]\tTime  3.870 ( 2.478)\tData  0.002 ( 1.570)\tLoss 3.8193e+00 (4.9028e+00)\tAcc@1  23.40 ( 11.23)\tAcc@5  46.80 ( 26.35)\n",
      "Epoch: [0][1030/1282]\tTime  4.252 ( 2.479)\tData  0.002 ( 1.555)\tLoss 3.7996e+00 (4.8918e+00)\tAcc@1  23.60 ( 11.35)\tAcc@5  46.00 ( 26.54)\n",
      "Epoch: [0][1040/1282]\tTime  4.085 ( 2.478)\tData  0.002 ( 1.540)\tLoss 3.7367e+00 (4.8810e+00)\tAcc@1  22.00 ( 11.46)\tAcc@5  44.20 ( 26.73)\n",
      "Epoch: [0][1050/1282]\tTime  3.581 ( 2.476)\tData  0.003 ( 1.526)\tLoss 3.6104e+00 (4.8702e+00)\tAcc@1  25.40 ( 11.57)\tAcc@5  52.40 ( 26.93)\n",
      "Epoch: [0][1060/1282]\tTime  3.505 ( 2.475)\tData  0.002 ( 1.512)\tLoss 3.7388e+00 (4.8596e+00)\tAcc@1  21.80 ( 11.69)\tAcc@5  47.60 ( 27.12)\n",
      "Epoch: [0][1070/1282]\tTime  3.229 ( 2.474)\tData  0.002 ( 1.501)\tLoss 3.7890e+00 (4.8499e+00)\tAcc@1  23.60 ( 11.78)\tAcc@5  45.60 ( 27.29)\n",
      "Epoch: [0][1080/1282]\tTime  3.577 ( 2.474)\tData  0.002 ( 1.494)\tLoss 3.6838e+00 (4.8395e+00)\tAcc@1  23.40 ( 11.89)\tAcc@5  51.60 ( 27.48)\n",
      "Epoch: [0][1090/1282]\tTime  1.555 ( 2.473)\tData  0.002 ( 1.486)\tLoss 3.7186e+00 (4.8294e+00)\tAcc@1  23.00 ( 12.00)\tAcc@5  48.00 ( 27.66)\n",
      "Epoch: [0][1100/1282]\tTime  0.949 ( 2.472)\tData  0.002 ( 1.484)\tLoss 3.7717e+00 (4.8188e+00)\tAcc@1  21.20 ( 12.11)\tAcc@5  46.40 ( 27.84)\n",
      "Epoch: [0][1110/1282]\tTime  0.825 ( 2.471)\tData  0.002 ( 1.485)\tLoss 3.6729e+00 (4.8094e+00)\tAcc@1  22.60 ( 12.20)\tAcc@5  48.40 ( 28.01)\n",
      "Epoch: [0][1120/1282]\tTime  0.833 ( 2.471)\tData  0.002 ( 1.487)\tLoss 3.7210e+00 (4.7992e+00)\tAcc@1  23.40 ( 12.31)\tAcc@5  45.60 ( 28.20)\n",
      "Epoch: [0][1130/1282]\tTime  0.837 ( 2.471)\tData  0.002 ( 1.488)\tLoss 3.7650e+00 (4.7896e+00)\tAcc@1  24.20 ( 12.42)\tAcc@5  47.80 ( 28.37)\n",
      "Epoch: [0][1140/1282]\tTime  0.862 ( 2.470)\tData  0.002 ( 1.488)\tLoss 3.5058e+00 (4.7795e+00)\tAcc@1  26.40 ( 12.53)\tAcc@5  52.40 ( 28.55)\n",
      "Epoch: [0][1150/1282]\tTime  0.831 ( 2.469)\tData  0.002 ( 1.489)\tLoss 3.7038e+00 (4.7695e+00)\tAcc@1  24.80 ( 12.64)\tAcc@5  49.60 ( 28.73)\n",
      "Epoch: [0][1160/1282]\tTime  1.952 ( 2.470)\tData  0.003 ( 1.488)\tLoss 3.7856e+00 (4.7603e+00)\tAcc@1  21.00 ( 12.73)\tAcc@5  45.80 ( 28.89)\n",
      "Epoch: [0][1170/1282]\tTime  1.880 ( 2.471)\tData  0.002 ( 1.478)\tLoss 3.7822e+00 (4.7512e+00)\tAcc@1  25.20 ( 12.83)\tAcc@5  46.80 ( 29.05)\n",
      "Epoch: [0][1180/1282]\tTime  1.032 ( 2.471)\tData  0.002 ( 1.468)\tLoss 3.7136e+00 (4.7414e+00)\tAcc@1  22.80 ( 12.94)\tAcc@5  47.40 ( 29.22)\n",
      "Epoch: [0][1190/1282]\tTime  0.793 ( 2.471)\tData  0.002 ( 1.458)\tLoss 3.7211e+00 (4.7319e+00)\tAcc@1  24.00 ( 13.03)\tAcc@5  49.20 ( 29.40)\n",
      "Epoch: [0][1200/1282]\tTime  0.755 ( 2.469)\tData  0.002 ( 1.446)\tLoss 3.5298e+00 (4.7221e+00)\tAcc@1  27.40 ( 13.14)\tAcc@5  50.40 ( 29.57)\n",
      "Epoch: [0][1210/1282]\tTime  0.760 ( 2.469)\tData  0.002 ( 1.434)\tLoss 3.6942e+00 (4.7123e+00)\tAcc@1  24.40 ( 13.25)\tAcc@5  47.00 ( 29.75)\n",
      "Epoch: [0][1220/1282]\tTime  0.755 ( 2.468)\tData  0.002 ( 1.423)\tLoss 3.6490e+00 (4.7032e+00)\tAcc@1  23.80 ( 13.35)\tAcc@5  47.80 ( 29.91)\n",
      "Epoch: [0][1230/1282]\tTime  0.755 ( 2.467)\tData  0.002 ( 1.415)\tLoss 3.6179e+00 (4.6939e+00)\tAcc@1  26.00 ( 13.45)\tAcc@5  49.60 ( 30.08)\n",
      "Epoch: [0][1240/1282]\tTime  0.740 ( 2.466)\tData  0.002 ( 1.410)\tLoss 3.5138e+00 (4.6849e+00)\tAcc@1  25.20 ( 13.54)\tAcc@5  52.60 ( 30.24)\n",
      "Epoch: [0][1250/1282]\tTime  0.734 ( 2.465)\tData  0.002 ( 1.403)\tLoss 3.3763e+00 (4.6755e+00)\tAcc@1  27.00 ( 13.64)\tAcc@5  53.60 ( 30.41)\n",
      "Epoch: [0][1260/1282]\tTime  0.730 ( 2.465)\tData  0.002 ( 1.394)\tLoss 3.6597e+00 (4.6665e+00)\tAcc@1  23.60 ( 13.74)\tAcc@5  47.80 ( 30.57)\n",
      "Epoch: [0][1270/1282]\tTime  0.731 ( 2.464)\tData  0.002 ( 1.388)\tLoss 3.4832e+00 (4.6575e+00)\tAcc@1  27.00 ( 13.84)\tAcc@5  52.00 ( 30.73)\n",
      "Epoch: [0][1280/1282]\tTime  0.729 ( 2.463)\tData  0.002 ( 1.382)\tLoss 3.3601e+00 (4.6481e+00)\tAcc@1  30.20 ( 13.95)\tAcc@5  54.40 ( 30.91)\n",
      "Test: [0/3]\tTime  8.884 ( 8.884)\tLoss 3.7918e+00 (3.7918e+00)\tAcc@1  20.80 ( 20.80)\tAcc@5  45.60 ( 45.60)\n",
      " * Acc@1 20.280 Acc@5 43.257\n",
      "lr: [0.0]\n",
      "Epoch: [1][   0/1282]\tTime  6.143 ( 6.143)\tData  5.340 ( 5.340)\tLoss 3.6095e+00 (3.6095e+00)\tAcc@1  25.20 ( 25.20)\tAcc@5  50.00 ( 50.00)\n",
      "Epoch: [1][  10/1282]\tTime  4.060 ( 2.796)\tData  2.474 ( 1.874)\tLoss 3.6239e+00 (3.5046e+00)\tAcc@1  24.40 ( 26.38)\tAcc@5  48.80 ( 51.78)\n",
      "Epoch: [1][  20/1282]\tTime  3.980 ( 2.577)\tData  2.704 ( 1.601)\tLoss 3.5821e+00 (3.5191e+00)\tAcc@1  25.20 ( 26.01)\tAcc@5  50.20 ( 51.14)\n",
      "Epoch: [1][  30/1282]\tTime  4.279 ( 2.534)\tData  2.139 ( 1.436)\tLoss 3.5028e+00 (3.5057e+00)\tAcc@1  27.20 ( 26.47)\tAcc@5  51.00 ( 51.33)\n",
      "Epoch: [1][  40/1282]\tTime  4.317 ( 2.550)\tData  0.091 ( 1.202)\tLoss 3.6059e+00 (3.5146e+00)\tAcc@1  24.40 ( 26.68)\tAcc@5  48.60 ( 51.20)\n",
      "Epoch: [1][  50/1282]\tTime  3.757 ( 2.506)\tData  1.372 ( 1.018)\tLoss 3.6258e+00 (3.5167e+00)\tAcc@1  27.00 ( 26.78)\tAcc@5  49.20 ( 51.07)\n",
      "Epoch: [1][  60/1282]\tTime  2.784 ( 2.493)\tData  0.637 ( 0.940)\tLoss 3.4733e+00 (3.5212e+00)\tAcc@1  30.00 ( 26.69)\tAcc@5  52.00 ( 51.06)\n",
      "Epoch: [1][  70/1282]\tTime  3.634 ( 2.505)\tData  0.002 ( 0.814)\tLoss 3.5245e+00 (3.5206e+00)\tAcc@1  23.80 ( 26.70)\tAcc@5  49.40 ( 51.14)\n",
      "Epoch: [1][  80/1282]\tTime  2.497 ( 2.499)\tData  0.002 ( 0.714)\tLoss 3.5535e+00 (3.5252e+00)\tAcc@1  27.20 ( 26.65)\tAcc@5  51.40 ( 51.05)\n",
      "Epoch: [1][  90/1282]\tTime  3.352 ( 2.496)\tData  0.002 ( 0.636)\tLoss 3.5629e+00 (3.5269e+00)\tAcc@1  24.80 ( 26.54)\tAcc@5  46.60 ( 50.99)\n",
      "Epoch: [1][ 100/1282]\tTime  2.610 ( 2.499)\tData  0.002 ( 0.573)\tLoss 3.2924e+00 (3.5201e+00)\tAcc@1  30.80 ( 26.58)\tAcc@5  56.60 ( 51.12)\n",
      "Epoch: [1][ 110/1282]\tTime  2.171 ( 2.493)\tData  0.002 ( 0.522)\tLoss 3.3405e+00 (3.5180e+00)\tAcc@1  29.40 ( 26.61)\tAcc@5  55.60 ( 51.15)\n",
      "Epoch: [1][ 120/1282]\tTime  2.676 ( 2.504)\tData  0.002 ( 0.479)\tLoss 3.3799e+00 (3.5162e+00)\tAcc@1  27.20 ( 26.64)\tAcc@5  54.00 ( 51.20)\n",
      "Epoch: [1][ 130/1282]\tTime  3.266 ( 2.512)\tData  0.002 ( 0.443)\tLoss 3.3646e+00 (3.5186e+00)\tAcc@1  28.80 ( 26.58)\tAcc@5  53.80 ( 51.13)\n",
      "Epoch: [1][ 140/1282]\tTime  2.611 ( 2.502)\tData  0.003 ( 0.411)\tLoss 3.5639e+00 (3.5194e+00)\tAcc@1  25.40 ( 26.59)\tAcc@5  49.20 ( 51.12)\n",
      "Epoch: [1][ 150/1282]\tTime  1.490 ( 2.488)\tData  0.002 ( 0.384)\tLoss 3.4796e+00 (3.5146e+00)\tAcc@1  30.00 ( 26.63)\tAcc@5  51.60 ( 51.21)\n",
      "Epoch: [1][ 160/1282]\tTime  1.034 ( 2.479)\tData  0.002 ( 0.361)\tLoss 3.4705e+00 (3.5141e+00)\tAcc@1  28.80 ( 26.67)\tAcc@5  54.20 ( 51.26)\n",
      "Epoch: [1][ 170/1282]\tTime  1.808 ( 2.474)\tData  0.002 ( 0.340)\tLoss 3.3835e+00 (3.5136e+00)\tAcc@1  27.60 ( 26.68)\tAcc@5  51.20 ( 51.22)\n",
      "Epoch: [1][ 180/1282]\tTime  2.148 ( 2.467)\tData  0.003 ( 0.323)\tLoss 3.5994e+00 (3.5138e+00)\tAcc@1  25.00 ( 26.65)\tAcc@5  49.80 ( 51.18)\n",
      "Epoch: [1][ 190/1282]\tTime  3.451 ( 2.466)\tData  0.002 ( 0.317)\tLoss 3.5746e+00 (3.5125e+00)\tAcc@1  26.20 ( 26.70)\tAcc@5  49.80 ( 51.21)\n",
      "Epoch: [1][ 200/1282]\tTime  2.035 ( 2.456)\tData  0.002 ( 0.326)\tLoss 3.5856e+00 (3.5157e+00)\tAcc@1  26.20 ( 26.64)\tAcc@5  50.40 ( 51.15)\n",
      "Epoch: [1][ 210/1282]\tTime  2.908 ( 2.456)\tData  0.002 ( 0.345)\tLoss 3.4944e+00 (3.5166e+00)\tAcc@1  25.80 ( 26.63)\tAcc@5  53.20 ( 51.19)\n",
      "Epoch: [1][ 220/1282]\tTime  1.835 ( 2.450)\tData  0.002 ( 0.364)\tLoss 3.4384e+00 (3.5190e+00)\tAcc@1  27.60 ( 26.60)\tAcc@5  53.00 ( 51.15)\n",
      "Epoch: [1][ 230/1282]\tTime  1.516 ( 2.445)\tData  0.002 ( 0.392)\tLoss 3.4273e+00 (3.5197e+00)\tAcc@1  26.40 ( 26.59)\tAcc@5  52.40 ( 51.14)\n",
      "Epoch: [1][ 240/1282]\tTime  1.784 ( 2.442)\tData  0.002 ( 0.421)\tLoss 3.4539e+00 (3.5175e+00)\tAcc@1  27.80 ( 26.62)\tAcc@5  52.40 ( 51.20)\n",
      "Epoch: [1][ 250/1282]\tTime  2.148 ( 2.442)\tData  0.002 ( 0.443)\tLoss 3.5882e+00 (3.5173e+00)\tAcc@1  27.60 ( 26.64)\tAcc@5  50.60 ( 51.20)\n",
      "Epoch: [1][ 260/1282]\tTime  3.308 ( 2.446)\tData  0.002 ( 0.453)\tLoss 3.6154e+00 (3.5150e+00)\tAcc@1  23.20 ( 26.65)\tAcc@5  49.60 ( 51.25)\n",
      "Epoch: [1][ 270/1282]\tTime  4.148 ( 2.449)\tData  0.002 ( 0.445)\tLoss 3.6138e+00 (3.5159e+00)\tAcc@1  26.60 ( 26.66)\tAcc@5  48.40 ( 51.23)\n",
      "Epoch: [1][ 280/1282]\tTime  3.366 ( 2.446)\tData  0.002 ( 0.431)\tLoss 3.4909e+00 (3.5153e+00)\tAcc@1  25.40 ( 26.65)\tAcc@5  52.60 ( 51.21)\n",
      "Epoch: [1][ 290/1282]\tTime  3.557 ( 2.447)\tData  0.003 ( 0.429)\tLoss 3.3636e+00 (3.5136e+00)\tAcc@1  29.00 ( 26.71)\tAcc@5  53.80 ( 51.26)\n",
      "Epoch: [1][ 300/1282]\tTime  4.318 ( 2.449)\tData  0.002 ( 0.418)\tLoss 3.5228e+00 (3.5130e+00)\tAcc@1  27.20 ( 26.74)\tAcc@5  48.20 ( 51.28)\n",
      "Epoch: [1][ 310/1282]\tTime  4.537 ( 2.453)\tData  0.002 ( 0.405)\tLoss 3.5515e+00 (3.5119e+00)\tAcc@1  24.40 ( 26.74)\tAcc@5  51.60 ( 51.29)\n",
      "Epoch: [1][ 320/1282]\tTime  4.043 ( 2.456)\tData  0.002 ( 0.392)\tLoss 3.6033e+00 (3.5127e+00)\tAcc@1  25.80 ( 26.72)\tAcc@5  49.00 ( 51.30)\n",
      "Epoch: [1][ 330/1282]\tTime  3.697 ( 2.452)\tData  0.002 ( 0.380)\tLoss 3.3687e+00 (3.5134e+00)\tAcc@1  26.80 ( 26.70)\tAcc@5  54.60 ( 51.29)\n",
      "Epoch: [1][ 340/1282]\tTime  4.180 ( 2.449)\tData  0.002 ( 0.369)\tLoss 3.4257e+00 (3.5125e+00)\tAcc@1  26.60 ( 26.70)\tAcc@5  51.80 ( 51.29)\n",
      "Epoch: [1][ 350/1282]\tTime  4.120 ( 2.446)\tData  0.002 ( 0.359)\tLoss 3.5878e+00 (3.5120e+00)\tAcc@1  29.20 ( 26.70)\tAcc@5  49.80 ( 51.29)\n",
      "Epoch: [1][ 360/1282]\tTime  3.640 ( 2.443)\tData  0.003 ( 0.351)\tLoss 3.5240e+00 (3.5117e+00)\tAcc@1  29.00 ( 26.69)\tAcc@5  51.60 ( 51.29)\n",
      "Epoch: [1][ 370/1282]\tTime  4.100 ( 2.443)\tData  0.002 ( 0.346)\tLoss 3.5230e+00 (3.5119e+00)\tAcc@1  28.80 ( 26.68)\tAcc@5  51.80 ( 51.28)\n",
      "Epoch: [1][ 380/1282]\tTime  3.804 ( 2.440)\tData  0.002 ( 0.339)\tLoss 3.4742e+00 (3.5123e+00)\tAcc@1  28.00 ( 26.65)\tAcc@5  50.20 ( 51.27)\n",
      "Epoch: [1][ 390/1282]\tTime  4.305 ( 2.440)\tData  0.003 ( 0.331)\tLoss 3.5803e+00 (3.5123e+00)\tAcc@1  24.80 ( 26.66)\tAcc@5  50.20 ( 51.27)\n",
      "Epoch: [1][ 400/1282]\tTime  3.836 ( 2.438)\tData  0.002 ( 0.323)\tLoss 3.4076e+00 (3.5125e+00)\tAcc@1  27.00 ( 26.66)\tAcc@5  51.00 ( 51.26)\n",
      "Epoch: [1][ 410/1282]\tTime  3.929 ( 2.437)\tData  0.002 ( 0.316)\tLoss 3.3760e+00 (3.5137e+00)\tAcc@1  28.20 ( 26.65)\tAcc@5  54.00 ( 51.25)\n",
      "Epoch: [1][ 420/1282]\tTime  3.881 ( 2.437)\tData  0.002 ( 0.308)\tLoss 3.4718e+00 (3.5136e+00)\tAcc@1  25.00 ( 26.63)\tAcc@5  52.60 ( 51.24)\n",
      "Epoch: [1][ 430/1282]\tTime  3.008 ( 2.435)\tData  0.002 ( 0.306)\tLoss 3.5614e+00 (3.5134e+00)\tAcc@1  24.80 ( 26.62)\tAcc@5  52.20 ( 51.25)\n",
      "Epoch: [1][ 440/1282]\tTime  3.972 ( 2.435)\tData  0.002 ( 0.302)\tLoss 3.3556e+00 (3.5132e+00)\tAcc@1  28.00 ( 26.62)\tAcc@5  57.00 ( 51.27)\n",
      "Epoch: [1][ 450/1282]\tTime  3.889 ( 2.434)\tData  0.002 ( 0.298)\tLoss 3.2701e+00 (3.5134e+00)\tAcc@1  27.00 ( 26.62)\tAcc@5  55.40 ( 51.25)\n",
      "Epoch: [1][ 460/1282]\tTime  4.197 ( 2.436)\tData  0.002 ( 0.297)\tLoss 3.5807e+00 (3.5129e+00)\tAcc@1  24.80 ( 26.61)\tAcc@5  51.60 ( 51.28)\n",
      "Epoch: [1][ 470/1282]\tTime  4.186 ( 2.436)\tData  0.002 ( 0.292)\tLoss 3.6630e+00 (3.5126e+00)\tAcc@1  23.60 ( 26.60)\tAcc@5  47.40 ( 51.27)\n",
      "Epoch: [1][ 480/1282]\tTime  3.767 ( 2.439)\tData  0.002 ( 0.288)\tLoss 3.4289e+00 (3.5116e+00)\tAcc@1  27.60 ( 26.59)\tAcc@5  53.60 ( 51.28)\n",
      "Epoch: [1][ 490/1282]\tTime  3.756 ( 2.440)\tData  0.002 ( 0.283)\tLoss 3.5164e+00 (3.5120e+00)\tAcc@1  26.00 ( 26.59)\tAcc@5  51.80 ( 51.27)\n",
      "Epoch: [1][ 500/1282]\tTime  5.040 ( 2.444)\tData  0.002 ( 0.278)\tLoss 3.5743e+00 (3.5119e+00)\tAcc@1  27.20 ( 26.60)\tAcc@5  47.40 ( 51.27)\n",
      "Epoch: [1][ 510/1282]\tTime  4.304 ( 2.446)\tData  0.002 ( 0.272)\tLoss 3.6204e+00 (3.5128e+00)\tAcc@1  23.80 ( 26.60)\tAcc@5  48.00 ( 51.25)\n",
      "Epoch: [1][ 520/1282]\tTime  4.336 ( 2.448)\tData  0.002 ( 0.267)\tLoss 3.5520e+00 (3.5118e+00)\tAcc@1  28.60 ( 26.60)\tAcc@5  50.60 ( 51.26)\n",
      "Epoch: [1][ 530/1282]\tTime  3.802 ( 2.446)\tData  0.002 ( 0.262)\tLoss 3.6147e+00 (3.5116e+00)\tAcc@1  24.60 ( 26.60)\tAcc@5  48.60 ( 51.25)\n",
      "Epoch: [1][ 540/1282]\tTime  4.068 ( 2.445)\tData  0.002 ( 0.257)\tLoss 3.3436e+00 (3.5121e+00)\tAcc@1  27.60 ( 26.58)\tAcc@5  51.80 ( 51.23)\n",
      "Epoch: [1][ 550/1282]\tTime  4.198 ( 2.445)\tData  0.003 ( 0.253)\tLoss 3.4253e+00 (3.5118e+00)\tAcc@1  31.40 ( 26.59)\tAcc@5  54.00 ( 51.23)\n",
      "Epoch: [1][ 560/1282]\tTime  4.329 ( 2.446)\tData  0.002 ( 0.248)\tLoss 3.5578e+00 (3.5116e+00)\tAcc@1  24.80 ( 26.59)\tAcc@5  49.60 ( 51.22)\n",
      "Epoch: [1][ 570/1282]\tTime  3.948 ( 2.446)\tData  0.002 ( 0.244)\tLoss 3.5010e+00 (3.5110e+00)\tAcc@1  27.60 ( 26.60)\tAcc@5  50.40 ( 51.22)\n",
      "Epoch: [1][ 580/1282]\tTime  5.558 ( 2.450)\tData  0.003 ( 0.240)\tLoss 3.6592e+00 (3.5115e+00)\tAcc@1  27.40 ( 26.59)\tAcc@5  48.00 ( 51.20)\n",
      "Epoch: [1][ 590/1282]\tTime  4.316 ( 2.449)\tData  0.002 ( 0.236)\tLoss 3.7726e+00 (3.5117e+00)\tAcc@1  25.20 ( 26.57)\tAcc@5  44.60 ( 51.19)\n",
      "Epoch: [1][ 600/1282]\tTime  4.053 ( 2.448)\tData  0.002 ( 0.232)\tLoss 3.7367e+00 (3.5125e+00)\tAcc@1  22.00 ( 26.56)\tAcc@5  47.40 ( 51.17)\n",
      "Epoch: [1][ 610/1282]\tTime  4.051 ( 2.447)\tData  0.003 ( 0.228)\tLoss 3.4903e+00 (3.5117e+00)\tAcc@1  25.20 ( 26.58)\tAcc@5  51.60 ( 51.20)\n",
      "Epoch: [1][ 620/1282]\tTime  4.460 ( 2.446)\tData  0.002 ( 0.224)\tLoss 3.5092e+00 (3.5117e+00)\tAcc@1  25.40 ( 26.57)\tAcc@5  51.80 ( 51.19)\n",
      "Epoch: [1][ 630/1282]\tTime  3.676 ( 2.445)\tData  0.002 ( 0.221)\tLoss 3.4465e+00 (3.5118e+00)\tAcc@1  29.80 ( 26.57)\tAcc@5  51.60 ( 51.19)\n",
      "Epoch: [1][ 640/1282]\tTime  4.016 ( 2.445)\tData  0.002 ( 0.218)\tLoss 3.6658e+00 (3.5119e+00)\tAcc@1  25.60 ( 26.56)\tAcc@5  48.60 ( 51.18)\n",
      "Epoch: [1][ 650/1282]\tTime  3.957 ( 2.445)\tData  0.094 ( 0.216)\tLoss 3.4551e+00 (3.5121e+00)\tAcc@1  27.20 ( 26.56)\tAcc@5  51.60 ( 51.18)\n",
      "Epoch: [1][ 660/1282]\tTime  3.741 ( 2.444)\tData  0.096 ( 0.213)\tLoss 3.4764e+00 (3.5120e+00)\tAcc@1  28.00 ( 26.57)\tAcc@5  52.40 ( 51.18)\n",
      "Epoch: [1][ 670/1282]\tTime  4.222 ( 2.443)\tData  0.655 ( 0.213)\tLoss 3.4495e+00 (3.5115e+00)\tAcc@1  28.00 ( 26.59)\tAcc@5  52.00 ( 51.21)\n",
      "Epoch: [1][ 680/1282]\tTime  3.821 ( 2.442)\tData  1.076 ( 0.215)\tLoss 3.5265e+00 (3.5113e+00)\tAcc@1  28.00 ( 26.60)\tAcc@5  54.80 ( 51.21)\n",
      "Epoch: [1][ 690/1282]\tTime  4.321 ( 2.442)\tData  0.091 ( 0.216)\tLoss 3.5010e+00 (3.5115e+00)\tAcc@1  28.60 ( 26.60)\tAcc@5  50.40 ( 51.21)\n",
      "Epoch: [1][ 700/1282]\tTime  3.656 ( 2.441)\tData  0.094 ( 0.214)\tLoss 3.5641e+00 (3.5109e+00)\tAcc@1  23.60 ( 26.61)\tAcc@5  49.20 ( 51.22)\n",
      "Epoch: [1][ 710/1282]\tTime  3.734 ( 2.441)\tData  0.106 ( 0.212)\tLoss 3.6324e+00 (3.5101e+00)\tAcc@1  25.00 ( 26.62)\tAcc@5  47.00 ( 51.23)\n",
      "Epoch: [1][ 720/1282]\tTime  3.913 ( 2.441)\tData  0.299 ( 0.211)\tLoss 3.4726e+00 (3.5102e+00)\tAcc@1  27.60 ( 26.62)\tAcc@5  50.60 ( 51.23)\n",
      "Epoch: [1][ 730/1282]\tTime  4.422 ( 2.441)\tData  0.094 ( 0.209)\tLoss 3.5414e+00 (3.5099e+00)\tAcc@1  27.40 ( 26.63)\tAcc@5  52.60 ( 51.23)\n",
      "Epoch: [1][ 740/1282]\tTime  4.905 ( 2.444)\tData  0.002 ( 0.206)\tLoss 3.6360e+00 (3.5098e+00)\tAcc@1  24.00 ( 26.64)\tAcc@5  48.60 ( 51.22)\n",
      "Epoch: [1][ 750/1282]\tTime  4.102 ( 2.446)\tData  0.002 ( 0.203)\tLoss 3.5179e+00 (3.5096e+00)\tAcc@1  26.60 ( 26.65)\tAcc@5  51.80 ( 51.23)\n",
      "Epoch: [1][ 760/1282]\tTime  4.193 ( 2.446)\tData  0.002 ( 0.201)\tLoss 3.6534e+00 (3.5091e+00)\tAcc@1  24.20 ( 26.65)\tAcc@5  49.40 ( 51.24)\n",
      "Epoch: [1][ 770/1282]\tTime  4.202 ( 2.446)\tData  0.002 ( 0.198)\tLoss 3.2763e+00 (3.5080e+00)\tAcc@1  29.60 ( 26.66)\tAcc@5  56.00 ( 51.27)\n",
      "Epoch: [1][ 780/1282]\tTime  4.113 ( 2.445)\tData  0.003 ( 0.196)\tLoss 3.3379e+00 (3.5074e+00)\tAcc@1  30.00 ( 26.68)\tAcc@5  55.20 ( 51.29)\n",
      "Epoch: [1][ 790/1282]\tTime  4.102 ( 2.445)\tData  0.002 ( 0.193)\tLoss 3.3624e+00 (3.5068e+00)\tAcc@1  29.00 ( 26.69)\tAcc@5  52.80 ( 51.31)\n",
      "Epoch: [1][ 800/1282]\tTime  4.012 ( 2.445)\tData  0.002 ( 0.191)\tLoss 3.4438e+00 (3.5060e+00)\tAcc@1  25.20 ( 26.69)\tAcc@5  51.80 ( 51.32)\n",
      "Epoch: [1][ 810/1282]\tTime  4.069 ( 2.446)\tData  0.002 ( 0.189)\tLoss 3.5235e+00 (3.5055e+00)\tAcc@1  26.20 ( 26.70)\tAcc@5  49.00 ( 51.33)\n",
      "Epoch: [1][ 820/1282]\tTime  4.233 ( 2.446)\tData  0.003 ( 0.186)\tLoss 3.5001e+00 (3.5051e+00)\tAcc@1  25.40 ( 26.71)\tAcc@5  52.20 ( 51.34)\n",
      "Epoch: [1][ 830/1282]\tTime  4.860 ( 2.447)\tData  0.002 ( 0.184)\tLoss 3.5831e+00 (3.5050e+00)\tAcc@1  24.60 ( 26.71)\tAcc@5  51.20 ( 51.35)\n",
      "Epoch: [1][ 840/1282]\tTime  4.024 ( 2.447)\tData  0.002 ( 0.182)\tLoss 3.5172e+00 (3.5046e+00)\tAcc@1  26.40 ( 26.71)\tAcc@5  49.00 ( 51.36)\n",
      "Epoch: [1][ 850/1282]\tTime  4.609 ( 2.447)\tData  0.003 ( 0.180)\tLoss 3.3214e+00 (3.5039e+00)\tAcc@1  29.60 ( 26.72)\tAcc@5  55.40 ( 51.38)\n",
      "Epoch: [1][ 860/1282]\tTime  3.703 ( 2.446)\tData  0.002 ( 0.178)\tLoss 3.5488e+00 (3.5037e+00)\tAcc@1  22.00 ( 26.72)\tAcc@5  50.60 ( 51.37)\n",
      "Epoch: [1][ 870/1282]\tTime  4.077 ( 2.445)\tData  0.002 ( 0.176)\tLoss 3.3981e+00 (3.5032e+00)\tAcc@1  28.20 ( 26.72)\tAcc@5  53.40 ( 51.37)\n",
      "Epoch: [1][ 880/1282]\tTime  4.477 ( 2.446)\tData  0.002 ( 0.174)\tLoss 3.4430e+00 (3.5032e+00)\tAcc@1  27.80 ( 26.71)\tAcc@5  50.80 ( 51.36)\n",
      "Epoch: [1][ 890/1282]\tTime  4.130 ( 2.446)\tData  0.002 ( 0.172)\tLoss 3.4269e+00 (3.5025e+00)\tAcc@1  28.60 ( 26.72)\tAcc@5  53.40 ( 51.37)\n",
      "Epoch: [1][ 900/1282]\tTime  4.094 ( 2.446)\tData  0.003 ( 0.170)\tLoss 3.5189e+00 (3.5026e+00)\tAcc@1  26.60 ( 26.70)\tAcc@5  52.00 ( 51.37)\n",
      "Epoch: [1][ 910/1282]\tTime  3.945 ( 2.445)\tData  0.002 ( 0.168)\tLoss 3.3881e+00 (3.5025e+00)\tAcc@1  28.00 ( 26.71)\tAcc@5  53.00 ( 51.38)\n",
      "Epoch: [1][ 920/1282]\tTime  3.970 ( 2.446)\tData  0.002 ( 0.166)\tLoss 3.4002e+00 (3.5016e+00)\tAcc@1  28.40 ( 26.72)\tAcc@5  55.20 ( 51.40)\n",
      "Epoch: [1][ 930/1282]\tTime  4.255 ( 2.445)\tData  0.002 ( 0.165)\tLoss 3.5569e+00 (3.5011e+00)\tAcc@1  26.00 ( 26.73)\tAcc@5  50.00 ( 51.41)\n",
      "Epoch: [1][ 940/1282]\tTime  4.164 ( 2.444)\tData  0.002 ( 0.163)\tLoss 3.5983e+00 (3.5009e+00)\tAcc@1  25.20 ( 26.74)\tAcc@5  51.40 ( 51.42)\n",
      "Epoch: [1][ 950/1282]\tTime  4.048 ( 2.444)\tData  0.003 ( 0.161)\tLoss 3.5641e+00 (3.5003e+00)\tAcc@1  24.60 ( 26.75)\tAcc@5  49.60 ( 51.43)\n",
      "Epoch: [1][ 960/1282]\tTime  3.861 ( 2.446)\tData  0.003 ( 0.160)\tLoss 3.4236e+00 (3.4996e+00)\tAcc@1  26.00 ( 26.75)\tAcc@5  51.00 ( 51.44)\n",
      "Epoch: [1][ 970/1282]\tTime  4.029 ( 2.446)\tData  0.002 ( 0.158)\tLoss 3.5083e+00 (3.4989e+00)\tAcc@1  24.80 ( 26.76)\tAcc@5  50.20 ( 51.45)\n",
      "Epoch: [1][ 980/1282]\tTime  4.162 ( 2.448)\tData  0.003 ( 0.156)\tLoss 3.3243e+00 (3.4981e+00)\tAcc@1  30.20 ( 26.78)\tAcc@5  54.20 ( 51.47)\n",
      "Epoch: [1][ 990/1282]\tTime  4.475 ( 2.448)\tData  0.002 ( 0.155)\tLoss 3.3623e+00 (3.4974e+00)\tAcc@1  26.20 ( 26.79)\tAcc@5  54.60 ( 51.47)\n",
      "Epoch: [1][1000/1282]\tTime  3.932 ( 2.447)\tData  0.002 ( 0.153)\tLoss 3.4524e+00 (3.4974e+00)\tAcc@1  26.60 ( 26.78)\tAcc@5  54.40 ( 51.48)\n",
      "Epoch: [1][1010/1282]\tTime  4.243 ( 2.448)\tData  0.002 ( 0.152)\tLoss 3.4316e+00 (3.4969e+00)\tAcc@1  26.80 ( 26.79)\tAcc@5  52.00 ( 51.48)\n",
      "Epoch: [1][1020/1282]\tTime  3.625 ( 2.449)\tData  0.003 ( 0.150)\tLoss 3.4291e+00 (3.4966e+00)\tAcc@1  26.80 ( 26.79)\tAcc@5  54.40 ( 51.49)\n",
      "Epoch: [1][1030/1282]\tTime  4.195 ( 2.450)\tData  0.002 ( 0.149)\tLoss 3.3921e+00 (3.4956e+00)\tAcc@1  29.60 ( 26.81)\tAcc@5  55.60 ( 51.52)\n",
      "Epoch: [1][1040/1282]\tTime  5.242 ( 2.452)\tData  0.002 ( 0.147)\tLoss 3.3630e+00 (3.4948e+00)\tAcc@1  28.80 ( 26.83)\tAcc@5  53.20 ( 51.53)\n",
      "Epoch: [1][1050/1282]\tTime  3.890 ( 2.452)\tData  0.002 ( 0.146)\tLoss 3.3385e+00 (3.4939e+00)\tAcc@1  29.60 ( 26.84)\tAcc@5  55.40 ( 51.55)\n",
      "Epoch: [1][1060/1282]\tTime  4.800 ( 2.453)\tData  0.003 ( 0.145)\tLoss 3.3977e+00 (3.4931e+00)\tAcc@1  29.80 ( 26.86)\tAcc@5  52.60 ( 51.56)\n",
      "Epoch: [1][1070/1282]\tTime  4.407 ( 2.454)\tData  0.002 ( 0.143)\tLoss 3.3579e+00 (3.4928e+00)\tAcc@1  29.00 ( 26.86)\tAcc@5  52.40 ( 51.57)\n",
      "Epoch: [1][1080/1282]\tTime  4.070 ( 2.454)\tData  0.002 ( 0.142)\tLoss 3.3645e+00 (3.4920e+00)\tAcc@1  28.60 ( 26.86)\tAcc@5  55.20 ( 51.58)\n",
      "Epoch: [1][1090/1282]\tTime  4.154 ( 2.453)\tData  0.002 ( 0.141)\tLoss 3.4351e+00 (3.4912e+00)\tAcc@1  26.00 ( 26.87)\tAcc@5  52.80 ( 51.60)\n",
      "Epoch: [1][1100/1282]\tTime  3.567 ( 2.453)\tData  0.002 ( 0.140)\tLoss 3.4217e+00 (3.4902e+00)\tAcc@1  29.40 ( 26.89)\tAcc@5  52.80 ( 51.62)\n",
      "Epoch: [1][1110/1282]\tTime  4.444 ( 2.454)\tData  0.002 ( 0.138)\tLoss 3.4148e+00 (3.4902e+00)\tAcc@1  26.40 ( 26.88)\tAcc@5  51.20 ( 51.61)\n",
      "Epoch: [1][1120/1282]\tTime  4.303 ( 2.453)\tData  0.003 ( 0.137)\tLoss 3.5460e+00 (3.4895e+00)\tAcc@1  24.00 ( 26.89)\tAcc@5  48.80 ( 51.63)\n",
      "Epoch: [1][1130/1282]\tTime  3.987 ( 2.453)\tData  0.002 ( 0.136)\tLoss 3.4363e+00 (3.4890e+00)\tAcc@1  29.00 ( 26.90)\tAcc@5  53.60 ( 51.64)\n",
      "Epoch: [1][1140/1282]\tTime  3.978 ( 2.453)\tData  0.003 ( 0.135)\tLoss 3.2852e+00 (3.4880e+00)\tAcc@1  31.60 ( 26.92)\tAcc@5  56.40 ( 51.66)\n",
      "Epoch: [1][1150/1282]\tTime  4.266 ( 2.453)\tData  0.002 ( 0.134)\tLoss 3.4796e+00 (3.4870e+00)\tAcc@1  28.60 ( 26.94)\tAcc@5  51.20 ( 51.67)\n",
      "Epoch: [1][1160/1282]\tTime  3.980 ( 2.453)\tData  0.002 ( 0.132)\tLoss 3.5087e+00 (3.4864e+00)\tAcc@1  26.20 ( 26.94)\tAcc@5  50.40 ( 51.68)\n",
      "Epoch: [1][1170/1282]\tTime  4.438 ( 2.453)\tData  0.002 ( 0.131)\tLoss 3.5489e+00 (3.4858e+00)\tAcc@1  27.60 ( 26.95)\tAcc@5  50.60 ( 51.69)\n",
      "Epoch: [1][1180/1282]\tTime  3.645 ( 2.452)\tData  0.002 ( 0.130)\tLoss 3.4446e+00 (3.4847e+00)\tAcc@1  27.40 ( 26.97)\tAcc@5  50.40 ( 51.71)\n",
      "Epoch: [1][1190/1282]\tTime  3.747 ( 2.451)\tData  0.002 ( 0.130)\tLoss 3.4347e+00 (3.4835e+00)\tAcc@1  28.40 ( 26.99)\tAcc@5  51.20 ( 51.74)\n",
      "Epoch: [1][1200/1282]\tTime  3.669 ( 2.450)\tData  0.002 ( 0.129)\tLoss 3.3598e+00 (3.4822e+00)\tAcc@1  28.20 ( 27.00)\tAcc@5  53.60 ( 51.76)\n",
      "Epoch: [1][1210/1282]\tTime  3.485 ( 2.449)\tData  0.002 ( 0.129)\tLoss 3.4974e+00 (3.4806e+00)\tAcc@1  26.60 ( 27.02)\tAcc@5  51.00 ( 51.79)\n",
      "Epoch: [1][1220/1282]\tTime  2.528 ( 2.448)\tData  0.002 ( 0.132)\tLoss 3.4524e+00 (3.4795e+00)\tAcc@1  28.20 ( 27.04)\tAcc@5  50.60 ( 51.82)\n",
      "Epoch: [1][1230/1282]\tTime  0.843 ( 2.448)\tData  0.002 ( 0.140)\tLoss 3.2864e+00 (3.4782e+00)\tAcc@1  29.00 ( 27.06)\tAcc@5  56.80 ( 51.84)\n",
      "Epoch: [1][1240/1282]\tTime  0.844 ( 2.448)\tData  0.002 ( 0.152)\tLoss 3.2551e+00 (3.4767e+00)\tAcc@1  32.80 ( 27.08)\tAcc@5  57.20 ( 51.87)\n",
      "Epoch: [1][1250/1282]\tTime  0.861 ( 2.447)\tData  0.002 ( 0.163)\tLoss 3.2122e+00 (3.4746e+00)\tAcc@1  31.80 ( 27.12)\tAcc@5  58.40 ( 51.92)\n",
      "Epoch: [1][1260/1282]\tTime  0.841 ( 2.447)\tData  0.003 ( 0.174)\tLoss 3.3111e+00 (3.4728e+00)\tAcc@1  30.20 ( 27.15)\tAcc@5  53.00 ( 51.94)\n",
      "Epoch: [1][1270/1282]\tTime  0.840 ( 2.446)\tData  0.002 ( 0.185)\tLoss 3.0851e+00 (3.4708e+00)\tAcc@1  35.80 ( 27.18)\tAcc@5  60.20 ( 51.99)\n",
      "Epoch: [1][1280/1282]\tTime  0.851 ( 2.445)\tData  0.002 ( 0.195)\tLoss 3.0875e+00 (3.4678e+00)\tAcc@1  34.40 ( 27.25)\tAcc@5  58.60 ( 52.05)\n",
      "Test: [0/3]\tTime  6.253 ( 6.253)\tLoss 3.3379e+00 (3.3379e+00)\tAcc@1  27.80 ( 27.80)\tAcc@5  56.00 ( 56.00)\n",
      " * Acc@1 26.274 Acc@5 51.049\n",
      "lr: [0.1]\n",
      "CPU times: user 1h 49min 54s, sys: 30min 20s, total: 2h 20min 15s\n",
      "Wall time: 1h 45min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "russian-european",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "governmental-columbia",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5054), started 0:00:00 ago. (Use '!kill 5054' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd613e30d8f16adf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd613e30d8f16adf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "empirical-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1027c4d1c386bbc4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1027c4d1c386bbc4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}  --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "victorian-smile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1e2feb89414c343c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1e2feb89414c343c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=data/ --port=8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-theory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
