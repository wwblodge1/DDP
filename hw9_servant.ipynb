{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ahead-mounting",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modular-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reported-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: wandb in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.12.6)\n",
      "Requirement already satisfied: six>=1.13.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.18.1)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: pathtools in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in ./anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwwblodge1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demanding-indonesian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/11bw1jye\" target=\"_blank\">fluent-voice-26</a></strong> to <a href=\"https://wandb.ai/wwblodge1/hw9_instance\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/hw9_instance/runs/11bw1jye?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f125ebe40d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"hw9_instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-mortality",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "# Assume that this notebook only sees one GPU.\n",
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-mixer",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-commonwealth",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-morgan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "departmental-listing",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-hammer",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 1\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\"\n",
    "\n",
    "global_step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-elite",
   "metadata": {
    "id": "85299ee3"
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"data/train\"\n",
    "VALDIR=\"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pretty-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:11bw1jye) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9754... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fluent-voice-26</strong>: <a href=\"https://wandb.ai/wwblodge1/hw9_instance/runs/11bw1jye\" target=\"_blank\">https://wandb.ai/wwblodge1/hw9_instance/runs/11bw1jye</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211029_195804-11bw1jye/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:11bw1jye). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wwblodge1/uncategorized/runs/273le5se\" target=\"_blank\">dry-plasma-8</a></strong> to <a href=\"https://wandb.ai/wwblodge1/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wwblodge1/uncategorized/runs/273le5se?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f125ebb0150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-eugene",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many processes in cluster?\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "# where is the master?\n",
    "# export NCCL_SOCKET_IFNAME=172.31.24.47\n",
    "URL = 'tcp://172.31.24.47:1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is my rank?\n",
    "RANK = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-melbourne",
   "metadata": {
    "id": "68491838"
   },
   "outputs": [],
   "source": [
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "disturbed-swimming",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device('cpu')\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mineral-gibson",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-fireplace",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "# def train(train_loader, model, criterion, optimizer, epoch):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     data_time = AverageMeter('Data', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(train_loader),\n",
    "#         [batch_time, data_time, losses, top1, top5],\n",
    "#         prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "#     # switch to train mode\n",
    "#     model.train()\n",
    "\n",
    "#     end = time.time()\n",
    "#     for i, (images, target) in enumerate(train_loader):\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # measure accuracy and record loss\n",
    "#         acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#         losses.update(loss.item(), images.size(0))\n",
    "#         top1.update(acc1[0], images.size(0))\n",
    "#         top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if i % PRINT_FREQ == 0:\n",
    "#             progress.display(i)\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-cathedral",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "# def validate(val_loader, model, criterion):\n",
    "#     batch_time = AverageMeter('Time', ':6.3f')\n",
    "#     losses = AverageMeter('Loss', ':.4e')\n",
    "#     top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "#     top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "#     progress = ProgressMeter(\n",
    "#         len(val_loader),\n",
    "#         [batch_time, losses, top1, top5],\n",
    "#         prefix='Test: ')\n",
    "\n",
    "#     # switch to evaluate mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         end = time.time()\n",
    "#         for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#             # compute output\n",
    "#             output = model(images)\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # measure accuracy and record loss\n",
    "#             acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "#             losses.update(loss.item(), images.size(0))\n",
    "#             top1.update(acc1[0], images.size(0))\n",
    "#             top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#             # measure elapsed time\n",
    "#             batch_time.update(time.time() - end)\n",
    "#             end = time.time()\n",
    "\n",
    "#             if i % PRINT_FREQ == 0:\n",
    "#                 progress.display(i)\n",
    "\n",
    "#         # TODO: this should also be done with the ProgressMeter\n",
    "#         print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "#               .format(top1=top1, top5=top5))\n",
    "\n",
    "#     return top1.avg\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-cover",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-cross",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informal-tunisia",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fresh-illustration",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rolled-bullet",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "muslim-edition",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advisory-flesh",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "linear-louisiana",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "anticipated-wound",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "organizational-format",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sacred-welsh",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varying-berry",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "detailed-hungary",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])\n",
    "# model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "homeless-ethernet",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-explorer",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "temporal-attachment",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seven-forum",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "painful-badge",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "durable-median",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparable-anderson",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "damaged-genre",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "productive-optimum",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-commercial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "grateful-margin",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spanish-manitoba",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 11.393 (11.393)\tData  4.442 ( 4.442)\tLoss 7.0184e+00 (7.0184e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.80 (  0.80)\n",
      "Epoch: [0][  10/1282]\tTime  0.839 ( 2.222)\tData  0.087 ( 0.791)\tLoss 6.9115e+00 (6.9741e+00)\tAcc@1   0.40 (  0.09)\tAcc@5   2.00 (  0.65)\n",
      "Epoch: [0][  20/1282]\tTime  0.819 ( 2.041)\tData  0.086 ( 0.830)\tLoss 6.8919e+00 (6.9500e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   2.40 (  0.89)\n",
      "Epoch: [0][  30/1282]\tTime  0.828 ( 1.995)\tData  0.002 ( 0.847)\tLoss 6.8102e+00 (6.9240e+00)\tAcc@1   0.60 (  0.26)\tAcc@5   2.40 (  1.15)\n",
      "Epoch: [0][  40/1282]\tTime  0.839 ( 1.973)\tData  0.003 ( 0.831)\tLoss 6.7028e+00 (6.8782e+00)\tAcc@1   1.40 (  0.45)\tAcc@5   3.40 (  1.55)\n",
      "Epoch: [0][  50/1282]\tTime  0.751 ( 1.968)\tData  0.003 ( 0.753)\tLoss 6.6764e+00 (6.8355e+00)\tAcc@1   0.20 (  0.52)\tAcc@5   3.00 (  1.85)\n",
      "Epoch: [0][  60/1282]\tTime  0.755 ( 1.961)\tData  0.003 ( 0.670)\tLoss 6.4955e+00 (6.7882e+00)\tAcc@1   1.20 (  0.58)\tAcc@5   4.20 (  2.14)\n",
      "Epoch: [0][  70/1282]\tTime  1.279 ( 1.955)\tData  0.520 ( 0.626)\tLoss 6.4509e+00 (6.7485e+00)\tAcc@1   0.80 (  0.61)\tAcc@5   3.80 (  2.35)\n",
      "Epoch: [0][  80/1282]\tTime  0.851 ( 1.948)\tData  0.091 ( 0.643)\tLoss 6.4187e+00 (6.7067e+00)\tAcc@1   2.20 (  0.73)\tAcc@5   4.80 (  2.64)\n",
      "Epoch: [0][  90/1282]\tTime  4.177 ( 1.975)\tData  3.374 ( 0.664)\tLoss 6.3465e+00 (6.6680e+00)\tAcc@1   1.20 (  0.78)\tAcc@5   4.40 (  2.91)\n",
      "Epoch: [0][ 100/1282]\tTime  3.713 ( 2.028)\tData  2.897 ( 0.762)\tLoss 6.1295e+00 (6.6270e+00)\tAcc@1   2.20 (  0.87)\tAcc@5   7.60 (  3.16)\n",
      "Epoch: [0][ 110/1282]\tTime  3.558 ( 2.064)\tData  2.760 ( 0.829)\tLoss 6.0762e+00 (6.5841e+00)\tAcc@1   2.20 (  0.97)\tAcc@5   8.00 (  3.51)\n",
      "Epoch: [0][ 120/1282]\tTime  4.348 ( 2.119)\tData  3.541 ( 0.921)\tLoss 6.0846e+00 (6.5462e+00)\tAcc@1   3.00 (  1.07)\tAcc@5   9.60 (  3.85)\n",
      "Epoch: [0][ 130/1282]\tTime  4.801 ( 2.150)\tData  4.005 ( 0.979)\tLoss 5.9367e+00 (6.5074e+00)\tAcc@1   3.40 (  1.14)\tAcc@5   9.00 (  4.10)\n",
      "Epoch: [0][ 140/1282]\tTime  4.207 ( 2.184)\tData  3.384 ( 1.038)\tLoss 6.0561e+00 (6.4709e+00)\tAcc@1   2.00 (  1.24)\tAcc@5   7.80 (  4.39)\n",
      "Epoch: [0][ 150/1282]\tTime  4.166 ( 2.223)\tData  3.339 ( 1.102)\tLoss 5.9253e+00 (6.4331e+00)\tAcc@1   4.00 (  1.35)\tAcc@5  10.40 (  4.71)\n",
      "Epoch: [0][ 160/1282]\tTime  2.416 ( 2.245)\tData  1.653 ( 1.144)\tLoss 5.8334e+00 (6.3975e+00)\tAcc@1   2.00 (  1.43)\tAcc@5   8.80 (  5.01)\n",
      "Epoch: [0][ 170/1282]\tTime  2.301 ( 2.268)\tData  1.539 ( 1.185)\tLoss 5.7338e+00 (6.3626e+00)\tAcc@1   4.20 (  1.54)\tAcc@5  11.00 (  5.30)\n",
      "Epoch: [0][ 180/1282]\tTime  2.790 ( 2.292)\tData  1.960 ( 1.224)\tLoss 5.8275e+00 (6.3310e+00)\tAcc@1   2.20 (  1.62)\tAcc@5  10.20 (  5.59)\n",
      "Epoch: [0][ 190/1282]\tTime  1.950 ( 2.308)\tData  1.182 ( 1.254)\tLoss 5.7639e+00 (6.3002e+00)\tAcc@1   2.60 (  1.70)\tAcc@5   9.20 (  5.85)\n",
      "Epoch: [0][ 200/1282]\tTime  0.868 ( 2.322)\tData  0.103 ( 1.282)\tLoss 5.7193e+00 (6.2707e+00)\tAcc@1   3.00 (  1.80)\tAcc@5  10.80 (  6.14)\n",
      "Epoch: [0][ 210/1282]\tTime  0.852 ( 2.339)\tData  0.084 ( 1.310)\tLoss 5.6316e+00 (6.2408e+00)\tAcc@1   4.00 (  1.90)\tAcc@5  11.40 (  6.41)\n",
      "Epoch: [0][ 220/1282]\tTime  0.771 ( 2.357)\tData  0.003 ( 1.339)\tLoss 5.5311e+00 (6.2126e+00)\tAcc@1   4.60 (  2.02)\tAcc@5  15.80 (  6.73)\n",
      "Epoch: [0][ 230/1282]\tTime  0.740 ( 2.371)\tData  0.002 ( 1.363)\tLoss 5.5050e+00 (6.1846e+00)\tAcc@1   4.80 (  2.14)\tAcc@5  16.00 (  7.04)\n",
      "Epoch: [0][ 240/1282]\tTime  1.104 ( 2.384)\tData  0.380 ( 1.387)\tLoss 5.4554e+00 (6.1556e+00)\tAcc@1   5.00 (  2.26)\tAcc@5  15.60 (  7.40)\n",
      "Epoch: [0][ 250/1282]\tTime  0.812 ( 2.394)\tData  0.091 ( 1.407)\tLoss 5.5044e+00 (6.1276e+00)\tAcc@1   4.60 (  2.38)\tAcc@5  14.00 (  7.73)\n",
      "Epoch: [0][ 260/1282]\tTime  0.732 ( 2.409)\tData  0.002 ( 1.430)\tLoss 5.5349e+00 (6.1000e+00)\tAcc@1   5.40 (  2.49)\tAcc@5  15.20 (  8.05)\n",
      "Epoch: [0][ 270/1282]\tTime  0.721 ( 2.423)\tData  0.002 ( 1.453)\tLoss 5.3057e+00 (6.0734e+00)\tAcc@1   4.20 (  2.60)\tAcc@5  17.60 (  8.36)\n",
      "Epoch: [0][ 280/1282]\tTime  0.730 ( 2.434)\tData  0.002 ( 1.472)\tLoss 5.2760e+00 (6.0475e+00)\tAcc@1   5.80 (  2.74)\tAcc@5  17.60 (  8.67)\n",
      "Epoch: [0][ 290/1282]\tTime  0.724 ( 2.440)\tData  0.002 ( 1.485)\tLoss 5.3021e+00 (6.0233e+00)\tAcc@1   8.20 (  2.86)\tAcc@5  19.00 (  8.97)\n",
      "Epoch: [0][ 300/1282]\tTime  0.735 ( 2.450)\tData  0.002 ( 1.502)\tLoss 5.1726e+00 (5.9981e+00)\tAcc@1   8.60 (  2.99)\tAcc@5  21.40 (  9.30)\n",
      "Epoch: [0][ 310/1282]\tTime  0.730 ( 2.461)\tData  0.002 ( 1.518)\tLoss 5.2069e+00 (5.9731e+00)\tAcc@1   5.40 (  3.10)\tAcc@5  18.60 (  9.61)\n",
      "Epoch: [0][ 320/1282]\tTime  0.737 ( 2.463)\tData  0.002 ( 1.526)\tLoss 5.1780e+00 (5.9496e+00)\tAcc@1   6.20 (  3.22)\tAcc@5  21.60 (  9.91)\n",
      "Epoch: [0][ 330/1282]\tTime  0.739 ( 2.471)\tData  0.002 ( 1.539)\tLoss 5.2280e+00 (5.9261e+00)\tAcc@1   7.00 (  3.34)\tAcc@5  18.00 ( 10.22)\n",
      "Epoch: [0][ 340/1282]\tTime  0.743 ( 2.475)\tData  0.003 ( 1.549)\tLoss 5.0264e+00 (5.9015e+00)\tAcc@1   6.60 (  3.46)\tAcc@5  19.60 ( 10.53)\n",
      "Epoch: [0][ 350/1282]\tTime  0.742 ( 2.484)\tData  0.002 ( 1.562)\tLoss 5.2194e+00 (5.8791e+00)\tAcc@1   7.80 (  3.58)\tAcc@5  20.00 ( 10.83)\n",
      "Epoch: [0][ 360/1282]\tTime  0.749 ( 2.492)\tData  0.002 ( 1.574)\tLoss 5.0545e+00 (5.8562e+00)\tAcc@1   7.60 (  3.70)\tAcc@5  19.40 ( 11.13)\n",
      "Epoch: [0][ 370/1282]\tTime  0.751 ( 2.502)\tData  0.002 ( 1.588)\tLoss 5.0925e+00 (5.8366e+00)\tAcc@1  10.00 (  3.80)\tAcc@5  21.40 ( 11.39)\n",
      "Epoch: [0][ 380/1282]\tTime  0.752 ( 2.507)\tData  0.002 ( 1.596)\tLoss 4.9553e+00 (5.8153e+00)\tAcc@1  10.00 (  3.91)\tAcc@5  28.00 ( 11.71)\n",
      "Epoch: [0][ 390/1282]\tTime  0.751 ( 2.519)\tData  0.002 ( 1.612)\tLoss 5.0539e+00 (5.7956e+00)\tAcc@1   6.80 (  4.03)\tAcc@5  20.60 ( 11.99)\n",
      "Epoch: [0][ 400/1282]\tTime  0.752 ( 2.532)\tData  0.002 ( 1.628)\tLoss 4.9236e+00 (5.7764e+00)\tAcc@1   9.80 (  4.14)\tAcc@5  25.20 ( 12.24)\n",
      "Epoch: [0][ 410/1282]\tTime  0.754 ( 2.548)\tData  0.002 ( 1.648)\tLoss 4.8328e+00 (5.7573e+00)\tAcc@1   7.80 (  4.25)\tAcc@5  26.40 ( 12.51)\n",
      "Epoch: [0][ 420/1282]\tTime  0.756 ( 2.551)\tData  0.002 ( 1.654)\tLoss 4.8708e+00 (5.7377e+00)\tAcc@1   9.20 (  4.36)\tAcc@5  27.40 ( 12.80)\n",
      "Epoch: [0][ 430/1282]\tTime  0.756 ( 2.555)\tData  0.003 ( 1.660)\tLoss 4.9143e+00 (5.7178e+00)\tAcc@1   8.40 (  4.49)\tAcc@5  23.00 ( 13.10)\n",
      "Epoch: [0][ 440/1282]\tTime  0.759 ( 2.555)\tData  0.002 ( 1.663)\tLoss 5.0522e+00 (5.6998e+00)\tAcc@1   8.60 (  4.61)\tAcc@5  20.60 ( 13.36)\n",
      "Epoch: [0][ 450/1282]\tTime  0.766 ( 2.559)\tData  0.002 ( 1.669)\tLoss 4.6075e+00 (5.6810e+00)\tAcc@1  11.00 (  4.73)\tAcc@5  28.00 ( 13.64)\n",
      "Epoch: [0][ 460/1282]\tTime  0.763 ( 2.561)\tData  0.002 ( 1.673)\tLoss 4.9731e+00 (5.6626e+00)\tAcc@1   8.60 (  4.85)\tAcc@5  25.00 ( 13.91)\n",
      "Epoch: [0][ 470/1282]\tTime  0.761 ( 2.568)\tData  0.002 ( 1.682)\tLoss 4.8834e+00 (5.6450e+00)\tAcc@1  11.00 (  4.95)\tAcc@5  24.80 ( 14.15)\n",
      "Epoch: [0][ 480/1282]\tTime  0.766 ( 2.569)\tData  0.003 ( 1.686)\tLoss 4.6694e+00 (5.6263e+00)\tAcc@1  13.40 (  5.08)\tAcc@5  29.40 ( 14.42)\n",
      "Epoch: [0][ 490/1282]\tTime  0.765 ( 2.574)\tData  0.002 ( 1.693)\tLoss 4.6187e+00 (5.6084e+00)\tAcc@1  11.60 (  5.20)\tAcc@5  28.40 ( 14.68)\n",
      "Epoch: [0][ 500/1282]\tTime  0.762 ( 2.574)\tData  0.002 ( 1.694)\tLoss 4.7934e+00 (5.5908e+00)\tAcc@1  12.40 (  5.32)\tAcc@5  26.60 ( 14.96)\n",
      "Epoch: [0][ 510/1282]\tTime  0.769 ( 2.578)\tData  0.002 ( 1.701)\tLoss 4.9117e+00 (5.5756e+00)\tAcc@1   7.00 (  5.41)\tAcc@5  23.40 ( 15.19)\n",
      "Epoch: [0][ 520/1282]\tTime  0.766 ( 2.583)\tData  0.002 ( 1.707)\tLoss 4.7933e+00 (5.5592e+00)\tAcc@1  10.60 (  5.53)\tAcc@5  26.60 ( 15.44)\n",
      "Epoch: [0][ 530/1282]\tTime  0.766 ( 2.593)\tData  0.002 ( 1.718)\tLoss 4.6525e+00 (5.5420e+00)\tAcc@1  12.40 (  5.65)\tAcc@5  29.80 ( 15.69)\n",
      "Epoch: [0][ 540/1282]\tTime  0.764 ( 2.599)\tData  0.003 ( 1.727)\tLoss 4.5374e+00 (5.5261e+00)\tAcc@1  14.00 (  5.76)\tAcc@5  29.80 ( 15.92)\n",
      "Epoch: [0][ 550/1282]\tTime  0.752 ( 2.600)\tData  0.002 ( 1.729)\tLoss 4.5621e+00 (5.5100e+00)\tAcc@1  12.00 (  5.87)\tAcc@5  31.80 ( 16.16)\n",
      "Epoch: [0][ 560/1282]\tTime  0.736 ( 2.604)\tData  0.002 ( 1.734)\tLoss 4.4784e+00 (5.4938e+00)\tAcc@1  14.00 (  6.00)\tAcc@5  31.20 ( 16.40)\n",
      "Epoch: [0][ 570/1282]\tTime  0.734 ( 2.607)\tData  0.002 ( 1.739)\tLoss 4.5751e+00 (5.4778e+00)\tAcc@1  10.20 (  6.11)\tAcc@5  29.40 ( 16.64)\n",
      "Epoch: [0][ 580/1282]\tTime  0.733 ( 2.613)\tData  0.002 ( 1.748)\tLoss 4.6194e+00 (5.4624e+00)\tAcc@1  14.00 (  6.24)\tAcc@5  30.60 ( 16.87)\n",
      "Epoch: [0][ 590/1282]\tTime  0.739 ( 2.612)\tData  0.002 ( 1.748)\tLoss 4.8003e+00 (5.4478e+00)\tAcc@1  12.00 (  6.36)\tAcc@5  26.80 ( 17.08)\n",
      "Epoch: [0][ 600/1282]\tTime  0.737 ( 2.614)\tData  0.002 ( 1.752)\tLoss 4.6630e+00 (5.4326e+00)\tAcc@1  11.60 (  6.47)\tAcc@5  28.40 ( 17.34)\n",
      "Epoch: [0][ 610/1282]\tTime  0.730 ( 2.614)\tData  0.002 ( 1.754)\tLoss 4.5659e+00 (5.4164e+00)\tAcc@1  12.40 (  6.60)\tAcc@5  32.00 ( 17.60)\n",
      "Epoch: [0][ 620/1282]\tTime  0.726 ( 2.616)\tData  0.002 ( 1.758)\tLoss 4.4370e+00 (5.4016e+00)\tAcc@1  11.80 (  6.72)\tAcc@5  35.00 ( 17.85)\n",
      "Epoch: [0][ 630/1282]\tTime  0.733 ( 2.619)\tData  0.002 ( 1.762)\tLoss 4.3566e+00 (5.3870e+00)\tAcc@1  15.80 (  6.84)\tAcc@5  34.20 ( 18.09)\n",
      "Epoch: [0][ 640/1282]\tTime  0.761 ( 2.619)\tData  0.002 ( 1.763)\tLoss 4.5426e+00 (5.3725e+00)\tAcc@1  12.80 (  6.95)\tAcc@5  32.40 ( 18.32)\n",
      "Epoch: [0][ 650/1282]\tTime  0.752 ( 2.619)\tData  0.002 ( 1.765)\tLoss 4.3116e+00 (5.3581e+00)\tAcc@1  17.00 (  7.08)\tAcc@5  37.20 ( 18.56)\n",
      "Epoch: [0][ 660/1282]\tTime  0.754 ( 2.627)\tData  0.003 ( 1.774)\tLoss 4.3492e+00 (5.3440e+00)\tAcc@1  14.00 (  7.19)\tAcc@5  36.40 ( 18.79)\n",
      "Epoch: [0][ 670/1282]\tTime  0.753 ( 2.630)\tData  0.002 ( 1.778)\tLoss 4.3823e+00 (5.3297e+00)\tAcc@1  12.60 (  7.30)\tAcc@5  33.20 ( 19.03)\n",
      "Epoch: [0][ 680/1282]\tTime  0.757 ( 2.631)\tData  0.002 ( 1.781)\tLoss 4.3411e+00 (5.3156e+00)\tAcc@1  15.60 (  7.42)\tAcc@5  36.60 ( 19.27)\n",
      "Epoch: [0][ 690/1282]\tTime  0.735 ( 2.632)\tData  0.002 ( 1.783)\tLoss 4.3061e+00 (5.3020e+00)\tAcc@1  15.60 (  7.54)\tAcc@5  37.20 ( 19.48)\n",
      "Epoch: [0][ 700/1282]\tTime  0.751 ( 2.639)\tData  0.002 ( 1.792)\tLoss 4.3896e+00 (5.2881e+00)\tAcc@1  12.80 (  7.66)\tAcc@5  34.80 ( 19.71)\n",
      "Epoch: [0][ 710/1282]\tTime  0.758 ( 2.649)\tData  0.002 ( 1.802)\tLoss 4.3882e+00 (5.2737e+00)\tAcc@1  14.20 (  7.78)\tAcc@5  34.00 ( 19.95)\n",
      "Epoch: [0][ 720/1282]\tTime  0.757 ( 2.653)\tData  0.002 ( 1.807)\tLoss 4.2019e+00 (5.2607e+00)\tAcc@1  18.40 (  7.89)\tAcc@5  38.00 ( 20.16)\n",
      "Epoch: [0][ 730/1282]\tTime  0.763 ( 2.657)\tData  0.002 ( 1.813)\tLoss 4.3511e+00 (5.2468e+00)\tAcc@1  16.60 (  8.00)\tAcc@5  33.40 ( 20.39)\n",
      "Epoch: [0][ 740/1282]\tTime  0.767 ( 2.663)\tData  0.002 ( 1.819)\tLoss 4.3776e+00 (5.2336e+00)\tAcc@1  15.20 (  8.12)\tAcc@5  33.80 ( 20.61)\n",
      "Epoch: [0][ 750/1282]\tTime  0.752 ( 2.675)\tData  0.003 ( 1.833)\tLoss 4.3035e+00 (5.2202e+00)\tAcc@1  17.00 (  8.24)\tAcc@5  34.80 ( 20.84)\n",
      "Epoch: [0][ 760/1282]\tTime  0.762 ( 2.683)\tData  0.003 ( 1.842)\tLoss 4.3660e+00 (5.2070e+00)\tAcc@1  15.80 (  8.37)\tAcc@5  33.20 ( 21.06)\n",
      "Epoch: [0][ 770/1282]\tTime  0.730 ( 2.685)\tData  0.002 ( 1.845)\tLoss 4.0490e+00 (5.1936e+00)\tAcc@1  19.40 (  8.49)\tAcc@5  41.80 ( 21.27)\n",
      "Epoch: [0][ 780/1282]\tTime  0.757 ( 2.688)\tData  0.002 ( 1.849)\tLoss 4.0816e+00 (5.1802e+00)\tAcc@1  19.40 (  8.61)\tAcc@5  41.60 ( 21.51)\n",
      "Epoch: [0][ 790/1282]\tTime  0.757 ( 2.691)\tData  0.002 ( 1.852)\tLoss 4.0831e+00 (5.1676e+00)\tAcc@1  18.00 (  8.72)\tAcc@5  42.80 ( 21.72)\n",
      "Epoch: [0][ 800/1282]\tTime  1.346 ( 2.694)\tData  0.627 ( 1.857)\tLoss 4.0875e+00 (5.1550e+00)\tAcc@1  17.00 (  8.83)\tAcc@5  39.60 ( 21.93)\n",
      "Epoch: [0][ 810/1282]\tTime  0.894 ( 2.696)\tData  0.178 ( 1.860)\tLoss 4.1439e+00 (5.1425e+00)\tAcc@1  16.40 (  8.94)\tAcc@5  38.20 ( 22.14)\n",
      "Epoch: [0][ 820/1282]\tTime  1.173 ( 2.695)\tData  0.452 ( 1.860)\tLoss 4.1974e+00 (5.1297e+00)\tAcc@1  18.00 (  9.06)\tAcc@5  40.00 ( 22.37)\n",
      "Epoch: [0][ 830/1282]\tTime  1.962 ( 2.694)\tData  1.239 ( 1.860)\tLoss 4.1210e+00 (5.1173e+00)\tAcc@1  17.80 (  9.17)\tAcc@5  41.20 ( 22.59)\n",
      "Epoch: [0][ 840/1282]\tTime  2.000 ( 2.694)\tData  1.274 ( 1.861)\tLoss 4.1552e+00 (5.1053e+00)\tAcc@1  17.60 (  9.28)\tAcc@5  36.80 ( 22.79)\n",
      "Epoch: [0][ 850/1282]\tTime  1.340 ( 2.693)\tData  0.611 ( 1.861)\tLoss 3.8632e+00 (5.0929e+00)\tAcc@1  23.40 (  9.40)\tAcc@5  44.60 ( 23.01)\n",
      "Epoch: [0][ 860/1282]\tTime  1.619 ( 2.692)\tData  0.885 ( 1.861)\tLoss 4.1048e+00 (5.0814e+00)\tAcc@1  15.40 (  9.51)\tAcc@5  39.20 ( 23.21)\n",
      "Epoch: [0][ 870/1282]\tTime  0.760 ( 2.693)\tData  0.002 ( 1.862)\tLoss 3.9326e+00 (5.0690e+00)\tAcc@1  19.00 (  9.63)\tAcc@5  45.00 ( 23.42)\n",
      "Epoch: [0][ 880/1282]\tTime  0.774 ( 2.694)\tData  0.002 ( 1.864)\tLoss 4.0335e+00 (5.0574e+00)\tAcc@1  20.20 (  9.73)\tAcc@5  40.60 ( 23.61)\n",
      "Epoch: [0][ 890/1282]\tTime  0.762 ( 2.697)\tData  0.002 ( 1.868)\tLoss 4.0547e+00 (5.0456e+00)\tAcc@1  20.40 (  9.84)\tAcc@5  41.40 ( 23.80)\n",
      "Epoch: [0][ 900/1282]\tTime  0.762 ( 2.700)\tData  0.002 ( 1.871)\tLoss 3.9722e+00 (5.0341e+00)\tAcc@1  21.40 (  9.95)\tAcc@5  44.00 ( 24.00)\n",
      "Epoch: [0][ 910/1282]\tTime  0.768 ( 2.700)\tData  0.002 ( 1.872)\tLoss 3.9361e+00 (5.0227e+00)\tAcc@1  20.00 ( 10.06)\tAcc@5  43.20 ( 24.20)\n",
      "Epoch: [0][ 920/1282]\tTime  0.738 ( 2.703)\tData  0.002 ( 1.875)\tLoss 3.9841e+00 (5.0113e+00)\tAcc@1  20.60 ( 10.16)\tAcc@5  43.00 ( 24.40)\n",
      "Epoch: [0][ 930/1282]\tTime  0.769 ( 2.703)\tData  0.002 ( 1.876)\tLoss 3.9457e+00 (5.0000e+00)\tAcc@1  21.60 ( 10.28)\tAcc@5  42.40 ( 24.60)\n",
      "Epoch: [0][ 940/1282]\tTime  0.740 ( 2.706)\tData  0.002 ( 1.879)\tLoss 4.0056e+00 (4.9891e+00)\tAcc@1  23.20 ( 10.38)\tAcc@5  43.60 ( 24.79)\n",
      "Epoch: [0][ 950/1282]\tTime  0.761 ( 2.706)\tData  0.002 ( 1.881)\tLoss 4.1398e+00 (4.9781e+00)\tAcc@1  18.20 ( 10.49)\tAcc@5  37.60 ( 24.98)\n",
      "Epoch: [0][ 960/1282]\tTime  0.844 ( 2.707)\tData  0.115 ( 1.882)\tLoss 3.9254e+00 (4.9670e+00)\tAcc@1  21.20 ( 10.60)\tAcc@5  42.00 ( 25.17)\n",
      "Epoch: [0][ 970/1282]\tTime  0.761 ( 2.711)\tData  0.003 ( 1.887)\tLoss 3.9712e+00 (4.9556e+00)\tAcc@1  19.60 ( 10.71)\tAcc@5  40.40 ( 25.38)\n",
      "Epoch: [0][ 980/1282]\tTime  0.764 ( 2.713)\tData  0.002 ( 1.889)\tLoss 3.7675e+00 (4.9443e+00)\tAcc@1  26.40 ( 10.83)\tAcc@5  47.20 ( 25.58)\n",
      "Epoch: [0][ 990/1282]\tTime  0.764 ( 2.717)\tData  0.002 ( 1.894)\tLoss 3.8055e+00 (4.9331e+00)\tAcc@1  18.80 ( 10.94)\tAcc@5  45.20 ( 25.78)\n",
      "Epoch: [0][1000/1282]\tTime  0.741 ( 2.716)\tData  0.002 ( 1.893)\tLoss 3.9522e+00 (4.9228e+00)\tAcc@1  21.40 ( 11.04)\tAcc@5  45.00 ( 25.97)\n",
      "Epoch: [0][1010/1282]\tTime  0.763 ( 2.716)\tData  0.002 ( 1.893)\tLoss 3.7040e+00 (4.9123e+00)\tAcc@1  23.60 ( 11.14)\tAcc@5  47.80 ( 26.15)\n",
      "Epoch: [0][1020/1282]\tTime  0.742 ( 2.715)\tData  0.002 ( 1.894)\tLoss 3.8561e+00 (4.9023e+00)\tAcc@1  21.40 ( 11.24)\tAcc@5  45.60 ( 26.33)\n",
      "Epoch: [0][1030/1282]\tTime  0.743 ( 2.714)\tData  0.002 ( 1.893)\tLoss 3.7385e+00 (4.8913e+00)\tAcc@1  24.20 ( 11.36)\tAcc@5  45.20 ( 26.52)\n",
      "Epoch: [0][1040/1282]\tTime  1.101 ( 2.715)\tData  0.369 ( 1.894)\tLoss 3.7220e+00 (4.8806e+00)\tAcc@1  22.00 ( 11.47)\tAcc@5  45.80 ( 26.71)\n",
      "Epoch: [0][1050/1282]\tTime  0.922 ( 2.716)\tData  0.188 ( 1.896)\tLoss 3.5890e+00 (4.8699e+00)\tAcc@1  24.40 ( 11.58)\tAcc@5  50.00 ( 26.90)\n",
      "Epoch: [0][1060/1282]\tTime  1.266 ( 2.719)\tData  0.528 ( 1.899)\tLoss 3.7523e+00 (4.8594e+00)\tAcc@1  20.20 ( 11.69)\tAcc@5  45.40 ( 27.08)\n",
      "Epoch: [0][1070/1282]\tTime  0.765 ( 2.730)\tData  0.002 ( 1.911)\tLoss 3.7464e+00 (4.8497e+00)\tAcc@1  23.80 ( 11.78)\tAcc@5  46.80 ( 27.26)\n",
      "Epoch: [0][1080/1282]\tTime  0.761 ( 2.742)\tData  0.002 ( 1.923)\tLoss 3.6740e+00 (4.8396e+00)\tAcc@1  23.60 ( 11.90)\tAcc@5  49.60 ( 27.44)\n",
      "Epoch: [0][1090/1282]\tTime  0.764 ( 2.751)\tData  0.002 ( 1.932)\tLoss 3.7330e+00 (4.8296e+00)\tAcc@1  23.20 ( 12.00)\tAcc@5  46.80 ( 27.62)\n",
      "Epoch: [0][1100/1282]\tTime  0.765 ( 2.757)\tData  0.002 ( 1.938)\tLoss 3.7904e+00 (4.8192e+00)\tAcc@1  21.00 ( 12.10)\tAcc@5  47.80 ( 27.80)\n",
      "Epoch: [0][1110/1282]\tTime  0.739 ( 2.756)\tData  0.002 ( 1.938)\tLoss 3.7061e+00 (4.8101e+00)\tAcc@1  21.40 ( 12.19)\tAcc@5  47.20 ( 27.96)\n",
      "Epoch: [0][1120/1282]\tTime  0.763 ( 2.756)\tData  0.002 ( 1.939)\tLoss 3.7696e+00 (4.8004e+00)\tAcc@1  21.20 ( 12.30)\tAcc@5  46.20 ( 28.14)\n",
      "Epoch: [0][1130/1282]\tTime  0.763 ( 2.759)\tData  0.002 ( 1.942)\tLoss 3.7502e+00 (4.7909e+00)\tAcc@1  24.20 ( 12.41)\tAcc@5  45.40 ( 28.31)\n",
      "Epoch: [0][1140/1282]\tTime  0.759 ( 2.758)\tData  0.003 ( 1.942)\tLoss 3.5507e+00 (4.7811e+00)\tAcc@1  26.60 ( 12.51)\tAcc@5  52.40 ( 28.48)\n",
      "Epoch: [0][1150/1282]\tTime  0.762 ( 2.761)\tData  0.002 ( 1.945)\tLoss 3.7467e+00 (4.7711e+00)\tAcc@1  24.20 ( 12.62)\tAcc@5  48.60 ( 28.66)\n",
      "Epoch: [0][1160/1282]\tTime  0.736 ( 2.760)\tData  0.002 ( 1.944)\tLoss 3.7662e+00 (4.7617e+00)\tAcc@1  22.80 ( 12.71)\tAcc@5  48.60 ( 28.82)\n",
      "Epoch: [0][1170/1282]\tTime  0.737 ( 2.763)\tData  0.002 ( 1.947)\tLoss 3.8346e+00 (4.7525e+00)\tAcc@1  22.80 ( 12.81)\tAcc@5  44.00 ( 28.98)\n",
      "Epoch: [0][1180/1282]\tTime  0.745 ( 2.762)\tData  0.002 ( 1.947)\tLoss 3.6437e+00 (4.7429e+00)\tAcc@1  26.60 ( 12.92)\tAcc@5  49.00 ( 29.15)\n",
      "Epoch: [0][1190/1282]\tTime  0.742 ( 2.760)\tData  0.002 ( 1.946)\tLoss 3.6260e+00 (4.7333e+00)\tAcc@1  25.00 ( 13.02)\tAcc@5  50.00 ( 29.32)\n",
      "Epoch: [0][1200/1282]\tTime  0.721 ( 2.760)\tData  0.002 ( 1.946)\tLoss 3.5454e+00 (4.7235e+00)\tAcc@1  26.60 ( 13.12)\tAcc@5  50.60 ( 29.50)\n",
      "Epoch: [0][1210/1282]\tTime  0.720 ( 2.759)\tData  0.002 ( 1.946)\tLoss 3.7727e+00 (4.7136e+00)\tAcc@1  21.40 ( 13.23)\tAcc@5  46.00 ( 29.68)\n",
      "Epoch: [0][1220/1282]\tTime  0.732 ( 2.760)\tData  0.002 ( 1.947)\tLoss 3.6012e+00 (4.7045e+00)\tAcc@1  26.00 ( 13.33)\tAcc@5  49.00 ( 29.84)\n",
      "Epoch: [0][1230/1282]\tTime  0.738 ( 2.761)\tData  0.002 ( 1.948)\tLoss 3.6921e+00 (4.6953e+00)\tAcc@1  23.80 ( 13.43)\tAcc@5  45.80 ( 30.00)\n",
      "Epoch: [0][1240/1282]\tTime  0.729 ( 2.759)\tData  0.002 ( 1.947)\tLoss 3.5560e+00 (4.6865e+00)\tAcc@1  27.40 ( 13.52)\tAcc@5  51.00 ( 30.16)\n",
      "Epoch: [0][1250/1282]\tTime  0.746 ( 2.759)\tData  0.002 ( 1.947)\tLoss 3.4471e+00 (4.6772e+00)\tAcc@1  28.00 ( 13.62)\tAcc@5  52.20 ( 30.33)\n",
      "Epoch: [0][1260/1282]\tTime  0.753 ( 2.759)\tData  0.002 ( 1.947)\tLoss 3.6260e+00 (4.6683e+00)\tAcc@1  24.40 ( 13.72)\tAcc@5  47.80 ( 30.48)\n",
      "Epoch: [0][1270/1282]\tTime  0.734 ( 2.757)\tData  0.002 ( 1.946)\tLoss 3.5347e+00 (4.6593e+00)\tAcc@1  28.20 ( 13.83)\tAcc@5  52.20 ( 30.64)\n",
      "Epoch: [0][1280/1282]\tTime  0.738 ( 2.757)\tData  0.002 ( 1.946)\tLoss 3.2979e+00 (4.6501e+00)\tAcc@1  32.20 ( 13.94)\tAcc@5  56.80 ( 30.82)\n",
      "Test: [0/3]\tTime  9.466 ( 9.466)\tLoss 3.9357e+00 (3.9357e+00)\tAcc@1  20.60 ( 20.60)\tAcc@5  43.80 ( 43.80)\n",
      " * Acc@1 20.579 Acc@5 43.457\n",
      "lr: [0.0]\n",
      "Epoch: [1][   0/1282]\tTime  7.359 ( 7.359)\tData  6.563 ( 6.563)\tLoss 3.5629e+00 (3.5629e+00)\tAcc@1  25.40 ( 25.40)\tAcc@5  51.00 ( 51.00)\n",
      "Epoch: [1][  10/1282]\tTime  5.108 ( 3.083)\tData  4.310 ( 2.318)\tLoss 3.6737e+00 (3.5330e+00)\tAcc@1  24.00 ( 25.65)\tAcc@5  48.60 ( 50.91)\n",
      "Epoch: [1][  20/1282]\tTime  4.872 ( 2.955)\tData  4.061 ( 2.181)\tLoss 3.5277e+00 (3.5276e+00)\tAcc@1  26.20 ( 26.15)\tAcc@5  51.60 ( 51.19)\n",
      "Epoch: [1][  30/1282]\tTime  4.598 ( 2.894)\tData  3.818 ( 2.125)\tLoss 3.4809e+00 (3.5148e+00)\tAcc@1  29.60 ( 26.75)\tAcc@5  53.00 ( 51.43)\n",
      "Epoch: [1][  40/1282]\tTime  3.657 ( 2.836)\tData  2.876 ( 2.068)\tLoss 3.6358e+00 (3.5205e+00)\tAcc@1  22.60 ( 26.76)\tAcc@5  50.20 ( 51.23)\n",
      "Epoch: [1][  50/1282]\tTime  4.807 ( 2.825)\tData  4.031 ( 2.059)\tLoss 3.6173e+00 (3.5233e+00)\tAcc@1  25.60 ( 26.73)\tAcc@5  51.40 ( 51.16)\n",
      "Epoch: [1][  60/1282]\tTime  4.605 ( 2.802)\tData  3.823 ( 2.036)\tLoss 3.4984e+00 (3.5297e+00)\tAcc@1  29.20 ( 26.64)\tAcc@5  54.00 ( 51.08)\n",
      "Epoch: [1][  70/1282]\tTime  4.832 ( 2.782)\tData  4.025 ( 2.016)\tLoss 3.4910e+00 (3.5278e+00)\tAcc@1  24.80 ( 26.67)\tAcc@5  50.20 ( 51.06)\n",
      "Epoch: [1][  80/1282]\tTime  4.454 ( 2.776)\tData  3.670 ( 2.009)\tLoss 3.5798e+00 (3.5312e+00)\tAcc@1  26.80 ( 26.55)\tAcc@5  48.80 ( 50.92)\n",
      "Epoch: [1][  90/1282]\tTime  4.710 ( 2.764)\tData  3.932 ( 1.997)\tLoss 3.5948e+00 (3.5323e+00)\tAcc@1  25.80 ( 26.47)\tAcc@5  49.00 ( 50.77)\n",
      "Epoch: [1][ 100/1282]\tTime  6.250 ( 2.788)\tData  5.471 ( 2.020)\tLoss 3.2833e+00 (3.5243e+00)\tAcc@1  30.20 ( 26.55)\tAcc@5  58.20 ( 50.88)\n",
      "Epoch: [1][ 110/1282]\tTime  6.216 ( 2.801)\tData  5.419 ( 2.032)\tLoss 3.3457e+00 (3.5224e+00)\tAcc@1  28.40 ( 26.57)\tAcc@5  56.00 ( 50.92)\n",
      "Epoch: [1][ 120/1282]\tTime  4.648 ( 2.801)\tData  3.869 ( 2.033)\tLoss 3.4040e+00 (3.5222e+00)\tAcc@1  26.40 ( 26.51)\tAcc@5  52.40 ( 50.91)\n",
      "Epoch: [1][ 130/1282]\tTime  5.312 ( 2.796)\tData  4.518 ( 2.027)\tLoss 3.3215e+00 (3.5240e+00)\tAcc@1  28.60 ( 26.46)\tAcc@5  56.40 ( 50.87)\n",
      "Epoch: [1][ 140/1282]\tTime  4.744 ( 2.789)\tData  3.955 ( 2.019)\tLoss 3.6478e+00 (3.5271e+00)\tAcc@1  25.20 ( 26.43)\tAcc@5  49.80 ( 50.84)\n",
      "Epoch: [1][ 150/1282]\tTime  5.718 ( 2.797)\tData  4.922 ( 2.027)\tLoss 3.5883e+00 (3.5235e+00)\tAcc@1  26.00 ( 26.46)\tAcc@5  50.40 ( 50.90)\n",
      "Epoch: [1][ 160/1282]\tTime  4.362 ( 2.792)\tData  3.578 ( 2.022)\tLoss 3.4655e+00 (3.5232e+00)\tAcc@1  28.00 ( 26.49)\tAcc@5  51.80 ( 50.91)\n",
      "Epoch: [1][ 170/1282]\tTime  3.846 ( 2.773)\tData  3.058 ( 2.002)\tLoss 3.3363e+00 (3.5225e+00)\tAcc@1  27.60 ( 26.47)\tAcc@5  54.00 ( 50.89)\n",
      "Epoch: [1][ 180/1282]\tTime  4.235 ( 2.764)\tData  3.455 ( 1.995)\tLoss 3.6341e+00 (3.5226e+00)\tAcc@1  23.40 ( 26.42)\tAcc@5  48.20 ( 50.86)\n",
      "Epoch: [1][ 190/1282]\tTime  4.272 ( 2.759)\tData  3.497 ( 1.989)\tLoss 3.5926e+00 (3.5221e+00)\tAcc@1  25.80 ( 26.44)\tAcc@5  50.40 ( 50.89)\n",
      "Epoch: [1][ 200/1282]\tTime  3.500 ( 2.753)\tData  2.718 ( 1.984)\tLoss 3.6326e+00 (3.5261e+00)\tAcc@1  25.20 ( 26.37)\tAcc@5  48.40 ( 50.81)\n",
      "Epoch: [1][ 210/1282]\tTime  2.995 ( 2.744)\tData  2.219 ( 1.976)\tLoss 3.5048e+00 (3.5260e+00)\tAcc@1  26.60 ( 26.36)\tAcc@5  50.80 ( 50.82)\n",
      "Epoch: [1][ 220/1282]\tTime  3.138 ( 2.749)\tData  2.328 ( 1.979)\tLoss 3.4586e+00 (3.5278e+00)\tAcc@1  26.60 ( 26.33)\tAcc@5  51.80 ( 50.78)\n",
      "Epoch: [1][ 230/1282]\tTime  2.981 ( 2.742)\tData  2.186 ( 1.973)\tLoss 3.4528e+00 (3.5283e+00)\tAcc@1  28.60 ( 26.35)\tAcc@5  51.20 ( 50.77)\n",
      "Epoch: [1][ 240/1282]\tTime  4.082 ( 2.742)\tData  3.278 ( 1.973)\tLoss 3.4995e+00 (3.5267e+00)\tAcc@1  24.80 ( 26.35)\tAcc@5  49.40 ( 50.79)\n",
      "Epoch: [1][ 250/1282]\tTime  3.720 ( 2.740)\tData  2.933 ( 1.971)\tLoss 3.6470e+00 (3.5269e+00)\tAcc@1  26.20 ( 26.34)\tAcc@5  49.20 ( 50.78)\n",
      "Epoch: [1][ 260/1282]\tTime  2.830 ( 2.739)\tData  2.020 ( 1.970)\tLoss 3.6674e+00 (3.5250e+00)\tAcc@1  26.20 ( 26.37)\tAcc@5  47.40 ( 50.82)\n",
      "Epoch: [1][ 270/1282]\tTime  2.943 ( 2.741)\tData  2.148 ( 1.972)\tLoss 3.6207e+00 (3.5259e+00)\tAcc@1  25.20 ( 26.35)\tAcc@5  47.20 ( 50.81)\n",
      "Epoch: [1][ 280/1282]\tTime  3.149 ( 2.743)\tData  2.354 ( 1.974)\tLoss 3.5495e+00 (3.5250e+00)\tAcc@1  26.20 ( 26.36)\tAcc@5  51.80 ( 50.81)\n",
      "Epoch: [1][ 290/1282]\tTime  3.198 ( 2.746)\tData  2.393 ( 1.977)\tLoss 3.3741e+00 (3.5237e+00)\tAcc@1  29.60 ( 26.37)\tAcc@5  53.20 ( 50.87)\n",
      "Epoch: [1][ 300/1282]\tTime  2.128 ( 2.738)\tData  1.393 ( 1.969)\tLoss 3.5495e+00 (3.5231e+00)\tAcc@1  25.60 ( 26.39)\tAcc@5  49.60 ( 50.89)\n",
      "Epoch: [1][ 310/1282]\tTime  1.914 ( 2.737)\tData  1.179 ( 1.968)\tLoss 3.5291e+00 (3.5218e+00)\tAcc@1  26.00 ( 26.40)\tAcc@5  54.00 ( 50.91)\n",
      "Epoch: [1][ 320/1282]\tTime  0.747 ( 2.746)\tData  0.003 ( 1.977)\tLoss 3.5539e+00 (3.5226e+00)\tAcc@1  25.40 ( 26.39)\tAcc@5  50.00 ( 50.90)\n",
      "Epoch: [1][ 330/1282]\tTime  1.102 ( 2.741)\tData  0.364 ( 1.973)\tLoss 3.4746e+00 (3.5238e+00)\tAcc@1  27.00 ( 26.38)\tAcc@5  50.00 ( 50.89)\n",
      "Epoch: [1][ 340/1282]\tTime  0.946 ( 2.740)\tData  0.209 ( 1.971)\tLoss 3.4739e+00 (3.5235e+00)\tAcc@1  23.80 ( 26.37)\tAcc@5  50.60 ( 50.89)\n",
      "Epoch: [1][ 350/1282]\tTime  0.761 ( 2.745)\tData  0.002 ( 1.976)\tLoss 3.5586e+00 (3.5229e+00)\tAcc@1  28.00 ( 26.35)\tAcc@5  51.40 ( 50.90)\n",
      "Epoch: [1][ 360/1282]\tTime  0.758 ( 2.751)\tData  0.002 ( 1.982)\tLoss 3.5111e+00 (3.5224e+00)\tAcc@1  26.80 ( 26.36)\tAcc@5  50.80 ( 50.91)\n",
      "Epoch: [1][ 370/1282]\tTime  0.753 ( 2.762)\tData  0.003 ( 1.993)\tLoss 3.5857e+00 (3.5230e+00)\tAcc@1  25.00 ( 26.35)\tAcc@5  53.20 ( 50.90)\n",
      "Epoch: [1][ 380/1282]\tTime  0.760 ( 2.762)\tData  0.002 ( 1.992)\tLoss 3.5470e+00 (3.5235e+00)\tAcc@1  24.20 ( 26.32)\tAcc@5  50.20 ( 50.89)\n",
      "Epoch: [1][ 390/1282]\tTime  0.739 ( 2.757)\tData  0.002 ( 1.988)\tLoss 3.5827e+00 (3.5232e+00)\tAcc@1  23.80 ( 26.33)\tAcc@5  48.00 ( 50.88)\n",
      "Epoch: [1][ 400/1282]\tTime  0.765 ( 2.759)\tData  0.003 ( 1.990)\tLoss 3.4027e+00 (3.5237e+00)\tAcc@1  28.40 ( 26.33)\tAcc@5  50.40 ( 50.88)\n",
      "Epoch: [1][ 410/1282]\tTime  0.753 ( 2.765)\tData  0.002 ( 1.996)\tLoss 3.3729e+00 (3.5247e+00)\tAcc@1  28.40 ( 26.33)\tAcc@5  52.80 ( 50.87)\n",
      "Epoch: [1][ 420/1282]\tTime  0.757 ( 2.772)\tData  0.002 ( 2.003)\tLoss 3.4616e+00 (3.5241e+00)\tAcc@1  25.40 ( 26.33)\tAcc@5  52.00 ( 50.87)\n",
      "Epoch: [1][ 430/1282]\tTime  0.754 ( 2.781)\tData  0.002 ( 2.011)\tLoss 3.5852e+00 (3.5240e+00)\tAcc@1  24.20 ( 26.33)\tAcc@5  50.80 ( 50.89)\n",
      "Epoch: [1][ 440/1282]\tTime  0.759 ( 2.778)\tData  0.002 ( 2.009)\tLoss 3.3982e+00 (3.5241e+00)\tAcc@1  30.20 ( 26.35)\tAcc@5  54.40 ( 50.90)\n",
      "Epoch: [1][ 450/1282]\tTime  0.731 ( 2.776)\tData  0.003 ( 2.007)\tLoss 3.3630e+00 (3.5247e+00)\tAcc@1  27.60 ( 26.35)\tAcc@5  52.80 ( 50.88)\n",
      "Epoch: [1][ 460/1282]\tTime  0.760 ( 2.781)\tData  0.002 ( 2.012)\tLoss 3.6191e+00 (3.5244e+00)\tAcc@1  26.00 ( 26.34)\tAcc@5  47.80 ( 50.89)\n",
      "Epoch: [1][ 470/1282]\tTime  0.735 ( 2.783)\tData  0.002 ( 2.014)\tLoss 3.6235e+00 (3.5241e+00)\tAcc@1  22.80 ( 26.33)\tAcc@5  48.80 ( 50.89)\n",
      "Epoch: [1][ 480/1282]\tTime  0.756 ( 2.782)\tData  0.002 ( 2.013)\tLoss 3.4297e+00 (3.5235e+00)\tAcc@1  28.20 ( 26.33)\tAcc@5  52.40 ( 50.90)\n",
      "Epoch: [1][ 490/1282]\tTime  0.761 ( 2.787)\tData  0.002 ( 2.018)\tLoss 3.5131e+00 (3.5237e+00)\tAcc@1  27.80 ( 26.33)\tAcc@5  51.00 ( 50.90)\n",
      "Epoch: [1][ 500/1282]\tTime  0.750 ( 2.795)\tData  0.002 ( 2.026)\tLoss 3.5764e+00 (3.5236e+00)\tAcc@1  24.40 ( 26.34)\tAcc@5  48.20 ( 50.90)\n",
      "Epoch: [1][ 510/1282]\tTime  0.759 ( 2.797)\tData  0.002 ( 2.028)\tLoss 3.6651e+00 (3.5245e+00)\tAcc@1  23.40 ( 26.33)\tAcc@5  47.80 ( 50.89)\n",
      "Epoch: [1][ 520/1282]\tTime  0.754 ( 2.799)\tData  0.002 ( 2.030)\tLoss 3.5334e+00 (3.5235e+00)\tAcc@1  26.60 ( 26.34)\tAcc@5  50.80 ( 50.90)\n",
      "Epoch: [1][ 530/1282]\tTime  0.761 ( 2.800)\tData  0.003 ( 2.031)\tLoss 3.6308e+00 (3.5232e+00)\tAcc@1  24.40 ( 26.34)\tAcc@5  47.80 ( 50.89)\n",
      "Epoch: [1][ 540/1282]\tTime  0.755 ( 2.803)\tData  0.002 ( 2.033)\tLoss 3.3456e+00 (3.5234e+00)\tAcc@1  29.20 ( 26.33)\tAcc@5  53.00 ( 50.90)\n",
      "Epoch: [1][ 550/1282]\tTime  0.761 ( 2.804)\tData  0.002 ( 2.035)\tLoss 3.3995e+00 (3.5228e+00)\tAcc@1  30.40 ( 26.35)\tAcc@5  54.40 ( 50.90)\n",
      "Epoch: [1][ 560/1282]\tTime  0.763 ( 2.804)\tData  0.002 ( 2.035)\tLoss 3.5283e+00 (3.5225e+00)\tAcc@1  27.00 ( 26.34)\tAcc@5  49.40 ( 50.90)\n",
      "Epoch: [1][ 570/1282]\tTime  0.764 ( 2.800)\tData  0.003 ( 2.031)\tLoss 3.5299e+00 (3.5221e+00)\tAcc@1  26.80 ( 26.36)\tAcc@5  49.40 ( 50.90)\n",
      "Epoch: [1][ 580/1282]\tTime  0.762 ( 2.799)\tData  0.002 ( 2.030)\tLoss 3.5975e+00 (3.5223e+00)\tAcc@1  26.00 ( 26.35)\tAcc@5  50.20 ( 50.90)\n",
      "Epoch: [1][ 590/1282]\tTime  0.763 ( 2.796)\tData  0.002 ( 2.027)\tLoss 3.7600e+00 (3.5228e+00)\tAcc@1  24.80 ( 26.34)\tAcc@5  46.00 ( 50.89)\n",
      "Epoch: [1][ 600/1282]\tTime  0.763 ( 2.794)\tData  0.002 ( 2.025)\tLoss 3.7159e+00 (3.5234e+00)\tAcc@1  24.00 ( 26.34)\tAcc@5  46.00 ( 50.87)\n",
      "Epoch: [1][ 610/1282]\tTime  0.760 ( 2.797)\tData  0.002 ( 2.029)\tLoss 3.5707e+00 (3.5227e+00)\tAcc@1  25.80 ( 26.35)\tAcc@5  49.00 ( 50.88)\n",
      "Epoch: [1][ 620/1282]\tTime  0.765 ( 2.800)\tData  0.002 ( 2.031)\tLoss 3.4955e+00 (3.5228e+00)\tAcc@1  28.00 ( 26.35)\tAcc@5  50.40 ( 50.87)\n",
      "Epoch: [1][ 630/1282]\tTime  0.761 ( 2.805)\tData  0.002 ( 2.036)\tLoss 3.4960e+00 (3.5228e+00)\tAcc@1  27.20 ( 26.36)\tAcc@5  53.00 ( 50.87)\n",
      "Epoch: [1][ 640/1282]\tTime  0.740 ( 2.810)\tData  0.002 ( 2.041)\tLoss 3.7130e+00 (3.5233e+00)\tAcc@1  24.60 ( 26.35)\tAcc@5  46.60 ( 50.85)\n",
      "Epoch: [1][ 650/1282]\tTime  0.743 ( 2.811)\tData  0.002 ( 2.042)\tLoss 3.4080e+00 (3.5233e+00)\tAcc@1  28.60 ( 26.35)\tAcc@5  51.60 ( 50.84)\n",
      "Epoch: [1][ 660/1282]\tTime  0.756 ( 2.818)\tData  0.002 ( 2.049)\tLoss 3.5290e+00 (3.5231e+00)\tAcc@1  26.40 ( 26.35)\tAcc@5  51.80 ( 50.86)\n",
      "Epoch: [1][ 670/1282]\tTime  0.763 ( 2.818)\tData  0.002 ( 2.049)\tLoss 3.4850e+00 (3.5228e+00)\tAcc@1  28.20 ( 26.36)\tAcc@5  52.80 ( 50.87)\n",
      "Epoch: [1][ 680/1282]\tTime  0.756 ( 2.821)\tData  0.002 ( 2.051)\tLoss 3.5037e+00 (3.5225e+00)\tAcc@1  27.40 ( 26.37)\tAcc@5  53.20 ( 50.88)\n",
      "Epoch: [1][ 690/1282]\tTime  0.759 ( 2.823)\tData  0.002 ( 2.053)\tLoss 3.5551e+00 (3.5227e+00)\tAcc@1  27.60 ( 26.35)\tAcc@5  51.00 ( 50.88)\n",
      "Epoch: [1][ 700/1282]\tTime  0.761 ( 2.823)\tData  0.002 ( 2.053)\tLoss 3.5706e+00 (3.5220e+00)\tAcc@1  24.20 ( 26.37)\tAcc@5  49.00 ( 50.90)\n",
      "Epoch: [1][ 710/1282]\tTime  0.757 ( 2.826)\tData  0.002 ( 2.056)\tLoss 3.6134e+00 (3.5212e+00)\tAcc@1  24.20 ( 26.38)\tAcc@5  48.60 ( 50.93)\n",
      "Epoch: [1][ 720/1282]\tTime  0.758 ( 2.828)\tData  0.003 ( 2.058)\tLoss 3.4778e+00 (3.5211e+00)\tAcc@1  26.40 ( 26.38)\tAcc@5  51.00 ( 50.94)\n",
      "Epoch: [1][ 730/1282]\tTime  0.769 ( 2.831)\tData  0.002 ( 2.061)\tLoss 3.5792e+00 (3.5206e+00)\tAcc@1  23.40 ( 26.39)\tAcc@5  51.40 ( 50.95)\n",
      "Epoch: [1][ 740/1282]\tTime  0.757 ( 2.830)\tData  0.002 ( 2.060)\tLoss 3.5974e+00 (3.5202e+00)\tAcc@1  25.00 ( 26.39)\tAcc@5  45.80 ( 50.95)\n",
      "Epoch: [1][ 750/1282]\tTime  0.757 ( 2.830)\tData  0.002 ( 2.059)\tLoss 3.4711e+00 (3.5200e+00)\tAcc@1  27.00 ( 26.39)\tAcc@5  53.00 ( 50.96)\n",
      "Epoch: [1][ 760/1282]\tTime  0.764 ( 2.829)\tData  0.002 ( 2.059)\tLoss 3.6531e+00 (3.5194e+00)\tAcc@1  23.20 ( 26.40)\tAcc@5  48.20 ( 50.96)\n",
      "Epoch: [1][ 770/1282]\tTime  0.794 ( 2.832)\tData  0.002 ( 2.061)\tLoss 3.3503e+00 (3.5185e+00)\tAcc@1  28.40 ( 26.40)\tAcc@5  56.00 ( 50.98)\n",
      "Epoch: [1][ 780/1282]\tTime  0.767 ( 2.829)\tData  0.002 ( 2.058)\tLoss 3.3291e+00 (3.5180e+00)\tAcc@1  30.00 ( 26.41)\tAcc@5  55.20 ( 51.00)\n",
      "Epoch: [1][ 790/1282]\tTime  0.763 ( 2.829)\tData  0.002 ( 2.058)\tLoss 3.4212e+00 (3.5178e+00)\tAcc@1  28.40 ( 26.41)\tAcc@5  50.60 ( 51.00)\n",
      "Epoch: [1][ 800/1282]\tTime  0.774 ( 2.827)\tData  0.003 ( 2.056)\tLoss 3.4123e+00 (3.5172e+00)\tAcc@1  25.60 ( 26.41)\tAcc@5  54.40 ( 51.02)\n",
      "Epoch: [1][ 810/1282]\tTime  0.765 ( 2.826)\tData  0.002 ( 2.054)\tLoss 3.4657e+00 (3.5168e+00)\tAcc@1  27.60 ( 26.42)\tAcc@5  52.80 ( 51.02)\n",
      "Epoch: [1][ 820/1282]\tTime  0.849 ( 2.824)\tData  0.002 ( 2.052)\tLoss 3.5020e+00 (3.5160e+00)\tAcc@1  24.20 ( 26.44)\tAcc@5  51.20 ( 51.04)\n",
      "Epoch: [1][ 830/1282]\tTime  0.764 ( 2.823)\tData  0.002 ( 2.050)\tLoss 3.5755e+00 (3.5158e+00)\tAcc@1  25.60 ( 26.44)\tAcc@5  49.80 ( 51.05)\n",
      "Epoch: [1][ 840/1282]\tTime  0.761 ( 2.824)\tData  0.002 ( 2.052)\tLoss 3.5691e+00 (3.5156e+00)\tAcc@1  26.20 ( 26.44)\tAcc@5  49.40 ( 51.06)\n",
      "Epoch: [1][ 850/1282]\tTime  0.764 ( 2.828)\tData  0.002 ( 2.055)\tLoss 3.3322e+00 (3.5149e+00)\tAcc@1  29.60 ( 26.44)\tAcc@5  55.00 ( 51.08)\n",
      "Epoch: [1][ 860/1282]\tTime  0.760 ( 2.830)\tData  0.002 ( 2.058)\tLoss 3.4950e+00 (3.5149e+00)\tAcc@1  26.80 ( 26.44)\tAcc@5  52.20 ( 51.09)\n",
      "Epoch: [1][ 870/1282]\tTime  0.763 ( 2.833)\tData  0.002 ( 2.060)\tLoss 3.3478e+00 (3.5139e+00)\tAcc@1  28.00 ( 26.45)\tAcc@5  53.40 ( 51.10)\n",
      "Epoch: [1][ 880/1282]\tTime  0.757 ( 2.839)\tData  0.002 ( 2.067)\tLoss 3.4123e+00 (3.5137e+00)\tAcc@1  28.00 ( 26.45)\tAcc@5  53.80 ( 51.09)\n",
      "Epoch: [1][ 890/1282]\tTime  0.757 ( 2.843)\tData  0.002 ( 2.070)\tLoss 3.5025e+00 (3.5129e+00)\tAcc@1  27.40 ( 26.45)\tAcc@5  51.40 ( 51.11)\n",
      "Epoch: [1][ 900/1282]\tTime  0.761 ( 2.845)\tData  0.002 ( 2.072)\tLoss 3.4968e+00 (3.5130e+00)\tAcc@1  29.00 ( 26.45)\tAcc@5  52.00 ( 51.11)\n",
      "Epoch: [1][ 910/1282]\tTime  0.762 ( 2.847)\tData  0.002 ( 2.075)\tLoss 3.4403e+00 (3.5130e+00)\tAcc@1  25.80 ( 26.45)\tAcc@5  56.20 ( 51.11)\n",
      "Epoch: [1][ 920/1282]\tTime  0.762 ( 2.848)\tData  0.003 ( 2.076)\tLoss 3.3757e+00 (3.5123e+00)\tAcc@1  27.60 ( 26.46)\tAcc@5  54.80 ( 51.13)\n",
      "Epoch: [1][ 930/1282]\tTime  0.758 ( 2.849)\tData  0.003 ( 2.077)\tLoss 3.5559e+00 (3.5119e+00)\tAcc@1  23.40 ( 26.47)\tAcc@5  49.80 ( 51.15)\n",
      "Epoch: [1][ 940/1282]\tTime  0.762 ( 2.849)\tData  0.002 ( 2.077)\tLoss 3.5395e+00 (3.5116e+00)\tAcc@1  28.40 ( 26.48)\tAcc@5  51.80 ( 51.15)\n",
      "Epoch: [1][ 950/1282]\tTime  0.760 ( 2.850)\tData  0.002 ( 2.077)\tLoss 3.5028e+00 (3.5110e+00)\tAcc@1  27.40 ( 26.50)\tAcc@5  52.00 ( 51.16)\n",
      "Epoch: [1][ 960/1282]\tTime  0.763 ( 2.850)\tData  0.002 ( 2.078)\tLoss 3.4490e+00 (3.5104e+00)\tAcc@1  25.20 ( 26.51)\tAcc@5  49.40 ( 51.17)\n",
      "Epoch: [1][ 970/1282]\tTime  0.758 ( 2.855)\tData  0.002 ( 2.083)\tLoss 3.5146e+00 (3.5095e+00)\tAcc@1  24.80 ( 26.52)\tAcc@5  49.00 ( 51.18)\n",
      "Epoch: [1][ 980/1282]\tTime  0.766 ( 2.862)\tData  0.002 ( 2.089)\tLoss 3.3602e+00 (3.5087e+00)\tAcc@1  30.60 ( 26.53)\tAcc@5  52.20 ( 51.20)\n",
      "Epoch: [1][ 990/1282]\tTime  0.772 ( 2.866)\tData  0.002 ( 2.093)\tLoss 3.3720e+00 (3.5082e+00)\tAcc@1  25.60 ( 26.54)\tAcc@5  53.80 ( 51.21)\n",
      "Epoch: [1][1000/1282]\tTime  0.751 ( 2.863)\tData  0.002 ( 2.090)\tLoss 3.4919e+00 (3.5082e+00)\tAcc@1  24.40 ( 26.53)\tAcc@5  50.80 ( 51.21)\n",
      "Epoch: [1][1010/1282]\tTime  0.751 ( 2.860)\tData  0.002 ( 2.087)\tLoss 3.3894e+00 (3.5076e+00)\tAcc@1  28.60 ( 26.54)\tAcc@5  51.60 ( 51.22)\n",
      "Epoch: [1][1020/1282]\tTime  0.755 ( 2.857)\tData  0.002 ( 2.084)\tLoss 3.4898e+00 (3.5076e+00)\tAcc@1  26.40 ( 26.54)\tAcc@5  53.20 ( 51.22)\n",
      "Epoch: [1][1030/1282]\tTime  0.757 ( 2.852)\tData  0.002 ( 2.079)\tLoss 3.3524e+00 (3.5066e+00)\tAcc@1  29.00 ( 26.55)\tAcc@5  54.00 ( 51.24)\n",
      "Epoch: [1][1040/1282]\tTime  0.759 ( 2.849)\tData  0.002 ( 2.076)\tLoss 3.3352e+00 (3.5057e+00)\tAcc@1  29.40 ( 26.57)\tAcc@5  54.80 ( 51.26)\n",
      "Epoch: [1][1050/1282]\tTime  0.765 ( 2.846)\tData  0.002 ( 2.073)\tLoss 3.3499e+00 (3.5049e+00)\tAcc@1  28.40 ( 26.58)\tAcc@5  56.60 ( 51.28)\n",
      "Epoch: [1][1060/1282]\tTime  0.767 ( 2.844)\tData  0.002 ( 2.071)\tLoss 3.4066e+00 (3.5040e+00)\tAcc@1  26.80 ( 26.60)\tAcc@5  52.80 ( 51.30)\n",
      "Epoch: [1][1070/1282]\tTime  0.760 ( 2.843)\tData  0.002 ( 2.069)\tLoss 3.3601e+00 (3.5036e+00)\tAcc@1  31.00 ( 26.61)\tAcc@5  54.20 ( 51.31)\n",
      "Epoch: [1][1080/1282]\tTime  0.783 ( 2.842)\tData  0.003 ( 2.069)\tLoss 3.3516e+00 (3.5031e+00)\tAcc@1  28.40 ( 26.62)\tAcc@5  53.40 ( 51.32)\n",
      "Epoch: [1][1090/1282]\tTime  0.762 ( 2.840)\tData  0.002 ( 2.067)\tLoss 3.5173e+00 (3.5022e+00)\tAcc@1  23.60 ( 26.62)\tAcc@5  52.20 ( 51.33)\n",
      "Epoch: [1][1100/1282]\tTime  0.765 ( 2.838)\tData  0.002 ( 2.064)\tLoss 3.3645e+00 (3.5011e+00)\tAcc@1  28.40 ( 26.64)\tAcc@5  53.80 ( 51.35)\n",
      "Epoch: [1][1110/1282]\tTime  0.762 ( 2.834)\tData  0.003 ( 2.060)\tLoss 3.4038e+00 (3.5010e+00)\tAcc@1  27.00 ( 26.63)\tAcc@5  52.20 ( 51.35)\n",
      "Epoch: [1][1120/1282]\tTime  0.771 ( 2.834)\tData  0.002 ( 2.060)\tLoss 3.5142e+00 (3.5004e+00)\tAcc@1  24.60 ( 26.64)\tAcc@5  50.40 ( 51.36)\n",
      "Epoch: [1][1130/1282]\tTime  0.794 ( 2.833)\tData  0.002 ( 2.058)\tLoss 3.3755e+00 (3.4998e+00)\tAcc@1  29.20 ( 26.65)\tAcc@5  56.20 ( 51.38)\n",
      "Epoch: [1][1140/1282]\tTime  0.801 ( 2.830)\tData  0.002 ( 2.056)\tLoss 3.3207e+00 (3.4988e+00)\tAcc@1  32.20 ( 26.67)\tAcc@5  55.60 ( 51.40)\n",
      "Epoch: [1][1150/1282]\tTime  0.801 ( 2.829)\tData  0.002 ( 2.054)\tLoss 3.4892e+00 (3.4977e+00)\tAcc@1  25.00 ( 26.68)\tAcc@5  52.80 ( 51.42)\n",
      "Epoch: [1][1160/1282]\tTime  0.767 ( 2.827)\tData  0.002 ( 2.052)\tLoss 3.4840e+00 (3.4970e+00)\tAcc@1  28.20 ( 26.69)\tAcc@5  50.20 ( 51.43)\n",
      "Epoch: [1][1170/1282]\tTime  0.763 ( 2.829)\tData  0.003 ( 2.054)\tLoss 3.5238e+00 (3.4965e+00)\tAcc@1  26.20 ( 26.70)\tAcc@5  51.20 ( 51.44)\n",
      "Epoch: [1][1180/1282]\tTime  0.751 ( 2.832)\tData  0.002 ( 2.058)\tLoss 3.4422e+00 (3.4955e+00)\tAcc@1  26.00 ( 26.72)\tAcc@5  49.00 ( 51.46)\n",
      "Epoch: [1][1190/1282]\tTime  0.728 ( 2.832)\tData  0.003 ( 2.057)\tLoss 3.3452e+00 (3.4942e+00)\tAcc@1  29.00 ( 26.74)\tAcc@5  53.20 ( 51.49)\n",
      "Epoch: [1][1200/1282]\tTime  0.723 ( 2.829)\tData  0.002 ( 2.055)\tLoss 3.3436e+00 (3.4928e+00)\tAcc@1  28.80 ( 26.75)\tAcc@5  52.40 ( 51.51)\n",
      "Epoch: [1][1210/1282]\tTime  0.746 ( 2.827)\tData  0.002 ( 2.053)\tLoss 3.5510e+00 (3.4912e+00)\tAcc@1  22.40 ( 26.77)\tAcc@5  50.60 ( 51.54)\n",
      "Epoch: [1][1220/1282]\tTime  0.737 ( 2.826)\tData  0.002 ( 2.052)\tLoss 3.3781e+00 (3.4901e+00)\tAcc@1  28.40 ( 26.79)\tAcc@5  49.60 ( 51.56)\n",
      "Epoch: [1][1230/1282]\tTime  0.753 ( 2.827)\tData  0.002 ( 2.053)\tLoss 3.2963e+00 (3.4887e+00)\tAcc@1  30.20 ( 26.81)\tAcc@5  54.80 ( 51.59)\n",
      "Epoch: [1][1240/1282]\tTime  0.749 ( 2.829)\tData  0.002 ( 2.055)\tLoss 3.3138e+00 (3.4873e+00)\tAcc@1  30.20 ( 26.83)\tAcc@5  54.80 ( 51.61)\n",
      "Epoch: [1][1250/1282]\tTime  0.753 ( 2.833)\tData  0.002 ( 2.059)\tLoss 3.2225e+00 (3.4853e+00)\tAcc@1  33.60 ( 26.86)\tAcc@5  58.00 ( 51.65)\n",
      "Epoch: [1][1260/1282]\tTime  0.740 ( 2.832)\tData  0.002 ( 2.058)\tLoss 3.3179e+00 (3.4835e+00)\tAcc@1  28.40 ( 26.89)\tAcc@5  54.60 ( 51.68)\n",
      "Epoch: [1][1270/1282]\tTime  0.739 ( 2.831)\tData  0.002 ( 2.057)\tLoss 3.0633e+00 (3.4814e+00)\tAcc@1  34.20 ( 26.92)\tAcc@5  61.20 ( 51.72)\n",
      "Epoch: [1][1280/1282]\tTime  0.739 ( 2.830)\tData  0.002 ( 2.056)\tLoss 3.0515e+00 (3.4783e+00)\tAcc@1  34.60 ( 26.98)\tAcc@5  60.00 ( 51.78)\n",
      "Test: [0/3]\tTime  7.697 ( 7.697)\tLoss 3.3160e+00 (3.3160e+00)\tAcc@1  27.60 ( 27.60)\tAcc@5  56.00 ( 56.00)\n",
      " * Acc@1 25.974 Acc@5 51.349\n",
      "lr: [0.1]\n",
      "CPU times: user 49min 39s, sys: 14min 34s, total: 1h 4min 13s\n",
      "Wall time: 1h 59min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "russian-european",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26134), started 0:22:29 ago. (Use '!kill 26134' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8af0023627b7bda\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8af0023627b7bda\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "governmental-columbia",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9291), started 3:18:02 ago. (Use '!kill 9291' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1027c4d1c386bbc4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1027c4d1c386bbc4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "empirical-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c2ce6f447ed4d57b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c2ce6f447ed4d57b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}  --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "victorian-smile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "E1029 22:56:17.007480 140491027007296 program.py:298] TensorBoard could not bind to port 8888, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 8888, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=data/ --port=8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-theory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
